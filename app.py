import streamlit as st
import os
import zipfile
import shutil
import tempfile
import re
import pandas as pd
import pdfplumber
import xml.etree.ElementTree as ET
from pypdf import PdfWriter

# ==========================================
# 1. åŸºç¡€å·¥å…·å‡½æ•°
# ==========================================

def extract_zip_with_encoding(zip_path, extract_to):
    """è§£å‹ ZIP å¹¶ä¿®å¤ä¸­æ–‡ä¹±ç """
    with zipfile.ZipFile(zip_path, 'r') as z:
        for file_info in z.infolist():
            try:
                if file_info.flag_bits & 0x800 == 0:
                    original_name = file_info.filename.encode('cp437').decode('gbk')
                else:
                    original_name = file_info.filename
            except:
                try: original_name = file_info.filename.encode('utf-8').decode('utf-8')
                except: original_name = file_info.filename

            if "__MACOSX" in original_name or ".DS_Store" in original_name:
                continue

            target_path = os.path.join(extract_to, original_name)
            parent_dir = os.path.dirname(target_path)
            if parent_dir and not os.path.exists(parent_dir):
                os.makedirs(parent_dir, exist_ok=True)
                
            if not original_name.endswith('/'):
                with z.open(file_info) as source, open(target_path, "wb") as target:
                    shutil.copyfileobj(source, target)

def normalize_text(text):
    """æ–‡æœ¬æ¸…æ´—"""
    if not text: return ""
    return text.replace(" ", "").replace("\n", "").replace("\r", "")\
               .replace("ï¼š", ":").replace("ï¿¥", "Â¥")\
               .replace("ï¼ˆ", "(").replace("ï¼‰", ")")\
               .replace("O", "0")

def format_date(date_str):
    """ç»Ÿä¸€æ—¥æœŸæ ¼å¼ YYYY-MM-DD"""
    if not date_str: return ""
    # æå–å¹´-æœˆ-æ—¥
    m = re.search(r'(\d{4})[-å¹´/.](\d{1,2})[-æœˆ/.](\d{1,2})', date_str)
    if m:
        return f"{m.group(1)}-{int(m.group(2)):02d}-{int(m.group(3)):02d}"
    return ""

def find_best_amount(text):
    """åŒé‡ç­–ç•¥æå–é‡‘é¢"""
    if not text: return 0.0
    # ç­–ç•¥A: é”šç‚¹æŸ¥æ‰¾
    anchor_pattern = r'(?:å°å†™|Â¥|ï¿¥|åˆè®¡|é‡‘é¢)[^0-9\.]*([0-9]{1,3}(?:,[0-9]{3})*\.[0-9]{2})'
    for m in re.findall(anchor_pattern, text):
        try:
            val = float(m.replace(",", ""))
            if 0.01 <= val <= 5000000: return val
        except: continue

    # ç­–ç•¥B: æœ€å¤§å€¼
    matches = re.findall(r'(\d{1,3}(?:,\d{3})*\.\d{2})', text)
    valid = []
    for m in matches:
        try:
            val = float(m.replace(",", ""))
            if 0.01 <= val <= 5000000 and val not in [0.06, 0.03, 0.13, 0.01, 1.00]:
                valid.append(val)
        except: continue
    return max(valid) if valid else 0.0

def extract_seller_name_smart(text):
    """æå–é”€å”®æ–¹"""
    suffix = r"[\u4e00-\u9fa5()ï¼ˆï¼‰]{2,30}(?:å…¬å¸|äº‹åŠ¡æ‰€|é…’åº—|æ—…è¡Œç¤¾|ç»è¥éƒ¨|æœåŠ¡éƒ¨|åˆ†è¡Œ|æ”¯è¡Œ|é¦†|åº—|å¤„|ä¸­å¿ƒ)"
    candidates = list(set(re.findall(suffix, text)))
    blacklist = ["ç¨åŠ¡å±€", "è´¢æ”¿éƒ¨", "è´­ä¹°æ–¹", "å¼€æˆ·è¡Œ", "é“¶è¡Œ", "åœ°å€", "ç”µè¯", "ç»Ÿä¸€ç¤¾ä¼šä¿¡ç”¨", "çº³ç¨äºº", "é€‚ç”¨ç¨ç‡", "å¯†ç åŒº"]
    filtered = [c for c in candidates if not any(b in c for b in blacklist) and len(c) >= 4]
    return max(filtered, key=len) if filtered else ""

def is_trip_file(filename, text=None):
    """åˆ¤æ–­è¡Œç¨‹å•"""
    fn = filename.lower()
    if "è¡Œç¨‹" in fn or "trip" in fn or "æŠ¥é”€" in fn:
        if text:
            clean = normalize_text(text)
            if "å‘ç¥¨ä»£ç " in clean or "å‘ç¥¨å·ç " in clean or "ç”µå­å‘ç¥¨" in clean:
                return False
        return True
    return False

# ==========================================
# 2. è§£æå‡½æ•° (å¢å¼ºç‰ˆ)
# ==========================================

def parse_xml_invoice_data(xml_path):
    try:
        tree = ET.parse(xml_path)
        root = tree.getroot()
        def g(path):
            node = root.find(path)
            return node.text if node is not None else ""

        num = g(".//TaxSupervisionInfo/InvoiceNumber") or g(".//InvoiceNumber") or g(".//Fphm")
        date = g(".//TaxSupervisionInfo/IssueTime") or g(".//IssueTime") or g(".//Kprq")
        seller = g(".//SellerInformation/SellerName") or g(".//Xfmc")
        amt_str = g(".//BasicInformation/TotalTax-includedAmount") or g(".//TotalTax-includedAmount") or g(".//TotalAmount") or g(".//Jshj")
        amount = float(amt_str.replace(',', '')) if amt_str else 0.0

        return {
            "num": num, "date": format_date(date), 
            "seller": seller, "amount": amount
        }
    except: return None

def extract_data_from_pdf_simple(pdf_path):
    try:
        with pdfplumber.open(pdf_path) as p:
            if not p.pages: return None
            raw = p.pages[0].extract_text()
            if not raw or len(raw.strip()) < 10: return None # çº¯å›¾å¿½ç•¥
            
            text = normalize_text(raw)
            num = ""
            m20 = re.search(r'(\d{20})', text)
            if m20: num = m20.group(1)
            else:
                m8 = re.search(r'(?:å·ç |No)[:|]?(\d{8,})', text)
                if m8: num = m8.group(1)
            
            date = ""
            md = re.search(r'(\d{4}[-å¹´/.]\d{1,2}[-æœˆ/.]\d{1,2}æ—¥?)', text)
            if md: date = format_date(md.group(1))
            
            amt = find_best_amount(text)
            seller = extract_seller_name_smart(text)
            
            return {
                "å‘ç¥¨å·ç ": num, "å¼€ç¥¨æ—¥æœŸ": date, "é”€å”®æ–¹åç§°": seller,
                "ä»·ç¨åˆè®¡": amt, "æ–‡ä»¶å": os.path.basename(pdf_path)
            }
    except: return None

# ==========================================
# 3. æ ¸å¿ƒæ ¡éªŒå¼•æ“ (Verification Engine)
# ==========================================

class InvoiceVerifier:
    def __init__(self, processed_df):
        """
        æ ¹æ® Excel æ•°æ®å»ºç«‹å¤šç»´ç´¢å¼•
        """
        self.df = processed_df
        self.processed_nums = {}   # Num -> {Amount, Date}
        self.processed_attrs = {}  # (Amount, Date, Seller) -> Exists
        
        # å»ºç«‹ç´¢å¼•
        for _, row in self.df.iterrows():
            # 1. ç´¢å¼•å·ç 
            p_num = str(row.get('å‘ç¥¨å·ç ', '')).strip()
            p_amt = float(row.get('ä»·ç¨åˆè®¡', 0))
            p_date = str(row.get('å¼€ç¥¨æ—¥æœŸ', '')).strip()
            p_seller = str(row.get('é”€å”®æ–¹åç§°', '')).strip()
            
            if p_num and len(p_num) > 6: # å¿½ç•¥å¤ªçŸ­çš„å·ç 
                self.processed_nums[p_num] = {'amount': p_amt, 'date': p_date}
            
            # 2. ç´¢å¼•å±æ€§ (é‡‘é¢+æ—¥æœŸ+é”€å”®æ–¹) - ç”¨äºæ— å·åŒ¹é…
            # é”€å”®æ–¹åªå–å‰4ä¸ªå­—ä½œä¸ºæ¨¡ç³ŠåŒ¹é…é”®ï¼Œé˜²æ­¢å…¬å¸åå…¨ç§°/ç®€ç§°å·®å¼‚
            short_seller = p_seller[:4] if len(p_seller) >=4 else p_seller
            attr_key = (f"{p_amt:.2f}", p_date, short_seller)
            self.processed_attrs[attr_key] = True

    def check(self, raw_info):
        """
        æ ¸å¯¹åŸå§‹æ–‡ä»¶æ˜¯å¦åœ¨å·²å¤„ç†åˆ—è¡¨ä¸­
        è¿”å›: (æ˜¯å¦é€šè¿‡, åŸå› )
        """
        raw_num = str(raw_info.get('num') or '').strip()
        raw_amt = float(raw_info.get('amount') or 0)
        raw_date = str(raw_info.get('date') or '').strip()
        raw_seller = str(raw_info.get('seller') or '').strip()
        
        # 1. ä¼˜å…ˆåŒ¹é…å‘ç¥¨å·ç  (å¼ºæ ¡éªŒ)
        if raw_num and len(raw_num) > 6:
            if raw_num in self.processed_nums:
                # è¿›ä¸€æ­¥æ ¸å¯¹é‡‘é¢ (å…è®¸ 0.1 è¯¯å·®)
                rec_amt = self.processed_nums[raw_num]['amount']
                if abs(rec_amt - raw_amt) < 0.1:
                    return True, "å·ç ä¸é‡‘é¢å®Œå…¨åŒ¹é…"
                else:
                    # å·ç å¯¹ä½†é‡‘é¢ä¸å¯¹ï¼Œä¾ç„¶ç®—"å·²å¤„ç†"ï¼Œä½†å€¼å¾—æ³¨æ„
                    # åœ¨æ ¸å¯¹"é—æ¼"çš„è¯­å¢ƒä¸‹ï¼Œåªè¦Excelé‡Œæœ‰è¿™ä¸ªå·ï¼Œå°±ä¸ç®—é—æ¼
                    return True, f"å·ç åŒ¹é…ä½†é‡‘é¢ä¸ä¸€è‡´ (Excel:{rec_amt} vs Raw:{raw_amt})"
        
        # 2. å¦‚æœæ²¡æœ‰å·ç æˆ–å·ç æ²¡åŒ¹é…ä¸Šï¼Œå°è¯•"æ— å·åŒ¹é…" (å…œåº•)
        # åªæœ‰å½“é‡‘é¢ > 0 æ—¶æ‰è¿›è¡Œæ­¤åŒ¹é…
        if raw_amt > 0:
            short_seller = raw_seller[:4] if len(raw_seller) >=4 else raw_seller
            attr_key = (f"{raw_amt:.2f}", raw_date, short_seller)
            if attr_key in self.processed_attrs:
                return True, "é‡‘é¢ã€æ—¥æœŸã€é”€å”®æ–¹åŒ¹é…"
                
            # æ”¾å®½æ¡ä»¶ï¼šåªåŒ¹é… é‡‘é¢ + æ—¥æœŸ (é˜²æ­¢é”€å”®æ–¹è¯†åˆ«å¤±è´¥)
            # ä½†ä¸ºäº†é˜²æ­¢æ’è½¦ï¼Œåªæœ‰å½“é‡‘é¢æ¯”è¾ƒ"ç‹¬ç‰¹"(å¸¦å°æ•°)æ—¶æ‰æ•¢è®¤
            if raw_amt % 1 != 0:
                for k in self.processed_attrs:
                    # k = (amt_str, date, seller)
                    if k[0] == f"{raw_amt:.2f}" and k[1] == raw_date:
                        return True, "é‡‘é¢ä¸æ—¥æœŸåŒ¹é…(å¿½ç•¥é”€å”®æ–¹)"

        # 3. ç¡®å®æ‰¾ä¸åˆ°
        return False, "æœªæ‰¾åˆ°åŒ¹é…é¡¹"

# ==========================================
# 4. ä¸»å¤„ç†æµç¨‹
# ==========================================

def run_process_pipeline(input_root_dir, output_dir):
    """å¤„ç†å¹¶è‡ªåŠ¨æ ¸å¯¹"""
    merged_dir = os.path.join(output_dir, 'Merged_PDFs')
    noxml_dir = os.path.join(output_dir, 'No_XML_PDFs')
    os.makedirs(merged_dir, exist_ok=True)
    os.makedirs(noxml_dir, exist_ok=True)

    # 1. æ‰«æä¸æ± åŒ–
    all_files = []
    for root, dirs, files in os.walk(input_root_dir):
        for f in files: all_files.append(os.path.join(root, f))
    
    xml_files = [f for f in all_files if f.lower().endswith('.xml')]
    pdf_files = [f for f in all_files if f.lower().endswith('.pdf')]
    
    trip_pool = []
    invoice_pdf_pool = []
    
    for pdf in pdf_files:
        try:
            with pdfplumber.open(pdf) as p:
                if not p.pages: continue
                text = normalize_text(p.pages[0].extract_text())
                amt = find_best_amount(text)
                folder = os.path.dirname(pdf)
                if is_trip_file(os.path.basename(pdf), text):
                    trip_pool.append({'path': pdf, 'amount': amt, 'folder': folder, 'used': False})
                else:
                    invoice_pdf_pool.append({'path': pdf, 'amount': amt, 'folder': folder})
        except: pass

    # 2. å¤„ç†æµç¨‹
    excel_rows = []
    idx = 1
    processed_files_map = set() # ä»…ç”¨äºå»é‡ï¼Œä¸ç”¨äºæ ¸å¯¹

    # A. XMLå¤„ç†
    for xml in xml_files:
        info = parse_xml_invoice_data(xml)
        if not info: continue
        processed_files_map.add(os.path.abspath(xml))
        
        row = {"åºå·": idx, "å‘ç¥¨å·ç ": info['num'], "å¼€ç¥¨æ—¥æœŸ": info['date'],
               "é”€å”®æ–¹åç§°": info['seller'], "ä»·ç¨åˆè®¡": info['amount'], "æ•°æ®æ¥æº": "XML", "æ–‡ä»¶å": os.path.basename(xml)}
        
        folder = os.path.dirname(xml)
        target_pdf = None
        # æ‰¾PDF
        cands = [p['path'] for p in invoice_pdf_pool if p['folder'] == folder]
        for p in cands:
            if os.path.splitext(os.path.basename(xml))[0] in os.path.basename(p) or (info['num'] and info['num'] in os.path.basename(p)):
                target_pdf = p; break
        
        if target_pdf:
            processed_files_map.add(os.path.abspath(target_pdf))
            # æ‰¾è¡Œç¨‹å•
            matched_trip = None
            for t in [x for x in trip_pool if x['folder'] == folder and not x['used']]:
                if abs(t['amount'] - info['amount']) < 0.05:
                    matched_trip = t; t['used'] = True; break
            
            if matched_trip:
                try:
                    merger = PdfWriter()
                    merger.append(target_pdf); merger.append(matched_trip['path'])
                    safe_name = f"{info['num']}_{info['amount']}.pdf".replace(':','').replace('/','_')
                    merger.write(os.path.join(merged_dir, safe_name)); merger.close()
                    row['å¤‡æ³¨'] = "å·²åˆå¹¶è¡Œç¨‹å•"
                except:
                    shutil.copy2(target_pdf, os.path.join(noxml_dir, os.path.basename(target_pdf)))
                    row['å¤‡æ³¨'] = "åˆå¹¶å¤±è´¥-ä¿ç•™åŸä»¶"
            else:
                shutil.copy2(target_pdf, os.path.join(noxml_dir, os.path.basename(target_pdf)))
                row['å¤‡æ³¨'] = "æ­£å¸¸(æ— è¡Œç¨‹å•)"
        else:
             row['å¤‡æ³¨'] = "ä»…XML(ç¼ºPDF)"
        
        excel_rows.append(row); idx += 1

    # B. PDFå¤„ç†
    for inv in invoice_pdf_pool:
        if os.path.abspath(inv['path']) in processed_files_map: continue
        data = extract_data_from_pdf_simple(inv['path'])
        if not data: continue # æ— æ³•è¯†åˆ«çš„æ–‡ä»¶æš‚ä¸è¿›è¡¨ï¼Œä¾é æ ¸å¯¹ç¯èŠ‚æå›
        
        # æ‰¾è¡Œç¨‹å•
        matched_trip = None
        folder = inv['folder']
        for t in [x for x in trip_pool if x['folder'] == folder and not x['used']]:
            if inv['amount'] > 0 and abs(t['amount'] - inv['amount']) < 0.05:
                matched_trip = t; t['used'] = True; break
        
        if matched_trip:
            try:
                merger = PdfWriter()
                merger.append(inv['path']); merger.append(matched_trip['path'])
                num = data.get('å‘ç¥¨å·ç ', 'NoNum')
                safe_name = f"{num}_{inv['amount']}.pdf".replace(':','').replace('/','_')
                merger.write(os.path.join(merged_dir, safe_name)); merger.close()
                data['å¤‡æ³¨'] = "å·²åˆå¹¶è¡Œç¨‹å•"
                if data['ä»·ç¨åˆè®¡'] == 0: data['ä»·ç¨åˆè®¡'] = inv['amount']
            except:
                shutil.copy2(inv['path'], os.path.join(noxml_dir, os.path.basename(inv['path'])))
                data['å¤‡æ³¨'] = "åˆå¹¶å¤±è´¥-ä¿ç•™åŸä»¶"
        else:
            shutil.copy2(inv['path'], os.path.join(noxml_dir, os.path.basename(inv['path'])))
            data['å¤‡æ³¨'] = "æ­£å¸¸(æ— XML)"
            
        data['åºå·'] = idx; excel_rows.append(data); idx += 1

    # C. ç”Ÿæˆ Excel
    excel_path = None
    df_result = pd.DataFrame()
    if excel_rows:
        df_result = pd.DataFrame(excel_rows)
        cols = ["åºå·", "å‘ç¥¨å·ç ", "å¼€ç¥¨æ—¥æœŸ", "é”€å”®æ–¹åç§°", "ä»·ç¨åˆè®¡", "æ•°æ®æ¥æº", "å¤‡æ³¨", "æ–‡ä»¶å"]
        for c in cols: 
            if c not in df_result.columns: df_result[c] = ""
        df_result = df_result[cols]
        df_result['ä»·ç¨åˆè®¡'] = pd.to_numeric(df_result['ä»·ç¨åˆè®¡'], errors='coerce').fillna(0.0)
        
        # ä¿å­˜ç”¨äºæ ¸å¯¹
        df_final = df_result.copy() 
        
        # æ·»åŠ æ€»è®¡è¡Œ (åªä¸ºäº†å±•ç¤ºï¼Œæ ¸å¯¹æ—¶ä¸åŒ…å«)
        sum_row = {"åºå·": "æ€»è®¡", "ä»·ç¨åˆè®¡": df_result['ä»·ç¨åˆè®¡'].sum(), "é”€å”®æ–¹åç§°": f"å…± {len(df_result)} å¼ "}
        df_display = pd.concat([df_result, pd.DataFrame([sum_row])], ignore_index=True)
        excel_path = os.path.join(output_dir, 'Summary_Final.xlsx')
        df_display.to_excel(excel_path, index=False)
    
    # 3. --- è‡ªåŠ¨æ ¸å¯¹ç¯èŠ‚ (Auto Verification) ---
    missing_files = []
    
    if not df_result.empty:
        verifier = InvoiceVerifier(df_result) # åŸºäºç»“æœå»ºç«‹ç´¢å¼•
        
        # éå†æ‰€æœ‰åŸå§‹æ–‡ä»¶è¿›è¡Œæ ¸å¯¹
        for f in all_files:
            if not f.lower().endswith(('.pdf', '.xml')): continue
            
            # æå–åŸå§‹æ–‡ä»¶ç‰¹å¾
            raw_info = {}
            try:
                if f.lower().endswith('.xml'):
                    raw_info = parse_xml_invoice_data(f)
                else:
                    # å¯¹äºPDFï¼Œå¦‚æœå®ƒæ˜¯è¢«ç”¨æ‰çš„è¡Œç¨‹å•ï¼Œæˆ‘ä»¬æš‚æ—¶ä¸è§†ä¸ºé—æ¼
                    # ä½†ä¸ºäº†ä¸¥è°¨ï¼Œæˆ‘ä»¬æ£€æŸ¥å®ƒæ˜¯å¦åœ¨ Excel æˆ–è¢«æ ‡è®°ä¸ºè¡Œç¨‹å•
                    # ç®€åŒ–é€»è¾‘ï¼šå°è¯•ä½œä¸ºå‘ç¥¨æå–
                    raw_info = extract_data_from_pdf_simple(f)
                    # å¦‚æœæå–å¤±è´¥(å¦‚æ‰«æä»¶)ï¼Œraw_info ä¸º None
            except: pass
            
            # åˆ¤å®šé€»è¾‘
            is_missing = False
            
            if not raw_info:
                # æ— æ³•è§£æçš„æ–‡ä»¶ï¼Œè§†ä¸ºé—æ¼ (å¯èƒ½æ˜¯åæ–‡ä»¶æˆ–çº¯å›¾)
                is_missing = True
            else:
                # æ£€æŸ¥æ˜¯å¦åœ¨ç»“æœä¸­
                found, reason = verifier.check({
                    'num': raw_info.get('num') or raw_info.get('å‘ç¥¨å·ç '),
                    'amount': raw_info.get('amount') or raw_info.get('ä»·ç¨åˆè®¡'),
                    'date': raw_info.get('date') or raw_info.get('å¼€ç¥¨æ—¥æœŸ'),
                    'seller': raw_info.get('seller') or raw_info.get('é”€å”®æ–¹åç§°')
                })
                
                if not found:
                    # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œå†ç»™ä¸€æ¬¡æœºä¼šï¼šæ˜¯ä¸æ˜¯è¡Œç¨‹å•ï¼Ÿ
                    # å¦‚æœæ˜¯è¡Œç¨‹å•ï¼Œä¸”åœ¨ Excel å¤‡æ³¨é‡Œæœ‰ "å·²åˆå¹¶è¡Œç¨‹å•" çš„è®°å½•ï¼Œæˆ‘ä»¬å¾ˆéš¾ä¸€ä¸€å¯¹åº”
                    # æ‰€ä»¥ç­–ç•¥æ˜¯ï¼šåªæŠ¥å‘Š "é—æ¼çš„å‘ç¥¨"ã€‚è¡Œç¨‹å•å¦‚æœæ²¡åŒ¹é…ä¸Šï¼Œä¹Ÿæ˜¯ä¸€ç§é—æ¼ã€‚
                    # è¿™é‡Œç›´æ¥åˆ¤å®šä¸ºé—æ¼ã€‚
                     is_missing = True
            
            if is_missing:
                # æ’é™¤æ‰ç¡®å®æ˜¯è¡Œç¨‹å•ä¸”è¢«ç¨‹åºå†…éƒ¨æ¶ˆåŒ–çš„æƒ…å†µï¼Ÿ
                # ç°åœ¨çš„é€»è¾‘æ›´ä¸¥æ ¼ï¼šåªè¦ Excel é‡Œæ‰¾ä¸åˆ°è¿™ä¸ªå·/é‡‘é¢ï¼Œå°±ç®—é—æ¼ã€‚
                # è¿™ä¼šæŠŠæœªåˆå¹¶çš„è¡Œç¨‹å•ä¹Ÿç®—ä½œé—æ¼ï¼ˆè¿™æ˜¯å¥½äº‹ï¼Œç”¨æˆ·éœ€è¦çŸ¥é“å“ªäº›è¡Œç¨‹å•æ²¡ç”¨ä¸Šï¼‰
                missing_files.append(f)

    return excel_path, merged_dir, noxml_dir, missing_files

# ==========================================
# 5. æ‰‹åŠ¨æ ¸å¯¹ (å¤ç”¨ Verifier)
# ==========================================

def run_manual_check(raw_dir, proc_zip_path, out_dir):
    # 1. è§£å‹å¹¶è¯»å– Excel
    df_proc = pd.DataFrame()
    with zipfile.ZipFile(proc_zip_path, 'r') as z:
        # ä¼˜å…ˆæ‰¾ Excel
        xls = [n for n in z.namelist() if n.endswith('.xlsx')]
        if xls:
            with z.open(xls[0]) as f:
                df_proc = pd.read_excel(f)
        else:
            # æ²¡æœ‰ Excelï¼Œå›é€€åˆ°æ–‡ä»¶åè§£æ (æ—§é€»è¾‘å…¼å®¹)
            rows = []
            for n in z.namelist():
                if n.endswith('.pdf'):
                    base = os.path.basename(n)
                    # å°è¯•ä»æ–‡ä»¶åæå– num, amount
                    m = re.match(r'(\d+)_([\d\.]+)\.pdf', base)
                    if m:
                        rows.append({'å‘ç¥¨å·ç ': m.group(1), 'ä»·ç¨åˆè®¡': float(m.group(2))})
            df_proc = pd.DataFrame(rows)

    verifier = InvoiceVerifier(df_proc)
    
    # 2. éå†åŸå§‹æ–‡ä»¶
    missing = []
    matched_count = 0
    
    for root, _, files in os.walk(raw_dir):
        for f in files:
            if not f.lower().endswith(('.pdf', '.xml')): continue
            fp = os.path.join(root, f)
            
            raw_info = {}
            try:
                if f.lower().endsWith('.xml'): raw_info = parse_xml_invoice_data(fp)
                else: raw_info = extract_data_from_pdf_simple(fp)
            except: pass
            
            if not raw_info:
                missing.append(fp)
                continue
                
            found, _ = verifier.check({
                'num': raw_info.get('num') or raw_info.get('å‘ç¥¨å·ç '),
                'amount': raw_info.get('amount') or raw_info.get('ä»·ç¨åˆè®¡'),
                'date': raw_info.get('date') or raw_info.get('å¼€ç¥¨æ—¥æœŸ'),
                'seller': raw_info.get('seller') or raw_info.get('é”€å”®æ–¹åç§°')
            })
            
            if found: matched_count += 1
            else: missing.append(fp)
            
    # æ‰“åŒ…
    zip_p = None
    if missing:
        zip_p = os.path.join(out_dir, "Manual_Missing.zip")
        with zipfile.ZipFile(zip_p, 'w', zipfile.ZIP_DEFLATED) as z:
            for m in missing: z.write(m, os.path.basename(m))
            
    return matched_count, len(missing), zip_p

# ==========================================
# 6. Streamlit ä¸»ç•Œé¢
# ==========================================

def main():
    st.set_page_config(page_title="å‘ç¥¨æ— å¿§ V11 (ç²¾å‡†æ ¸å¯¹ç‰ˆ)", layout="wide")
    st.title("ğŸ§¾ å‘ç¥¨æ— å¿§ V11 (é«˜ç²¾åº¦è‡ªåŠ¨æ ¸å¯¹)")

    tab1, tab2 = st.tabs(["ğŸš€ ä¸€é”®å¤„ç†+æ ¸å¯¹", "ğŸ” æ‰‹åŠ¨å¤æ ¸"])

    # --- Tab 1 ---
    with tab1:
        st.info("ä¸Šä¼  ZIP/æ–‡ä»¶å¤¹ -> å¤„ç† -> è‡ªåŠ¨æ¯”å¯¹ç»“æœ -> å¯¼å‡ºé—æ¼æ–‡ä»¶")
        uploaded_files = st.file_uploader("ä¸Šä¼ æ–‡ä»¶", type=['zip', 'xml', 'pdf'], accept_multiple_files=True, key="u1")

        if uploaded_files and st.button("å¼€å§‹å¤„ç†", key="b1"):
            with st.spinner('æ­£åœ¨å¤„ç†å¹¶è¿›è¡Œå…¨é‡æ ¸å¯¹...'):
                with tempfile.TemporaryDirectory() as temp_dir:
                    input_root = os.path.join(temp_dir, "input")
                    os.makedirs(input_root, exist_ok=True)
                    
                    for i, up in enumerate(uploaded_files):
                        scope_dir = os.path.join(input_root, f"scope_{i}")
                        os.makedirs(scope_dir, exist_ok=True)
                        save_path = os.path.join(scope_dir, up.name)
                        with open(save_path, "wb") as f: f.write(up.getbuffer())
                        if up.name.endswith('.zip'):
                            extract_zip_with_encoding(save_path, scope_dir)
                            os.remove(save_path)
                    
                    out_dir = os.path.join(temp_dir, "output")
                    excel, merged, noxml, missing_list = run_process_pipeline(input_root, out_dir)
                    
                    st.success("âœ… å¤„ç†å®Œæˆï¼")
                    c1, c2 = st.columns(2)
                    
                    if excel:
                        df = pd.read_excel(excel)
                        c1.metric("å·²å½•å…¥å‘ç¥¨", f"{len(df)-1} å¼ ")
                        st.dataframe(df.tail(3))
                        
                        # ä¸‹è½½ç»“æœ
                        res_zip = os.path.join(temp_dir, "Result.zip")
                        with zipfile.ZipFile(res_zip, 'w', zipfile.ZIP_DEFLATED) as z:
                            z.write(excel, "æ±‡æ€»è¡¨.xlsx")
                            for r, _, fs in os.walk(merged):
                                for f in fs: z.write(os.path.join(r, f), f"åˆå¹¶åå‘ç¥¨/{f}")
                            for r, _, fs in os.walk(noxml):
                                for f in fs: z.write(os.path.join(r, f), f"ç‹¬ç«‹å‘ç¥¨/{f}")
                        with open(res_zip, "rb") as f:
                            st.download_button("ğŸ“¥ ä¸‹è½½ç»“æœåŒ… (Result.zip)", f, "Result.zip")

                    # é—æ¼æŠ¥å‘Š
                    c2.metric("é—æ¼æ–‡ä»¶ (å«æ— æ•ˆ/æœªåŒ¹é…)", f"{len(missing_list)} ä¸ª", delta_color="inverse")
                    if missing_list:
                        st.error("æ£€æµ‹åˆ°é—æ¼æ–‡ä»¶ï¼(å·²æ‰“åŒ…ï¼ŒåŒ…å«åæ–‡ä»¶ã€æ‰«æä»¶æˆ–æœªåŒ¹é…çš„è¡Œç¨‹å•)")
                        m_zip = os.path.join(temp_dir, "Missing.zip")
                        with zipfile.ZipFile(m_zip, 'w', zipfile.ZIP_DEFLATED) as z:
                            for m in missing_list: z.write(m, f"é—æ¼æ–‡ä»¶/{os.path.basename(m)}")
                        with open(m_zip, "rb") as f:
                            st.download_button("ğŸ“¥ ä¸‹è½½é—æ¼åŒ… (Missing.zip)", f, "Missing.zip", type="primary")

    # --- Tab 2 ---
    with tab2:
        st.write("ç”¨ã€Excel æ•°æ®ã€‘åå‘æ ¸å¯¹åŸå§‹æ–‡ä»¶ï¼Œç²¾åº¦æ›´é«˜ã€‚")
        c1, c2 = st.columns(2)
        raw_ups = c1.file_uploader("1. ä¸Šä¼ åŸå§‹å‘ç¥¨", type=['zip','pdf'], accept_multiple_files=True, key="u2")
        proc_zip = c2.file_uploader("2. ä¸Šä¼  Result.zip", type=['zip'], key="u3")
        
        if raw_ups and proc_zip and st.button("å¼€å§‹æ ¸å¯¹", key="b2"):
            with st.spinner("æ­£åœ¨è§£å‹æ¯”å¯¹..."):
                with tempfile.TemporaryDirectory() as td:
                    raw_d = os.path.join(td, "raw")
                    os.makedirs(raw_d, exist_ok=True)
                    for up in raw_ups:
                        p = os.path.join(raw_d, up.name)
                        with open(p, "wb") as f: f.write(up.getbuffer())
                        if p.endswith('.zip'): extract_zip_with_encoding(p, raw_d)
                    
                    pz = os.path.join(td, "proc.zip")
                    with open(pz, "wb") as f: f.write(proc_zip.getbuffer())
                    
                    match, miss, mzip = run_manual_check(raw_d, pz, td)
                    st.metric("âœ… åŒ¹é…æˆåŠŸ", match)
                    st.metric("âŒ é—æ¼/æœªå½•å…¥", miss)
                    if mzip:
                        with open(mzip, "rb") as f:
                            st.download_button("ğŸ“¥ ä¸‹è½½é—æ¼æ–‡ä»¶", f, "Manual_Missing.zip")

if __name__ == "__main__":
    main()