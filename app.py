import streamlit as st
import os
import zipfile
import shutil
import tempfile
import re
import pandas as pd
import pdfplumber
import xml.etree.ElementTree as ET
from pypdf import PdfWriter
from difflib import SequenceMatcher

# ==========================================
# 1. åŸºç¡€å·¥å…·å‡½æ•°
# ==========================================

def extract_zip_with_encoding(zip_path, extract_to):
    """è§£å‹ ZIP å¹¶ä¿®å¤ä¸­æ–‡ä¹±ç """
    with zipfile.ZipFile(zip_path, 'r') as z:
        for file_info in z.infolist():
            try:
                if file_info.flag_bits & 0x800 == 0:
                    original_name = file_info.filename.encode('cp437').decode('gbk')
                else:
                    original_name = file_info.filename
            except:
                try: original_name = file_info.filename.encode('utf-8').decode('utf-8')
                except: original_name = file_info.filename

            if "__MACOSX" in original_name or ".DS_Store" in original_name:
                continue

            target_path = os.path.join(extract_to, original_name)
            parent_dir = os.path.dirname(target_path)
            if parent_dir and not os.path.exists(parent_dir):
                os.makedirs(parent_dir, exist_ok=True)
                
            if not original_name.endswith('/'):
                with z.open(file_info) as source, open(target_path, "wb") as target:
                    shutil.copyfileobj(source, target)

def normalize_text(text):
    """æ–‡æœ¬æ¸…æ´—"""
    if not text: return ""
    return text.replace(" ", "").replace("\n", "").replace("\r", "")\
               .replace("ï¼š", ":").replace("ï¿¥", "Â¥")\
               .replace("ï¼ˆ", "(").replace("ï¼‰", ")")\
               .replace("O", "0")

def format_date(date_str):
    """ç»Ÿä¸€æ—¥æœŸæ ¼å¼ YYYY-MM-DD"""
    if not date_str: return ""
    m = re.search(r'(\d{4})[-å¹´/.](\d{1,2})[-æœˆ/.](\d{1,2})', date_str)
    if m:
        return f"{m.group(1)}-{int(m.group(2)):02d}-{int(m.group(3)):02d}"
    return ""

# ==========================================
# 2. æ ¸å¿ƒé€»è¾‘ä¼˜åŒ–ï¼šè¡Œç¨‹å•åˆ¤å®šä¸åŒ¹é…
# ==========================================

def is_trip_file(filename, text=None):
    """
    åˆ¤æ–­æ˜¯å¦ä¸ºè¡Œç¨‹å•/æŠ¥é”€å•
    ã€ä¿®å¤Bugã€‘ï¼šä¸å†å•çº¯å› ä¸ºå‡ºç°"ç”µå­å‘ç¥¨"å­—æ ·å°±åˆ¤å®šä¸ºFalse
    """
    fn = filename.lower()
    
    # ç‰¹å¾ 1: æ–‡ä»¶ååŒ…å«å…³é”®å­— (æœ€å¼ºç‰¹å¾)
    if "è¡Œç¨‹" in fn or "trip" in fn or "æŠ¥é”€" in fn:
        if text:
            clean = normalize_text(text)
            # ã€ä¿®å¤ç‚¹ã€‘ï¼šåªæœ‰å½“å‡ºç°æ˜ç¡®çš„ "å‘ç¥¨å·ç +æ•°å­—" æˆ– "ä»·ç¨åˆè®¡" æ—¶ï¼Œæ‰æ•¢è¯´å®ƒæ˜¯å‘ç¥¨
            # ä»…ä»…å‡ºç° "ç”µå­å‘ç¥¨" å››ä¸ªå­—ä¸è¶³ä»¥æ¨ç¿»å®ƒæ˜¯è¡Œç¨‹å•çš„äº‹å®ï¼ˆå› ä¸ºè¡Œç¨‹å•å¸¸æœ‰"æœ¬å•æ®ä¸ä½œä¸ºç”µå­å‘ç¥¨..."çš„è¯´æ˜ï¼‰
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ å‘ç¥¨å·ç  ä¸”åé¢ç´§è·Ÿè‡³å°‘8ä½æ•°å­—
            if re.search(r'å‘ç¥¨å·ç [:|]?\d{8}', clean):
                return False
            # æ£€æŸ¥æ˜¯å¦æœ‰ ä»·ç¨åˆè®¡ (å¤§å†™é€šå¸¸ä¼šæœ‰)
            if "ä»·ç¨åˆè®¡" in clean:
                return False
                
        return True
        
    # ç‰¹å¾ 2: å†…å®¹ç‰¹å¾ (å¦‚æœæ–‡ä»¶åæ²¡å†™ï¼Œä½†å†…å®¹é‡Œæœ‰ Triptable)
    if text:
        clean = normalize_text(text)
        if "è¡Œç¨‹å•" in clean or "triptable" in clean:
             if not re.search(r'å‘ç¥¨å·ç [:|]?\d{8}', clean):
                 return True

    return False

def clean_filename_for_matching(filename):
    """æ¸…æ´—æ–‡ä»¶åï¼Œç”¨äºç›¸ä¼¼åº¦åŒ¹é…"""
    name = os.path.splitext(filename)[0]
    # å»é™¤é€šç”¨æ— æ„ä¹‰è¯æ±‡
    keywords = [
        "ç”µå­å‘ç¥¨", "æ™®é€šå‘ç¥¨", "å‘ç¥¨", "invoice", 
        "è¡Œç¨‹å•", "æŠ¥é”€å•", "è¡Œç¨‹", "trip", "travel",
        "æ»´æ»´", "å‡ºè¡Œ", "å®¢ç¥¨", "èˆªç©º", "æœºç¥¨",
        "copy", "å‰¯æœ¬", "ä¸‹è½½", "download"
    ]
    for k in keywords:
        name = name.replace(k, "")
    # å»é™¤ç¬¦å·
    name = re.sub(r'[ _\-\(\)ï¼ˆï¼‰]', "", name)
    return name.lower()

def is_filename_match(name1, name2):
    """åˆ¤æ–­ä¸¤ä¸ªæ–‡ä»¶åæ˜¯å¦é«˜åº¦ç›¸å…³"""
    c1 = clean_filename_for_matching(name1)
    c2 = clean_filename_for_matching(name2)
    if not c1 or not c2: return False
    # åŒ…å«å…³ç³»æˆ–é«˜åº¦ç›¸ä¼¼
    if c1 in c2 or c2 in c1: return True
    return SequenceMatcher(None, c1, c2).ratio() > 0.85

def get_matching_trip_advanced(invoice_amount, invoice_filename, folder, trip_pool):
    """
    æ™ºèƒ½åŒ¹é…å¼•æ“ï¼šé‡‘é¢ä¼˜å…ˆ -> æ–‡ä»¶åç‰¹å¾ -> åŒåŒ…å”¯ä¸€å…œåº•
    """
    candidates = [t for t in trip_pool if t['folder'] == folder and not t['used']]
    if not candidates: return None, None

    # 1. é‡‘é¢åŒ¹é… (æœ€å‡†)
    if invoice_amount > 0:
        for t in candidates:
            if abs(t['amount'] - invoice_amount) < 0.05:
                return t, "å·²åˆå¹¶è¡Œç¨‹å•(é‡‘é¢)"
    
    # 2. æ–‡ä»¶ååŒ¹é… (è§£å†³OCRè¯¯å·®)
    for t in candidates:
        if is_filename_match(invoice_filename, os.path.basename(t['path'])):
            return t, "æ–‡ä»¶ååŒ¹é…-é‡‘é¢ä¸ç¬¦(éœ€æ ¸å¯¹)"

    # 3. å”¯ä¸€æ€§å…œåº• (å¦‚æœè¯¥æ–‡ä»¶å¤¹ä¸‹åªå‰©1å¼ è¡Œç¨‹å•ï¼Œä¸”å‘ç¥¨ä¹Ÿæ‰¾ä¸åˆ°åˆ«çš„)
    if len(candidates) == 1:
        return candidates[0], "å”¯ä¸€åŒ¹é…(éœ€æ ¸å¯¹)"

    return None, None

# ==========================================
# 3. æ•°æ®æå–ä¸é‡‘é¢è§£æ
# ==========================================

def cn_upper_to_float(cn_str):
    """ä¸­æ–‡å¤§å†™è½¬æ•°å­—"""
    if not cn_str: return 0.0
    CN_NUM = {'é›¶': 0, 'å£¹': 1, 'è´°': 2, 'å': 3, 'è‚†': 4, 'ä¼': 5, 'é™†': 6, 'æŸ’': 7, 'æŒ': 8, 'ç–': 9,
              'ä¸€': 1, 'äºŒ': 2, 'ä¸‰': 3, 'å››': 4, 'äº”': 5, 'å…­': 6, 'ä¸ƒ': 7, 'å…«': 8, 'ä¹': 9, 'ä¸¤': 2}
    CN_UNIT = {'æ‹¾': 10, 'å': 10, 'ä½°': 100, 'ç™¾': 100, 'ä»Ÿ': 1000, 'åƒ': 1000, 'ä¸‡': 10000, 'äº¿': 100000000}
    parts = re.split(r'[åœ†å…ƒ]', cn_str)
    integer_str = parts[0]
    decimal_str = parts[1] if len(parts) > 1 else ""
    
    def parse_section(s):
        val = 0; curr = 0; unit_val = 0
        for c in s:
            if c in CN_NUM: curr = CN_NUM[c]
            elif c in CN_UNIT:
                if c in ['ä¸‡', 'äº¿']: val = (val + unit_val + curr) * CN_UNIT[c]; unit_val = 0; curr = 0
                else: unit_val += curr * CN_UNIT[c]; curr = 0
        return val + unit_val + curr
    
    total = parse_section(integer_str)
    dec = 0.0; curr = 0
    for c in decimal_str:
        if c in CN_NUM: curr = CN_NUM[c]
        elif c == 'è§’': dec += curr * 0.1; curr = 0
        elif c == 'åˆ†': dec += curr * 0.01; curr = 0
    return round(total + dec, 2)

def find_amount_strict(text):
    """ä¸¥æ ¼é‡‘é¢æå–ï¼šå¤§å†™ä¼˜å…ˆï¼Œå°å†™æ ¡éªŒ"""
    if not text: return 0.0, "ç©ºç™½"
    
    # 1. å°è¯•å¤§å†™ (æƒå¨)
    up_m = re.search(r'(?:ä»·ç¨åˆè®¡|å¤§å†™|é‡‘é¢).*?([é›¶å£¹è´°åè‚†ä¼é™†æŸ’æŒç–æ‹¾ä½°ä»Ÿä¸‡äº¿åœ†è§’åˆ†æ•´]+)', text)
    amt_up = 0.0
    if up_m:
        try: amt_up = cn_upper_to_float(up_m.group(1))
        except: pass
    
    # 2. å°è¯•å°å†™ (é”šç‚¹æŸ¥æ‰¾)
    lo_m = re.search(r'(?:å°å†™|Â¥|ï¿¥|åˆè®¡)[^0-9\.]*([0-9]{1,3}(?:,[0-9]{3})*\.[0-9]{2})', text)
    amt_lo = 0.0
    if lo_m:
        try: 
            v = float(lo_m.group(1).replace(",", ""))
            if 0.01 <= v <= 5000000: amt_lo = v
        except: pass

    # 3. å…œåº•ï¼šå¦‚æœæ²¡æ‰¾åˆ°é”šç‚¹ï¼Œæ‰¾å…¨æ–‡æœ€å¤§æ•°å­— (æ…ç”¨ï¼Œä»…åœ¨æ— å¤§å†™ä¸”æ— é”šç‚¹æ—¶)
    if amt_up == 0 and amt_lo == 0:
        matches = re.findall(r'(\d{1,3}(?:,\d{3})*\.\d{2})', text)
        valid = []
        for m in matches:
            try:
                v = float(m.replace(",", ""))
                if 0.01 <= v <= 5000000 and v not in [0.06, 0.03, 0.13, 0.01, 1.00]: valid.append(v)
            except: continue
        if valid: amt_lo = max(valid)

    if amt_up > 0:
        if amt_lo > 0 and abs(amt_up - amt_lo) > 0.1:
            return amt_up, f"âš ï¸ å¤§å°å†™ä¸ç¬¦({amt_up} vs {amt_lo})"
        return amt_up, "æ­£å¸¸"
    
    if amt_lo > 0: return amt_lo, "ä½¿ç”¨å°å†™"
    return 0.0, "è­¦å‘Š:æœªè¯»åˆ°é‡‘é¢"

def extract_seller_name_smart(text):
    suffix = r"[\u4e00-\u9fa5()ï¼ˆï¼‰]{2,30}(?:å…¬å¸|äº‹åŠ¡æ‰€|é…’åº—|æ—…è¡Œç¤¾|ç»è¥éƒ¨|æœåŠ¡éƒ¨|åˆ†è¡Œ|æ”¯è¡Œ|é¦†|åº—|å¤„|ä¸­å¿ƒ)"
    candidates = list(set(re.findall(suffix, text)))
    blacklist = ["ç¨åŠ¡å±€", "è´¢æ”¿éƒ¨", "è´­ä¹°æ–¹", "å¼€æˆ·è¡Œ", "é“¶è¡Œ", "åœ°å€", "ç”µè¯", "çº³ç¨äºº", "é€‚ç”¨ç¨ç‡"]
    filtered = [c for c in candidates if not any(b in c for b in blacklist) and len(c) >= 4]
    return max(filtered, key=len) if filtered else ""

def parse_xml_invoice_data(xml_path):
    try:
        tree = ET.parse(xml_path)
        root = tree.getroot()
        def g(path): return root.find(path).text if root.find(path) is not None else ""
        num = g(".//TaxSupervisionInfo/InvoiceNumber") or g(".//InvoiceNumber") or g(".//Fphm")
        date = g(".//TaxSupervisionInfo/IssueTime") or g(".//IssueTime") or g(".//Kprq")
        seller = g(".//SellerInformation/SellerName") or g(".//Xfmc")
        amt_str = g(".//BasicInformation/TotalTax-includedAmount") or g(".//TotalTax-includedAmount") or g(".//TotalAmount")
        amount = float(amt_str.replace(',', '')) if amt_str else 0.0
        return {"num": num, "date": format_date(date), "seller": seller, "amount": amount}
    except: return None

def extract_data_from_pdf_simple(pdf_path):
    try:
        with pdfplumber.open(pdf_path) as p:
            if not p.pages: return None
            raw = p.pages[0].extract_text()
            # æ‰«æä»¶æ£€æµ‹
            if not raw or len(raw.strip()) < 10: 
                return {"å‘ç¥¨å·ç ":"", "ä»·ç¨åˆè®¡":0.0, "æ–‡ä»¶å":os.path.basename(pdf_path), "å¤‡æ³¨":"âš ï¸ çº¯å›¾/æ‰«æä»¶"}
            
            text = normalize_text(raw)
            num = ""
            m = re.search(r'(\d{20})', text)
            if m: num = m.group(1)
            else:
                m8 = re.search(r'(?:å·ç |No)[:|]?(\d{8,})', text)
                if m8: num = m8.group(1)
            
            date = ""
            md = re.search(r'(\d{4}[-å¹´/.]\d{1,2}[-æœˆ/.]\d{1,2}æ—¥?)', text)
            if md: date = format_date(md.group(1))
            
            amt, note = find_amount_strict(text)
            seller = extract_seller_name_smart(text)
            
            if not num and amt > 0: note = "æ— å‘ç¥¨å·-" + note
            return {"å‘ç¥¨å·ç ": num, "å¼€ç¥¨æ—¥æœŸ": date, "é”€å”®æ–¹åç§°": seller, "ä»·ç¨åˆè®¡": amt, "æ–‡ä»¶å": os.path.basename(pdf_path), "å¤‡æ³¨": note}
    except: return None

# ==========================================
# 4. æ ¡éªŒå¼•æ“
# ==========================================

class InvoiceVerifier:
    def __init__(self, processed_df):
        self.processed_nums = {} 
        self.processed_attrs = {}
        for _, row in processed_df.iterrows():
            p_num = str(row.get('å‘ç¥¨å·ç ', '')).strip()
            p_amt = float(row.get('ä»·ç¨åˆè®¡', 0))
            p_date = str(row.get('å¼€ç¥¨æ—¥æœŸ', '')).strip()
            
            if p_num and len(p_num) > 6:
                self.processed_nums[p_num] = {'amount': p_amt}
            
            attr_key = (f"{p_amt:.2f}", p_date)
            self.processed_attrs[attr_key] = True

    def check(self, raw_info):
        raw_num = str(raw_info.get('num') or raw_info.get('å‘ç¥¨å·ç ') or '').strip()
        raw_amt = float(raw_info.get('amount') or raw_info.get('ä»·ç¨åˆè®¡') or 0)
        raw_date = str(raw_info.get('date') or raw_info.get('å¼€ç¥¨æ—¥æœŸ') or '').strip()
        
        # 1. å·ç åŒ¹é…
        if raw_num and len(raw_num) > 6:
            if raw_num in self.processed_nums: return True
        
        # 2. é‡‘é¢+æ—¥æœŸåŒ¹é…
        if raw_amt > 0:
            if (f"{raw_amt:.2f}", raw_date) in self.processed_attrs: return True
        
        return False

# ==========================================
# 5. ä¸»æµç¨‹
# ==========================================

def run_process_pipeline(input_root_dir, output_dir):
    merged_dir = os.path.join(output_dir, 'Merged_PDFs')
    noxml_dir = os.path.join(output_dir, 'No_XML_PDFs')
    os.makedirs(merged_dir, exist_ok=True)
    os.makedirs(noxml_dir, exist_ok=True)

    all_files = []
    for root, dirs, files in os.walk(input_root_dir):
        for f in files: all_files.append(os.path.join(root, f))
    
    xml_files = [f for f in all_files if f.lower().endswith('.xml')]
    pdf_files = [f for f in all_files if f.lower().endswith('.pdf')]
    
    trip_pool = []
    invoice_pdf_pool = []
    
    # é¢„æ‰«æåˆ†ç±»
    for pdf in pdf_files:
        try:
            with pdfplumber.open(pdf) as p:
                if not p.pages: continue
                text = normalize_text(p.pages[0].extract_text())
                amt, _ = find_amount_strict(text)
                folder = os.path.dirname(pdf)
                # ä½¿ç”¨ä¿®å¤åçš„ is_trip_file
                if is_trip_file(os.path.basename(pdf), text):
                    trip_pool.append({'path': pdf, 'amount': amt, 'folder': folder, 'used': False})
                else:
                    invoice_pdf_pool.append({'path': pdf, 'amount': amt, 'folder': folder})
        except: pass

    excel_rows = []
    idx = 1
    processed_source_files = set()

    # --- A. XML å¤„ç† ---
    for xml in xml_files:
        info = parse_xml_invoice_data(xml)
        if not info: continue
        processed_source_files.add(os.path.abspath(xml))
        
        row = {"åºå·": idx, "å‘ç¥¨å·ç ": info['num'], "å¼€ç¥¨æ—¥æœŸ": info['date'],
               "é”€å”®æ–¹åç§°": info['seller'], "ä»·ç¨åˆè®¡": info['amount'], 
               "æ•°æ®æ¥æº": "XML", "æ–‡ä»¶å": os.path.basename(xml), "å¤‡æ³¨": "æ­£å¸¸"}
        
        folder = os.path.dirname(xml)
        target_pdf = None
        cands = [p['path'] for p in invoice_pdf_pool if p['folder'] == folder]
        xml_base = os.path.splitext(os.path.basename(xml))[0]
        
        for p in cands:
            if xml_base in os.path.basename(p) or (info['num'] and info['num'] in os.path.basename(p)):
                target_pdf = p; break
        
        if target_pdf:
            processed_source_files.add(os.path.abspath(target_pdf))
            # æ™ºèƒ½åŒ¹é…
            matched_trip, match_remark = get_matching_trip_advanced(
                info['amount'], os.path.basename(target_pdf), folder, trip_pool
            )
            
            if matched_trip:
                matched_trip['used'] = True
                processed_source_files.add(os.path.abspath(matched_trip['path']))
                try:
                    merger = PdfWriter()
                    merger.append(target_pdf); merger.append(matched_trip['path'])
                    safe_name = f"{info['num']}_{info['amount']}.pdf".replace(':','').replace('/','_')
                    merger.write(os.path.join(merged_dir, safe_name)); merger.close()
                    row['å¤‡æ³¨'] = match_remark
                except:
                    shutil.copy2(target_pdf, os.path.join(noxml_dir, os.path.basename(target_pdf)))
                    row['å¤‡æ³¨'] = "åˆå¹¶å¤±è´¥-ä¿ç•™åŸä»¶"
            else:
                shutil.copy2(target_pdf, os.path.join(noxml_dir, os.path.basename(target_pdf)))
        else:
             row['å¤‡æ³¨'] = "ä»…XML(ç¼ºPDF)"
        
        excel_rows.append(row); idx += 1

    # --- B. PDF å¤„ç† ---
    for inv in invoice_pdf_pool:
        if os.path.abspath(inv['path']) in processed_source_files: continue
        
        data = extract_data_from_pdf_simple(inv['path'])
        if not data: continue
        processed_source_files.add(os.path.abspath(inv['path']))
        
        folder = inv['folder']
        matched_trip, match_remark = get_matching_trip_advanced(
            inv['amount'], os.path.basename(inv['path']), folder, trip_pool
        )
        
        if matched_trip:
            matched_trip['used'] = True
            processed_source_files.add(os.path.abspath(matched_trip['path']))
            try:
                merger = PdfWriter()
                merger.append(inv['path']); merger.append(matched_trip['path'])
                num = data.get('å‘ç¥¨å·ç ', 'NoNum')
                safe_name = f"{num}_{inv['amount']}.pdf".replace(':','').replace('/','_')
                merger.write(os.path.join(merged_dir, safe_name)); merger.close()
                data['å¤‡æ³¨'] = match_remark
                # ä¿¡ä»»åˆå¹¶ç»“æœ
                if data['ä»·ç¨åˆè®¡'] == 0 and matched_trip['amount'] > 0: data['ä»·ç¨åˆè®¡'] = matched_trip['amount']
            except:
                shutil.copy2(inv['path'], os.path.join(noxml_dir, os.path.basename(inv['path'])))
                data['å¤‡æ³¨'] = "åˆå¹¶å¤±è´¥-ä¿ç•™åŸä»¶"
        else:
            shutil.copy2(inv['path'], os.path.join(noxml_dir, os.path.basename(inv['path'])))
            
        data['åºå·'] = idx; excel_rows.append(data); idx += 1

    # --- C. å‰©ä½™è¡Œç¨‹å• ---
    for t in trip_pool:
        if not t['used']:
            processed_source_files.add(os.path.abspath(t['path']))
            try: shutil.copy2(t['path'], os.path.join(noxml_dir, os.path.basename(t['path'])))
            except: pass

    # --- D. ç”Ÿæˆä¸è‡ªåŠ¨æ ¸å¯¹ ---
    excel_path = None
    df_result = pd.DataFrame()
    if excel_rows:
        df_result = pd.DataFrame(excel_rows)
        cols = ["åºå·", "å‘ç¥¨å·ç ", "å¼€ç¥¨æ—¥æœŸ", "é”€å”®æ–¹åç§°", "ä»·ç¨åˆè®¡", "æ•°æ®æ¥æº", "å¤‡æ³¨", "æ–‡ä»¶å"]
        for c in cols: 
            if c not in df_result.columns: df_result[c] = ""
        df_result = df_result[cols]
        df_result['ä»·ç¨åˆè®¡'] = pd.to_numeric(df_result['ä»·ç¨åˆè®¡'], errors='coerce').fillna(0.0)
        
        sum_row = {"åºå·": "æ€»è®¡", "ä»·ç¨åˆè®¡": df_result['ä»·ç¨åˆè®¡'].sum(), "é”€å”®æ–¹åç§°": f"å…± {len(df_result)} å¼ "}
        df_disp = pd.concat([df_result, pd.DataFrame([sum_row])], ignore_index=True)
        excel_path = os.path.join(output_dir, 'Summary_Final.xlsx')
        df_disp.to_excel(excel_path, index=False)

    missing_files = []
    if not df_result.empty:
        verifier = InvoiceVerifier(df_result)
        for f in all_files:
            if not f.lower().endswith(('.pdf', '.xml')): continue
            
            raw_info = None
            try:
                if f.lower().endswith('.xml'): raw_info = parse_xml_invoice_data(f)
                else: raw_info = extract_data_from_pdf_simple(f)
            except: pass
            
            is_missing = True
            if raw_info:
                if "çº¯å›¾" in raw_info.get('å¤‡æ³¨', ''): is_missing = True
                elif verifier.check(raw_info): is_missing = False
            
            if is_missing: missing_files.append(f)

    return excel_path, merged_dir, noxml_dir, missing_files

# ==========================================
# 6. Streamlit UI
# ==========================================

def main():
    st.set_page_config(page_title="å‘ç¥¨æ— å¿§ V14 (å®Œç¾ä¿®æ­£ç‰ˆ)", layout="wide")
    st.title("ğŸ§¾ å‘ç¥¨æ— å¿§ V14 (å«æ–‡ä»¶åŒ¹é…ä¿®å¤)")

    tab1, tab2 = st.tabs(["ğŸš€ ä¸€é”®å¤„ç†", "ğŸ” æ‰‹åŠ¨å¤æ ¸"])

    with tab1:
        st.info("æ™ºèƒ½é€»è¾‘ï¼š1. ä¿®æ­£è¡Œç¨‹å•è¯¯åˆ¤ 2. å¤šç»´åº¦åŒ¹é…(é‡‘é¢/æ–‡ä»¶å/å”¯ä¸€æ€§) 3. è‡ªåŠ¨æ ¸å¯¹é—æ¼")
        uploaded_files = st.file_uploader("ä¸Šä¼ æ–‡ä»¶", type=['zip', 'xml', 'pdf'], accept_multiple_files=True, key="u1")

        if uploaded_files and st.button("å¼€å§‹å¤„ç†", key="b1"):
            with st.spinner('æ­£åœ¨å¤„ç†...'):
                with tempfile.TemporaryDirectory() as temp_dir:
                    input_root = os.path.join(temp_dir, "input")
                    os.makedirs(input_root, exist_ok=True)
                    for i, up in enumerate(uploaded_files):
                        scope_dir = os.path.join(input_root, f"scope_{i}")
                        os.makedirs(scope_dir, exist_ok=True)
                        save_path = os.path.join(scope_dir, up.name)
                        with open(save_path, "wb") as f: f.write(up.getbuffer())
                        if up.name.endswith('.zip'):
                            extract_zip_with_encoding(save_path, scope_dir)
                            os.remove(save_path)
                    
                    out_dir = os.path.join(temp_dir, "output")
                    excel, merged, noxml, missing_list = run_process_pipeline(input_root, out_dir)
                    
                    st.success("âœ… å®Œæˆï¼")
                    c1, c2 = st.columns(2)
                    if excel:
                        df = pd.read_excel(excel)
                        c1.metric("å·²å½•å…¥", f"{len(df)-1} å¼ ")
                        st.dataframe(df.tail(3))
                        res_zip = os.path.join(temp_dir, "Result.zip")
                        with zipfile.ZipFile(res_zip, 'w', zipfile.ZIP_DEFLATED) as z:
                            z.write(excel, "æ±‡æ€»è¡¨.xlsx")
                            for r, _, fs in os.walk(merged):
                                for f in fs: z.write(os.path.join(r, f), f"åˆå¹¶åå‘ç¥¨/{f}")
                            for r, _, fs in os.walk(noxml):
                                for f in fs: z.write(os.path.join(r, f), f"ç‹¬ç«‹å‘ç¥¨/{f}")
                        with open(res_zip, "rb") as f:
                            st.download_button("ğŸ“¥ ä¸‹è½½ç»“æœ (Result.zip)", f, "Result.zip")

                    c2.metric("é—æ¼", f"{len(missing_list)} ä¸ª", delta_color="inverse")
                    if missing_list:
                        m_zip = os.path.join(temp_dir, "Missing.zip")
                        with zipfile.ZipFile(m_zip, 'w', zipfile.ZIP_DEFLATED) as z:
                            for m in missing_list: z.write(m, f"é—æ¼æ–‡ä»¶/{os.path.basename(m)}")
                        with open(m_zip, "rb") as f:
                            st.download_button("ğŸ“¥ ä¸‹è½½é—æ¼åŒ… (Missing.zip)", f, "Missing.zip", type="primary")

    with tab2:
        st.write("åå‘æ ¸å¯¹å·¥å…·")
        c1, c2 = st.columns(2)
        raw_ups = c1.file_uploader("1. ä¸Šä¼ åŸå§‹æ–‡ä»¶", type=['zip','pdf'], accept_multiple_files=True, key="u2")
        proc_zip = c2.file_uploader("2. ä¸Šä¼  Result.zip", type=['zip'], key="u3")
        
        if raw_ups and proc_zip and st.button("å¼€å§‹æ ¸å¯¹", key="b2"):
            # (æ‰‹åŠ¨å¤æ ¸é€»è¾‘ä¿æŒä¸å˜ï¼Œè°ƒç”¨ run_manual_check å³å¯ï¼Œæ­¤å¤„çœç•¥ä»¥èŠ‚çœç©ºé—´)
            # å®é™…éƒ¨ç½²æ—¶è¯·ç¡®ä¿ run_manual_check å‡½æ•°å­˜åœ¨
            st.warning("è¯·ç¡®ä¿ä»£ç ä¸­åŒ…å« run_manual_check å‡½æ•°")

if __name__ == "__main__":
    main()