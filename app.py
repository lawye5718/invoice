import streamlit as st
import os
import zipfile
import shutil
import tempfile
import re
import pandas as pd
import pdfplumber
import xml.etree.ElementTree as ET
from pypdf import PdfWriter
from difflib import SequenceMatcher

# ==========================================
# 1. åŸºç¡€å·¥å…·å‡½æ•°
# ==========================================

def extract_zip_with_encoding(zip_path, extract_to):
    """è§£å‹ ZIP å¹¶ä¿®å¤ä¸­æ–‡ä¹±ç """
    with zipfile.ZipFile(zip_path, 'r') as z:
        for file_info in z.infolist():
            try:
                if file_info.flag_bits & 0x800 == 0:
                    original_name = file_info.filename.encode('cp437').decode('gbk')
                else:
                    original_name = file_info.filename
            except:
                try: original_name = file_info.filename.encode('utf-8').decode('utf-8')
                except: original_name = file_info.filename

            if "__MACOSX" in original_name or ".DS_Store" in original_name:
                continue

            target_path = os.path.join(extract_to, original_name)
            parent_dir = os.path.dirname(target_path)
            if parent_dir and not os.path.exists(parent_dir):
                os.makedirs(parent_dir, exist_ok=True)
                
            if not original_name.endswith('/'):
                with z.open(file_info) as source, open(target_path, "wb") as target:
                    shutil.copyfileobj(source, target)

def normalize_text(text):
    """æ–‡æœ¬æ¸…æ´—"""
    if not text: return ""
    return text.replace(" ", "").replace("\n", "").replace("\r", "")\
               .replace("ï¼š", ":").replace("ï¿¥", "Â¥")\
               .replace("ï¼ˆ", "(").replace("ï¼‰", ")")\
               .replace("O", "0")

def format_date(date_str):
    """ç»Ÿä¸€æ—¥æœŸæ ¼å¼ YYYY-MM-DD"""
    if not date_str: return ""
    m = re.search(r'(\d{4})[-å¹´/.](\d{1,2})[-æœˆ/.](\d{1,2})', date_str)
    if m:
        return f"{m.group(1)}-{int(m.group(2)):02d}-{int(m.group(3)):02d}"
    return ""

# ==========================================
# 2. å¢å¼ºå‹åŒ¹é…é€»è¾‘ (é‡‘é¢ + æ–‡ä»¶å)
# ==========================================

def clean_filename_for_matching(filename):
    """
    æ¸…æ´—æ–‡ä»¶åï¼Œæå–æ ¸å¿ƒç‰¹å¾
    ä¾‹å¦‚: "æ»´æ»´ç”µå­å‘ç¥¨A (1).pdf" -> "A(1)"
    """
    # å»é™¤æ‰©å±•å
    name = os.path.splitext(filename)[0]
    # å»é™¤é€šç”¨å¹²æ‰°è¯
    keywords = [
        "ç”µå­å‘ç¥¨", "æ™®é€šå‘ç¥¨", "å‘ç¥¨", "invoice", 
        "è¡Œç¨‹å•", "æŠ¥é”€å•", "è¡Œç¨‹", "trip", "travel",
        "æ»´æ»´", "å‡ºè¡Œ", "å®¢ç¥¨", "èˆªç©º", "æœºç¥¨",
        "copy", "å‰¯æœ¬", "ä¸‹è½½", "download"
    ]
    for k in keywords:
        name = name.replace(k, "")
    
    # å»é™¤ç‰¹æ®Šç¬¦å·å’Œç©ºæ ¼
    name = re.sub(r'[ _\-\(\)ï¼ˆï¼‰]', "", name)
    return name.lower()

def is_filename_match(name1, name2):
    """
    åˆ¤æ–­ä¸¤ä¸ªæ–‡ä»¶åæ˜¯å¦é«˜åº¦ç›¸ä¼¼ï¼ˆç”¨äºåŒ¹é…è¡Œç¨‹å•ï¼‰
    """
    c1 = clean_filename_for_matching(name1)
    c2 = clean_filename_for_matching(name2)
    
    # å¦‚æœæ¸…æ´—åä¸ºç©ºï¼Œæ— æ³•åŒ¹é…
    if not c1 or not c2:
        return False
    
    # ç­–ç•¥1: åŒ…å«å…³ç³» (å¦‚ "Order123" å’Œ "TripOrder123")
    if c1 in c2 or c2 in c1:
        return True
    
    # ç­–ç•¥2: ç›¸ä¼¼åº¦åŒ¹é… (difflib)
    ratio = SequenceMatcher(None, c1, c2).ratio()
    return ratio > 0.85

def get_matching_trip_advanced(invoice_amount, invoice_filename, folder, trip_pool):
    """
    é«˜çº§åŒ¹é…å¼•æ“ï¼š
    1. ä¼˜å…ˆå°è¯•ã€é‡‘é¢ç²¾å‡†åŒ¹é…ã€‘
    2. å¤±è´¥åˆ™å°è¯•ã€æ–‡ä»¶åç‰¹å¾åŒ¹é…ã€‘
    3. å¤±è´¥åˆ™å°è¯•ã€åŒåŒ…å”¯ä¸€å…œåº•ã€‘(ä»…å½“è¯¥æ–‡ä»¶å¤¹ä¸‹åªå‰©1ä¸ªå¯ç”¨è¡Œç¨‹å•æ—¶)
    
    è¿”å›: (matched_trip, match_type_remark)
    """
    # 1. ç­›é€‰åŒ Scope (åŒæ–‡ä»¶å¤¹) ä¸‹æœªä½¿ç”¨çš„è¡Œç¨‹å•
    candidates = [t for t in trip_pool if t['folder'] == folder and not t['used']]
    
    if not candidates:
        return None, "æ— å¯ç”¨è¡Œç¨‹å•"

    # --- ç­–ç•¥ A: é‡‘é¢ç²¾å‡†åŒ¹é… (æœ€å®‰å…¨) ---
    # åªæœ‰å½“å‘ç¥¨é‡‘é¢æœ‰æ•ˆ (>0) æ—¶æ‰å°è¯•
    if invoice_amount > 0:
        for t in candidates:
            # å…è®¸ 0.05 å…ƒçš„è¯¯å·®
            if abs(t['amount'] - invoice_amount) < 0.05:
                return t, "å·²åˆå¹¶è¡Œç¨‹å•(é‡‘é¢)"
    
    # --- ç­–ç•¥ B: æ–‡ä»¶åç‰¹å¾åŒ¹é… (è§£å†³é‡‘é¢è¯»é”™/ä¸º0çš„æƒ…å†µ) ---
    # å¦‚æœé‡‘é¢åŒ¹é…å¤±è´¥ï¼Œæˆ–è€…å‘ç¥¨é‡‘é¢æœ¬èº«è¯»å‡ºæ¥æ˜¯0ï¼Œå°è¯•æ–‡ä»¶å
    for t in candidates:
        if is_filename_match(invoice_filename, os.path.basename(t['path'])):
            return t, "æ–‡ä»¶ååŒ¹é…-é‡‘é¢ä¸ç¬¦(éœ€æ ¸å¯¹)"

    # --- ç­–ç•¥ C: åŒåŒ…å”¯ä¸€æ€§å…œåº• (æ…ç”¨) ---
    # å¦‚æœå½“å‰æ–‡ä»¶å¤¹ä¸‹ï¼Œåªå‰©è¿™ä¸€ä¸ªè¡Œç¨‹å•æ²¡ç”¨è¿‡ï¼Œä¸”å½“å‰å‘ç¥¨ä¹Ÿæ²¡åŒ¹é…åˆ°åˆ«çš„
    # è¿™æ˜¯ä¸€ç§å¼ºå‡è®¾ï¼šä¸€ä¸ªåŒ…é‡Œçš„ä¸€å¼ å‘ç¥¨å’Œä¸€å¼ è¡Œç¨‹å•å¿…ç„¶æ˜¯ä¸€å¯¹
    if len(candidates) == 1:
        # è¿™é‡Œå¯ä»¥åŠ ä¸ªé™åˆ¶ï¼Œæ¯”å¦‚å‘ç¥¨æ€»æ•°ä¹Ÿåªæœ‰1ä¸ªï¼Ÿ
        # ç®€åŒ–å¤„ç†ï¼šæ ‡è®°ä¸º"å”¯ä¸€åŒ¹é…"ï¼Œæç¤ºç”¨æˆ·æ ¸å¯¹
        return candidates[0], "å”¯ä¸€åŒ¹é…(éœ€æ ¸å¯¹)"

    return None, None

# ==========================================
# 3. æ•°æ®æå–ä¸è§£æ
# ==========================================

def cn_upper_to_float(cn_str):
    """ä¸­æ–‡å¤§å†™è½¬æ•°å­—"""
    if not cn_str: return 0.0
    CN_NUM = {'é›¶': 0, 'å£¹': 1, 'è´°': 2, 'å': 3, 'è‚†': 4, 'ä¼': 5, 'é™†': 6, 'æŸ’': 7, 'æŒ': 8, 'ç–': 9,
              'ä¸€': 1, 'äºŒ': 2, 'ä¸‰': 3, 'å››': 4, 'äº”': 5, 'å…­': 6, 'ä¸ƒ': 7, 'å…«': 8, 'ä¹': 9, 'ä¸¤': 2}
    CN_UNIT = {'æ‹¾': 10, 'å': 10, 'ä½°': 100, 'ç™¾': 100, 'ä»Ÿ': 1000, 'åƒ': 1000, 'ä¸‡': 10000, 'äº¿': 100000000}
    parts = re.split(r'[åœ†å…ƒ]', cn_str)
    integer_str = parts[0]
    decimal_str = parts[1] if len(parts) > 1 else ""
    
    def parse_section(s):
        val = 0; curr = 0; unit_val = 0
        for c in s:
            if c in CN_NUM: curr = CN_NUM[c]
            elif c in CN_UNIT:
                if c in ['ä¸‡', 'äº¿']: val = (val + unit_val + curr) * CN_UNIT[c]; unit_val = 0; curr = 0
                else: unit_val += curr * CN_UNIT[c]; curr = 0
        return val + unit_val + curr
    
    total = parse_section(integer_str)
    dec = 0.0; curr = 0
    for c in decimal_str:
        if c in CN_NUM: curr = CN_NUM[c]
        elif c == 'è§’': dec += curr * 0.1; curr = 0
        elif c == 'åˆ†': dec += curr * 0.01; curr = 0
    return round(total + dec, 2)

def find_amount_strict(text):
    """æå–é‡‘é¢ (å¤§å†™ä¼˜å…ˆ)"""
    if not text: return 0.0, "ç©ºç™½"
    # å¤§å†™
    up_m = re.search(r'(?:ä»·ç¨åˆè®¡|å¤§å†™|é‡‘é¢).*?([é›¶å£¹è´°åè‚†ä¼é™†æŸ’æŒç–æ‹¾ä½°ä»Ÿä¸‡äº¿åœ†è§’åˆ†æ•´]+)', text)
    amt_up = 0.0
    if up_m:
        try: amt_up = cn_upper_to_float(up_m.group(1))
        except: pass
    
    # å°å†™
    lo_m = re.search(r'(?:å°å†™|Â¥|ï¿¥|åˆè®¡)[^0-9\.]*([0-9]{1,3}(?:,[0-9]{3})*\.[0-9]{2})', text)
    amt_lo = 0.0
    if lo_m:
        try: 
            v = float(lo_m.group(1).replace(",", ""))
            if 0.01 <= v <= 5000000: amt_lo = v
        except: pass

    if amt_up > 0:
        if amt_lo > 0 and abs(amt_up - amt_lo) > 0.1:
            return amt_up, f"âš ï¸ å¤§å°å†™ä¸ç¬¦({amt_up} vs {amt_lo})"
        return amt_up, "æ­£å¸¸"
    
    if amt_lo > 0: return amt_lo, "ä½¿ç”¨å°å†™"
    return 0.0, "è­¦å‘Š:æœªè¯»åˆ°é‡‘é¢"

def extract_seller_name_smart(text):
    suffix = r"[\u4e00-\u9fa5()ï¼ˆï¼‰]{2,30}(?:å…¬å¸|äº‹åŠ¡æ‰€|é…’åº—|æ—…è¡Œç¤¾|ç»è¥éƒ¨|æœåŠ¡éƒ¨|åˆ†è¡Œ|æ”¯è¡Œ|é¦†|åº—|å¤„|ä¸­å¿ƒ)"
    candidates = list(set(re.findall(suffix, text)))
    blacklist = ["ç¨åŠ¡å±€", "è´¢æ”¿éƒ¨", "è´­ä¹°æ–¹", "å¼€æˆ·è¡Œ", "é“¶è¡Œ", "åœ°å€", "ç”µè¯", "çº³ç¨äºº", "é€‚ç”¨ç¨ç‡"]
    filtered = [c for c in candidates if not any(b in c for b in blacklist) and len(c) >= 4]
    return max(filtered, key=len) if filtered else ""

def is_trip_file(filename, text=None):
    fn = filename.lower()
    if "è¡Œç¨‹" in fn or "trip" in fn or "æŠ¥é”€" in fn:
        if text:
            clean = normalize_text(text)
            if "å‘ç¥¨ä»£ç " in clean or "å‘ç¥¨å·ç " in clean or "ç”µå­å‘ç¥¨" in clean:
                return False
        return True
    return False

# ==========================================
# 4. è§£æå™¨å°è£…
# ==========================================

def parse_xml_invoice_data(xml_path):
    try:
        tree = ET.parse(xml_path)
        root = tree.getroot()
        def g(path): return root.find(path).text if root.find(path) is not None else ""
        num = g(".//TaxSupervisionInfo/InvoiceNumber") or g(".//InvoiceNumber") or g(".//Fphm")
        date = g(".//TaxSupervisionInfo/IssueTime") or g(".//IssueTime") or g(".//Kprq")
        seller = g(".//SellerInformation/SellerName") or g(".//Xfmc")
        amt_str = g(".//BasicInformation/TotalTax-includedAmount") or g(".//TotalTax-includedAmount") or g(".//TotalAmount")
        amount = float(amt_str.replace(',', '')) if amt_str else 0.0
        return {"num": num, "date": format_date(date), "seller": seller, "amount": amount}
    except: return None

def extract_data_from_pdf_simple(pdf_path):
    try:
        with pdfplumber.open(pdf_path) as p:
            if not p.pages: return None
            raw = p.pages[0].extract_text()
            if not raw or len(raw.strip()) < 10: 
                return {"å‘ç¥¨å·ç ":"", "ä»·ç¨åˆè®¡":0.0, "æ–‡ä»¶å":os.path.basename(pdf_path), "å¤‡æ³¨":"âš ï¸ çº¯å›¾/æ‰«æä»¶"}
            
            text = normalize_text(raw)
            num = ""
            m = re.search(r'(\d{20})', text)
            if m: num = m.group(1)
            else:
                m8 = re.search(r'(?:å·ç |No)[:|]?(\d{8,})', text)
                if m8: num = m8.group(1)
            
            date = ""
            md = re.search(r'(\d{4}[-å¹´/.]\d{1,2}[-æœˆ/.]\d{1,2}æ—¥?)', text)
            if md: date = format_date(md.group(1))
            
            amt, note = find_amount_strict(text)
            seller = extract_seller_name_smart(text)
            
            if not num and amt > 0: note = "æ— å‘ç¥¨å·-" + note
            return {"å‘ç¥¨å·ç ": num, "å¼€ç¥¨æ—¥æœŸ": date, "é”€å”®æ–¹åç§°": seller, "ä»·ç¨åˆè®¡": amt, "æ–‡ä»¶å": os.path.basename(pdf_path), "å¤‡æ³¨": note}
    except: return None

# ==========================================
# 5. æ ¡éªŒå¼•æ“ (Verifier)
# ==========================================

class InvoiceVerifier:
    def __init__(self, processed_df):
        self.processed_nums = {} 
        self.processed_attrs = {}
        for _, row in processed_df.iterrows():
            p_num = str(row.get('å‘ç¥¨å·ç ', '')).strip()
            p_amt = float(row.get('ä»·ç¨åˆè®¡', 0))
            p_date = str(row.get('å¼€ç¥¨æ—¥æœŸ', '')).strip()
            p_seller = str(row.get('é”€å”®æ–¹åç§°', '')).strip()
            
            if p_num and len(p_num) > 6:
                self.processed_nums[p_num] = {'amount': p_amt}
            
            short_seller = p_seller[:4] if len(p_seller) >=4 else p_seller
            attr_key = (f"{p_amt:.2f}", p_date, short_seller)
            self.processed_attrs[attr_key] = True

    def check(self, raw_info):
        raw_num = str(raw_info.get('num') or raw_info.get('å‘ç¥¨å·ç ') or '').strip()
        raw_amt = float(raw_info.get('amount') or raw_info.get('ä»·ç¨åˆè®¡') or 0)
        raw_date = str(raw_info.get('date') or raw_info.get('å¼€ç¥¨æ—¥æœŸ') or '').strip()
        raw_seller = str(raw_info.get('seller') or raw_info.get('é”€å”®æ–¹åç§°') or '').strip()
        
        # 1. å¼ºæ ¡éªŒ
        if raw_num and len(raw_num) > 6:
            if raw_num in self.processed_nums: return True
        
        # 2. å¼±æ ¡éªŒ
        if raw_amt > 0:
            short_seller = raw_seller[:4] if len(raw_seller) >=4 else raw_seller
            if (f"{raw_amt:.2f}", raw_date, short_seller) in self.processed_attrs: return True
            # 3. å…œåº•
            if raw_amt % 1 != 0:
                for k in self.processed_attrs:
                    if k[0] == f"{raw_amt:.2f}" and k[1] == raw_date: return True
        return False

# ==========================================
# 6. ä¸»æµç¨‹ (run_process_pipeline)
# ==========================================

def run_process_pipeline(input_root_dir, output_dir):
    merged_dir = os.path.join(output_dir, 'Merged_PDFs')
    noxml_dir = os.path.join(output_dir, 'No_XML_PDFs')
    os.makedirs(merged_dir, exist_ok=True)
    os.makedirs(noxml_dir, exist_ok=True)

    all_files = []
    for root, dirs, files in os.walk(input_root_dir):
        for f in files: all_files.append(os.path.join(root, f))
    
    xml_files = [f for f in all_files if f.lower().endswith('.xml')]
    pdf_files = [f for f in all_files if f.lower().endswith('.pdf')]
    
    # å»ºç«‹è¡Œç¨‹å•æ± 
    trip_pool = []
    invoice_pdf_pool = []
    
    for pdf in pdf_files:
        try:
            with pdfplumber.open(pdf) as p:
                if not p.pages: continue
                text = normalize_text(p.pages[0].extract_text())
                amt, _ = find_amount_strict(text)
                folder = os.path.dirname(pdf)
                if is_trip_file(os.path.basename(pdf), text):
                    trip_pool.append({'path': pdf, 'amount': amt, 'folder': folder, 'used': False})
                else:
                    invoice_pdf_pool.append({'path': pdf, 'amount': amt, 'folder': folder})
        except: pass

    excel_rows = []
    idx = 1
    processed_source_files = set()

    # --- A. XMLå¤„ç† ---
    for xml in xml_files:
        info = parse_xml_invoice_data(xml)
        if not info: continue
        processed_source_files.add(os.path.abspath(xml))
        
        row = {"åºå·": idx, "å‘ç¥¨å·ç ": info['num'], "å¼€ç¥¨æ—¥æœŸ": info['date'],
               "é”€å”®æ–¹åç§°": info['seller'], "ä»·ç¨åˆè®¡": info['amount'], 
               "æ•°æ®æ¥æº": "XML", "æ–‡ä»¶å": os.path.basename(xml), "å¤‡æ³¨": "æ­£å¸¸"}
        
        folder = os.path.dirname(xml)
        target_pdf = None
        cands = [p['path'] for p in invoice_pdf_pool if p['folder'] == folder]
        xml_base = os.path.splitext(os.path.basename(xml))[0]
        
        for p in cands:
            if xml_base in os.path.basename(p) or (info['num'] and info['num'] in os.path.basename(p)):
                target_pdf = p; break
        
        if target_pdf:
            processed_source_files.add(os.path.abspath(target_pdf))
            
            # === ä½¿ç”¨å¢å¼ºåŒ¹é…é€»è¾‘ ===
            matched_trip, match_remark = get_matching_trip_advanced(
                info['amount'], os.path.basename(target_pdf), folder, trip_pool
            )
            
            if matched_trip:
                matched_trip['used'] = True # æ ‡è®°ä½¿ç”¨
                processed_source_files.add(os.path.abspath(matched_trip['path']))
                try:
                    merger = PdfWriter()
                    merger.append(target_pdf); merger.append(matched_trip['path'])
                    safe_name = f"{info['num']}_{info['amount']}.pdf".replace(':','').replace('/','_')
                    merger.write(os.path.join(merged_dir, safe_name)); merger.close()
                    row['å¤‡æ³¨'] = match_remark
                except:
                    shutil.copy2(target_pdf, os.path.join(noxml_dir, os.path.basename(target_pdf)))
                    row['å¤‡æ³¨'] = "åˆå¹¶å¤±è´¥-ä¿ç•™åŸä»¶"
            else:
                shutil.copy2(target_pdf, os.path.join(noxml_dir, os.path.basename(target_pdf)))
        else:
             row['å¤‡æ³¨'] = "ä»…XML(ç¼ºPDF)"
        
        excel_rows.append(row); idx += 1

    # --- B. PDFå¤„ç† ---
    for inv in invoice_pdf_pool:
        if os.path.abspath(inv['path']) in processed_source_files: continue
        
        data = extract_data_from_pdf_simple(inv['path'])
        if not data: continue
        processed_source_files.add(os.path.abspath(inv['path']))
        
        folder = inv['folder']
        # === ä½¿ç”¨å¢å¼ºåŒ¹é…é€»è¾‘ ===
        matched_trip, match_remark = get_matching_trip_advanced(
            inv['amount'], os.path.basename(inv['path']), folder, trip_pool
        )
        
        if matched_trip:
            matched_trip['used'] = True
            processed_source_files.add(os.path.abspath(matched_trip['path']))
            try:
                merger = PdfWriter()
                merger.append(inv['path']); merger.append(matched_trip['path'])
                num = data.get('å‘ç¥¨å·ç ', 'NoNum')
                safe_name = f"{num}_{inv['amount']}.pdf".replace(':','').replace('/','_')
                merger.write(os.path.join(merged_dir, safe_name)); merger.close()
                data['å¤‡æ³¨'] = match_remark
                # å¦‚æœå‘ç¥¨é‡‘é¢æ˜¯0ï¼Œä¿¡ä»»åŒ¹é…åˆ°çš„è¡Œç¨‹å•çš„é‡‘é¢(å¦‚æœæœ‰)
                if data['ä»·ç¨åˆè®¡'] == 0 and matched_trip['amount'] > 0:
                     data['ä»·ç¨åˆè®¡'] = matched_trip['amount']
            except:
                shutil.copy2(inv['path'], os.path.join(noxml_dir, os.path.basename(inv['path'])))
                data['å¤‡æ³¨'] = "åˆå¹¶å¤±è´¥-ä¿ç•™åŸä»¶"
        else:
            shutil.copy2(inv['path'], os.path.join(noxml_dir, os.path.basename(inv['path'])))
            
        data['åºå·'] = idx; excel_rows.append(data); idx += 1

    # --- C. å‰©ä½™è¡Œç¨‹å• ---
    for t in trip_pool:
        if not t['used']:
            processed_source_files.add(os.path.abspath(t['path']))
            try: shutil.copy2(t['path'], os.path.join(noxml_dir, os.path.basename(t['path'])))
            except: pass

    # --- D. ç”Ÿæˆä¸æ ¸å¯¹ ---
    excel_path = None
    df_result = pd.DataFrame()
    if excel_rows:
        df_result = pd.DataFrame(excel_rows)
        cols = ["åºå·", "å‘ç¥¨å·ç ", "å¼€ç¥¨æ—¥æœŸ", "é”€å”®æ–¹åç§°", "ä»·ç¨åˆè®¡", "æ•°æ®æ¥æº", "å¤‡æ³¨", "æ–‡ä»¶å"]
        for c in cols: 
            if c not in df_result.columns: df_result[c] = ""
        df_result = df_result[cols]
        df_result['ä»·ç¨åˆè®¡'] = pd.to_numeric(df_result['ä»·ç¨åˆè®¡'], errors='coerce').fillna(0.0)
        
        sum_row = {"åºå·": "æ€»è®¡", "ä»·ç¨åˆè®¡": df_result['ä»·ç¨åˆè®¡'].sum(), "é”€å”®æ–¹åç§°": f"å…± {len(df_result)} å¼ "}
        df_disp = pd.concat([df_result, pd.DataFrame([sum_row])], ignore_index=True)
        excel_path = os.path.join(output_dir, 'Summary_Final.xlsx')
        df_disp.to_excel(excel_path, index=False)

    missing_files = []
    if not df_result.empty:
        verifier = InvoiceVerifier(df_result)
        for f in all_files:
            if not f.lower().endswith(('.pdf', '.xml')): continue
            raw_info = None
            try:
                if f.lower().endswith('.xml'): raw_info = parse_xml_invoice_data(f)
                else: raw_info = extract_data_from_pdf_simple(f)
            except: pass
            
            is_missing = True
            if raw_info:
                if "çº¯å›¾" in raw_info.get('å¤‡æ³¨', ''): is_missing = True
                elif verifier.check(raw_info): is_missing = False
            
            if is_missing: missing_files.append(f)

    return excel_path, merged_dir, noxml_dir, missing_files

# ==========================================
# 7. æ‰‹åŠ¨æ ¸å¯¹
# ==========================================

def run_manual_check(raw_dir, proc_zip_path, out_dir):
    df_proc = pd.DataFrame()
    with zipfile.ZipFile(proc_zip_path, 'r') as z:
        xls = [n for n in z.namelist() if n.endswith('.xlsx')]
        if xls:
            with z.open(xls[0]) as f: df_proc = pd.read_excel(f)
        else:
            rows = []
            for n in z.namelist():
                if n.endswith('.pdf'):
                    m = re.match(r'(\d+)_([\d\.]+)\.pdf', os.path.basename(n))
                    if m: rows.append({'å‘ç¥¨å·ç ': m.group(1), 'ä»·ç¨åˆè®¡': float(m.group(2))})
            df_proc = pd.DataFrame(rows)

    verifier = InvoiceVerifier(df_proc)
    missing = []
    matched_count = 0
    
    for root, _, files in os.walk(raw_dir):
        for f in files:
            if not f.lower().endswith(('.pdf', '.xml')): continue
            fp = os.path.join(root, f)
            raw_info = None
            try:
                if f.lower().endswith('.xml'): raw_info = parse_xml_invoice_data(fp)
                else: raw_info = extract_data_from_pdf_simple(fp)
            except: pass
            
            if raw_info and verifier.check(raw_info): matched_count += 1
            else: missing.append(fp)
    
    zip_p = None
    if missing:
        zip_p = os.path.join(out_dir, "Manual_Missing.zip")
        with zipfile.ZipFile(zip_p, 'w', zipfile.ZIP_DEFLATED) as z:
            for m in missing: z.write(m, os.path.basename(m))
            
    return matched_count, len(missing), zip_p

# ==========================================
# 8. Streamlit UI
# ==========================================

def main():
    st.set_page_config(page_title="å‘ç¥¨æ— å¿§ V13 (æ™ºèƒ½åŒ¹é…ç‰ˆ)", layout="wide")
    st.title("ğŸ§¾ å‘ç¥¨æ— å¿§ V13 (é‡‘é¢/æ–‡ä»¶ååŒé‡åŒ¹é…)")

    tab1, tab2 = st.tabs(["ğŸš€ ä¸€é”®å¤„ç†", "ğŸ” æ‰‹åŠ¨å¤æ ¸"])

    with tab1:
        st.info("æ™ºèƒ½åŒ¹é…ç­–ç•¥ï¼š1.é‡‘é¢ç²¾å‡†åŒ¹é… -> 2.æ–‡ä»¶åç‰¹å¾åŒ¹é… -> 3.åŒåŒ…å”¯ä¸€å…œåº•")
        uploaded_files = st.file_uploader("ä¸Šä¼ æ–‡ä»¶", type=['zip', 'xml', 'pdf'], accept_multiple_files=True, key="u1")

        if uploaded_files and st.button("å¼€å§‹å¤„ç†", key="b1"):
            with st.spinner('æ­£åœ¨å¤„ç†...'):
                with tempfile.TemporaryDirectory() as temp_dir:
                    input_root = os.path.join(temp_dir, "input")
                    os.makedirs(input_root, exist_ok=True)
                    for i, up in enumerate(uploaded_files):
                        scope_dir = os.path.join(input_root, f"scope_{i}")
                        os.makedirs(scope_dir, exist_ok=True)
                        save_path = os.path.join(scope_dir, up.name)
                        with open(save_path, "wb") as f: f.write(up.getbuffer())
                        if up.name.endswith('.zip'):
                            extract_zip_with_encoding(save_path, scope_dir)
                            os.remove(save_path)
                    
                    out_dir = os.path.join(temp_dir, "output")
                    excel, merged, noxml, missing_list = run_process_pipeline(input_root, out_dir)
                    
                    st.success("âœ… å®Œæˆï¼")
                    c1, c2 = st.columns(2)
                    if excel:
                        df = pd.read_excel(excel)
                        c1.metric("å·²å½•å…¥", f"{len(df)-1} å¼ ")
                        st.dataframe(df.tail(3))
                        res_zip = os.path.join(temp_dir, "Result.zip")
                        with zipfile.ZipFile(res_zip, 'w', zipfile.ZIP_DEFLATED) as z:
                            z.write(excel, "æ±‡æ€»è¡¨.xlsx")
                            for r, _, fs in os.walk(merged):
                                for f in fs: z.write(os.path.join(r, f), f"åˆå¹¶åå‘ç¥¨/{f}")
                            for r, _, fs in os.walk(noxml):
                                for f in fs: z.write(os.path.join(r, f), f"ç‹¬ç«‹å‘ç¥¨/{f}")
                        with open(res_zip, "rb") as f:
                            st.download_button("ğŸ“¥ ä¸‹è½½ç»“æœ (Result.zip)", f, "Result.zip")

                    c2.metric("é—æ¼", f"{len(missing_list)} ä¸ª", delta_color="inverse")
                    if missing_list:
                        m_zip = os.path.join(temp_dir, "Missing.zip")
                        with zipfile.ZipFile(m_zip, 'w', zipfile.ZIP_DEFLATED) as z:
                            for m in missing_list: z.write(m, f"é—æ¼æ–‡ä»¶/{os.path.basename(m)}")
                        with open(m_zip, "rb") as f:
                            st.download_button("ğŸ“¥ ä¸‹è½½é—æ¼åŒ… (Missing.zip)", f, "Missing.zip", type="primary")

    with tab2:
        st.write("åå‘æ ¸å¯¹ï¼šç”¨ Excel ç»“æœæ£€æŸ¥åŸå§‹æ–‡ä»¶æ˜¯å¦é—æ¼ã€‚")
        c1, c2 = st.columns(2)
        raw_ups = c1.file_uploader("1. ä¸Šä¼ åŸå§‹æ–‡ä»¶", type=['zip','pdf'], accept_multiple_files=True, key="u2")
        proc_zip = c2.file_uploader("2. ä¸Šä¼  Result.zip", type=['zip'], key="u3")
        
        if raw_ups and proc_zip and st.button("å¼€å§‹æ ¸å¯¹", key="b2"):
            with st.spinner("æ ¸å¯¹ä¸­..."):
                with tempfile.TemporaryDirectory() as td:
                    raw_d = os.path.join(td, "raw")
                    os.makedirs(raw_d, exist_ok=True)
                    for up in raw_ups:
                        p = os.path.join(raw_d, up.name)
                        with open(p, "wb") as f: f.write(up.getbuffer())
                        if p.endswith('.zip'): extract_zip_with_encoding(p, raw_d)
                    
                    pz = os.path.join(td, "proc.zip")
                    with open(pz, "wb") as f: f.write(proc_zip.getbuffer())
                    
                    match, miss, mzip = run_manual_check(raw_d, pz, td)
                    st.metric("âœ… åŒ¹é…æˆåŠŸ", match)
                    st.metric("âŒ é—æ¼", miss)
                    if mzip:
                        with open(mzip, "rb") as f:
                            st.download_button("ğŸ“¥ ä¸‹è½½é—æ¼æ–‡ä»¶", f, "Manual_Missing.zip")

if __name__ == "__main__":
    main()