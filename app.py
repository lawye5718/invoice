import streamlit as st
import os
import zipfile
import shutil
import tempfile
import re
import pandas as pd
import pdfplumber
import xml.etree.ElementTree as ET
from pypdf import PdfWriter

# ==========================================
# 1. åŸºç¡€å·¥å…·å‡½æ•°
# ==========================================

def extract_zip_with_encoding(zip_path, extract_to):
    """è§£å‹ ZIP å¹¶ä¿®å¤ä¸­æ–‡ä¹±ç """
    with zipfile.ZipFile(zip_path, 'r') as z:
        for file_info in z.infolist():
            try:
                if file_info.flag_bits & 0x800 == 0:
                    original_name = file_info.filename.encode('cp437').decode('gbk')
                else:
                    original_name = file_info.filename
            except:
                try: original_name = file_info.filename.encode('utf-8').decode('utf-8')
                except: original_name = file_info.filename

            if "__MACOSX" in original_name or ".DS_Store" in original_name:
                continue

            target_path = os.path.join(extract_to, original_name)
            parent_dir = os.path.dirname(target_path)
            if parent_dir and not os.path.exists(parent_dir):
                os.makedirs(parent_dir, exist_ok=True)
                
            if not original_name.endswith('/'):
                with z.open(file_info) as source, open(target_path, "wb") as target:
                    shutil.copyfileobj(source, target)

def normalize_text(text):
    """æ–‡æœ¬æ¸…æ´—ï¼šç»Ÿä¸€ç¬¦å·ï¼Œå»ç©ºæ ¼"""
    if not text: return ""
    return text.replace(" ", "").replace("\n", "").replace("\r", "")\
               .replace("ï¼š", ":").replace("ï¿¥", "Â¥")\
               .replace("ï¼ˆ", "(").replace("ï¼‰", ")")\
               .replace("O", "0") # å¸¸è§OCRé”™è¯¯ä¿®æ­£

def format_date(date_str):
    """ç»Ÿä¸€æ—¥æœŸæ ¼å¼ä¸º YYYY-MM-DD"""
    if not date_str: return ""
    # æ›¿æ¢å¸¸è§åˆ†éš”ç¬¦
    clean = re.sub(r'[å¹´/.]', '-', date_str).replace('æ—¥', '')
    return clean

# --- ğŸ¯ æ ¸å¿ƒå¢å¼ºï¼šåŒé‡ç­–ç•¥æå–é‡‘é¢ ---
def find_best_amount(text):
    """
    æ™ºèƒ½é‡‘é¢æå–ï¼š
    ç­–ç•¥A (é«˜ç½®ä¿¡åº¦): æŸ¥æ‰¾ "å°å†™"ã€"Â¥"ã€"ä»·ç¨åˆè®¡" åç´§è·Ÿçš„æ•°å­—
    ç­–ç•¥B (å…œåº•): æŸ¥æ‰¾å…¨æ–‡ä¸­æœ€å¤§çš„åˆè§„æ•°å­—
    """
    if not text: return 0.0

    # 1. ç­–ç•¥A: è¯­ä¹‰é”šç‚¹æŸ¥æ‰¾ (æœ€å‡†)
    # åŒ¹é…æ¨¡å¼: (å°å†™|ï¿¥|Â¥|åˆè®¡) åé¢è·Ÿéšç€æ•°å­—
    # ä¾‹å­: "å°å†™Â¥100.00", "åˆè®¡:100.00"
    anchor_pattern = r'(?:å°å†™|Â¥|ï¿¥|åˆè®¡|é‡‘é¢)[^0-9\.]*([0-9]{1,3}(?:,[0-9]{3})*\.[0-9]{2})'
    anchor_matches = re.findall(anchor_pattern, text)
    
    for m in anchor_matches:
        try:
            val = float(m.replace(",", ""))
            # ç®€å•æ ¡éªŒ
            if 0.01 <= val <= 5000000:
                return val
        except: continue

    # 2. ç­–ç•¥B: å…¨æ–‡æœç´¢æœ€å¤§å€¼ (å…œåº•)
    # åŒ¹é…æ‰€æœ‰å¸¦ä¸¤ä½å°æ•°çš„æ•°å­—
    matches = re.findall(r'(\d{1,3}(?:,\d{3})*\.\d{2})', text)
    valid_amounts = []
    for m in matches:
        try:
            val = float(m.replace(",", ""))
            # æ’é™¤å¹²æ‰°é¡¹: ç¨ç‡, æ•°é‡(1.00), å¸¸è§æ—¥æœŸç‰‡æ®µ(20.25)
            if 0.01 <= val <= 5000000 and val not in [0.06, 0.03, 0.13, 0.01, 1.00]:
                valid_amounts.append(val)
        except: continue
        
    return max(valid_amounts) if valid_amounts else 0.0

def extract_seller_name_smart(text):
    """æå–é”€å”®æ–¹"""
    suffix_pattern = r"[\u4e00-\u9fa5()ï¼ˆï¼‰]{2,30}(?:å…¬å¸|äº‹åŠ¡æ‰€|é…’åº—|æ—…è¡Œç¤¾|ç»è¥éƒ¨|æœåŠ¡éƒ¨|åˆ†è¡Œ|æ”¯è¡Œ|é¦†|åº—|å¤„|ä¸­å¿ƒ)"
    candidates = list(set(re.findall(suffix_pattern, text)))
    blacklist = ["ç¨åŠ¡å±€", "è´¢æ”¿éƒ¨", "è´­ä¹°æ–¹", "å¼€æˆ·è¡Œ", "é“¶è¡Œ", "åœ°å€", "ç”µè¯", "ç»Ÿä¸€ç¤¾ä¼šä¿¡ç”¨", "çº³ç¨äºº", "é€‚ç”¨ç¨ç‡", "å¯†ç åŒº", "æœºå™¨ç¼–å·"]
    filtered = [c for c in candidates if not any(b in c for b in blacklist) and len(c) >= 4]
    return max(filtered, key=len) if filtered else ""

def is_trip_file(filename, text=None):
    """åˆ¤æ–­æ˜¯å¦ä¸ºè¡Œç¨‹å•"""
    fn = filename.lower()
    if "è¡Œç¨‹" in fn or "trip" in fn or "æŠ¥é”€" in fn:
        if text:
            clean = normalize_text(text)
            # å¦‚æœå†…å®¹é‡Œæœ‰æ˜ç¡®å‘ç¥¨ç‰¹å¾ï¼Œåˆ™ä¸æ˜¯è¡Œç¨‹å•
            if "å‘ç¥¨ä»£ç " in clean or "å‘ç¥¨å·ç " in clean or "ç”µå­å‘ç¥¨" in clean:
                return False
        return True
    return False

# ==========================================
# 2. è§£æå‡½æ•° (XML & PDF)
# ==========================================

def parse_xml_invoice_data(xml_path):
    try:
        tree = ET.parse(xml_path)
        root = tree.getroot()
        def g(path):
            node = root.find(path)
            return node.text if node is not None else ""

        num = g(".//TaxSupervisionInfo/InvoiceNumber") or g(".//InvoiceNumber") or g(".//Fphm")
        date = g(".//TaxSupervisionInfo/IssueTime") or g(".//IssueTime") or g(".//Kprq")
        seller = g(".//SellerInformation/SellerName") or g(".//Xfmc")
        
        amt_str = g(".//BasicInformation/TotalTax-includedAmount") or g(".//TotalTax-includedAmount") or g(".//TotalAmount") or g(".//Jshj")
        # ä¿®å¤: ç§»é™¤é€—å·é˜²æ­¢ float æŠ¥é”™
        amount = float(amt_str.replace(',', '')) if amt_str else 0.0

        return {
            "num": num, 
            "date": format_date(date.split(' ')[0] if date else ""), # ä»…å–æ—¥æœŸéƒ¨åˆ†
            "seller": seller, 
            "amount": amount
        }
    except: return None

def extract_data_from_pdf_simple(pdf_path):
    """
    å¢å¼ºç‰ˆ PDF è§£æï¼šæ”¯æŒæ‰«æä»¶æ£€æµ‹
    """
    try:
        with pdfplumber.open(pdf_path) as p:
            if not p.pages: return None
            raw = p.pages[0].extract_text()
            
            # --- æ£€æµ‹: æ‰«æä»¶/çº¯å›¾ç‰‡ ---
            # å¦‚æœæå–å‡ºçš„å­—ç¬¦å¤ªå°‘(ä¾‹å¦‚å°‘äº10ä¸ªå­—)ï¼Œæå¤§å¯èƒ½æ˜¯æ‰«æä»¶
            if not raw or len(raw.strip()) < 10:
                return {
                    "å‘ç¥¨å·ç ": "", "å¼€ç¥¨æ—¥æœŸ": "", "é”€å”®æ–¹åç§°": "", "ä»·ç¨åˆè®¡": 0.0,
                    "æ•°æ®æ¥æº": "PDF(æœªè¯†åˆ«)", "æ–‡ä»¶å": os.path.basename(pdf_path),
                    "å¤‡æ³¨": "âš ï¸ çº¯å›¾/æ‰«æä»¶ï¼Œéœ€äººå·¥æ ¸å¯¹"
                }

            text = normalize_text(raw)
            
            # 1. å‘ç¥¨å·ç  (20ä½å…¨ç”µ æˆ– 8+ä½å¸¸è§„)
            num = ""
            m20 = re.search(r'(\d{20})', text)
            if m20: num = m20.group(1)
            else:
                m8 = re.search(r'(?:å·ç |No)[:|]?(\d{8,})', text)
                if m8: num = m8.group(1)
            
            # 2. æ—¥æœŸ (å…¼å®¹ YYYY-MM-DD, YYYY.MM.DD, YYYYå¹´MMæœˆDDæ—¥)
            date = ""
            md = re.search(r'(\d{4}[-å¹´/.]\d{1,2}[-æœˆ/.]\d{1,2}æ—¥?)', text)
            if md: date = format_date(md.group(1))
            
            # 3. é‡‘é¢ (ä½¿ç”¨å¢å¼ºç­–ç•¥)
            amt = find_best_amount(text)
            
            # 4. é”€å”®æ–¹
            seller = extract_seller_name_smart(text)
            
            status = "æ­£å¸¸"
            if amt == 0: status = "è­¦å‘Š:æœªè¯»åˆ°é‡‘é¢"
            elif not num: status = "è­¦å‘Š:æ— å‘ç¥¨å·"
            
            return {
                "å‘ç¥¨å·ç ": num, "å¼€ç¥¨æ—¥æœŸ": date, "é”€å”®æ–¹åç§°": seller,
                "ä»·ç¨åˆè®¡": amt, "æ•°æ®æ¥æº": "PDFè¯†åˆ«", "æ–‡ä»¶å": os.path.basename(pdf_path),
                "å¤‡æ³¨": status
            }
    except: return None

# ==========================================
# 3. æ ¸å¿ƒå¤„ç†æµç¨‹ (å«è‡ªåŠ¨æ ¸å¯¹)
# ==========================================

def run_process_pipeline(input_root_dir, output_dir):
    """
    æ‰§è¡Œå¤„ç†å¹¶åœ¨æœ€åè¿›è¡Œè‡ªåŠ¨æ ¸å¯¹
    è¿”å›: excelè·¯å¾„, åˆå¹¶æ–‡ä»¶å¤¹, ç‹¬ç«‹å‘ç¥¨æ–‡ä»¶å¤¹, é—æ¼æ–‡ä»¶åˆ—è¡¨
    """
    merged_pdf_dir = os.path.join(output_dir, 'Merged_PDFs')
    no_xml_pdf_dir = os.path.join(output_dir, 'No_XML_PDFs')
    os.makedirs(merged_pdf_dir, exist_ok=True)
    os.makedirs(no_xml_pdf_dir, exist_ok=True)

    # 1. æ‰«ææ‰€æœ‰æ–‡ä»¶
    all_files = []
    for root, dirs, files in os.walk(input_root_dir):
        for f in files: all_files.append(os.path.join(root, f))
    
    xml_files = [f for f in all_files if f.lower().endswith('.xml')]
    pdf_files = [f for f in all_files if f.lower().endswith('.pdf')]
    
    # 2. å»ºç«‹è¡Œç¨‹å•æ±  & å‘ç¥¨å€™é€‰æ±  (åŒºåˆ† Scope)
    trip_pool = []
    invoice_pdf_pool = []
    
    for pdf in pdf_files:
        try:
            with pdfplumber.open(pdf) as p:
                if not p.pages: continue
                # ç®€å•é¢„è¯»å–ï¼Œç”¨äºåˆ†ç±»
                raw_text = p.pages[0].extract_text()
                text = normalize_text(raw_text) if raw_text else ""
                
                # å³ä½¿æ˜¯ç©ºæ–‡æœ¬(æ‰«æä»¶)ï¼Œä¹Ÿå…ˆå°è¯•å¤„ç†ï¼Œä¸ç›´æ¥ä¸¢å¼ƒ
                amt = find_best_amount(text)
                folder = os.path.dirname(pdf)
                
                if is_trip_file(os.path.basename(pdf), text):
                    trip_pool.append({'path': pdf, 'amount': amt, 'folder': folder, 'used': False})
                else:
                    invoice_pdf_pool.append({'path': pdf, 'amount': amt, 'folder': folder})
        except: pass

    excel_rows = []
    idx = 1
    
    # ã€æ ¸å¯¹å…³é”®ã€‘è®°å½•å“ªäº›åŸå§‹æ–‡ä»¶è¢«æˆåŠŸä½¿ç”¨äº† (ä½¿ç”¨ç»å¯¹è·¯å¾„)
    processed_source_files = set()

    # --- é˜¶æ®µ A: XML å‘ç¥¨ ---
    for xml in xml_files:
        info = parse_xml_invoice_data(xml)
        if not info: continue
        
        # æ ‡è®° XML ä¸ºå·²å¤„ç†
        processed_source_files.add(os.path.abspath(xml))
        
        row = {
            "åºå·": idx, "å‘ç¥¨å·ç ": info['num'], "å¼€ç¥¨æ—¥æœŸ": info['date'],
            "é”€å”®æ–¹åç§°": info['seller'], "ä»·ç¨åˆè®¡": info['amount'], 
            "æ•°æ®æ¥æº": "XML", "æ–‡ä»¶å": os.path.basename(xml), "å¤‡æ³¨": "æ­£å¸¸"
        }
        
        # æ‰¾ PDF
        folder = os.path.dirname(xml)
        target_pdf = None
        
        # Scope åŒ¹é… (åŒç›®å½•ä¸‹)
        cands = [p['path'] for p in invoice_pdf_pool if p['folder'] == folder]
        xml_base = os.path.splitext(os.path.basename(xml))[0]
        
        for p in cands:
            # æ–‡ä»¶ååŒ…å« xmlå æˆ– å‘ç¥¨å·
            if xml_base in os.path.basename(p) or (info['num'] and info['num'] in os.path.basename(p)):
                target_pdf = p
                break
        
        if target_pdf:
            processed_source_files.add(os.path.abspath(target_pdf))
            
            # æ‰¾è¡Œç¨‹å•
            matched_trip = None
            trips = [t for t in trip_pool if t['folder'] == folder and not t['used']]
            for t in trips:
                # é‡‘é¢åŒ¹é…
                if abs(t['amount'] - info['amount']) < 0.05:
                    matched_trip = t
                    t['used'] = True
                    break
            
            if matched_trip:
                processed_source_files.add(os.path.abspath(matched_trip['path']))
                try:
                    merger = PdfWriter()
                    merger.append(target_pdf)
                    merger.append(matched_trip['path'])
                    safe_name = f"{info['num']}_{info['amount']}.pdf".replace(':','').replace('/','_')
                    merger.write(os.path.join(merged_pdf_dir, safe_name))
                    merger.close()
                    row['å¤‡æ³¨'] = "å·²åˆå¹¶è¡Œç¨‹å•"
                except:
                    # åˆå¹¶å¤±è´¥ï¼Œå¤åˆ¶åŸä»¶ä½œä¸ºå…œåº•
                    shutil.copy2(target_pdf, os.path.join(no_xml_pdf_dir, os.path.basename(target_pdf)))
                    row['å¤‡æ³¨'] = "åˆå¹¶å¤±è´¥-ä¿ç•™åŸä»¶"
            else:
                shutil.copy2(target_pdf, os.path.join(no_xml_pdf_dir, os.path.basename(target_pdf)))
        
        excel_rows.append(row)
        idx += 1

    # --- é˜¶æ®µ B: æ—  XML çš„ PDF ---
    for inv in invoice_pdf_pool:
        # å¦‚æœå·²ç»è¢« XML é˜¶æ®µå¤„ç†è¿‡ï¼Œè·³è¿‡
        if os.path.abspath(inv['path']) in processed_source_files: continue
        
        data = extract_data_from_pdf_simple(inv['path'])
        if not data: continue
        
        processed_source_files.add(os.path.abspath(inv['path']))
        
        matched_trip = None
        folder = inv['folder']
        trips = [t for t in trip_pool if t['folder'] == folder and not t['used']]
        for t in trips:
            if inv['amount'] > 0 and abs(t['amount'] - inv['amount']) < 0.05:
                matched_trip = t
                t['used'] = True
                break
        
        if matched_trip:
            processed_source_files.add(os.path.abspath(matched_trip['path']))
            try:
                merger = PdfWriter()
                merger.append(inv['path'])
                merger.append(matched_trip['path'])
                num = data.get('å‘ç¥¨å·ç ', 'NoNum')
                safe_name = f"{num}_{inv['amount']}.pdf".replace(':','').replace('/','_')
                merger.write(os.path.join(merged_pdf_dir, safe_name))
                merger.close()
                data['å¤‡æ³¨'] = "å·²åˆå¹¶è¡Œç¨‹å•"
                if data['ä»·ç¨åˆè®¡'] == 0: data['ä»·ç¨åˆè®¡'] = inv['amount']
            except:
                shutil.copy2(inv['path'], os.path.join(no_xml_pdf_dir, os.path.basename(inv['path'])))
                data['å¤‡æ³¨'] = "åˆå¹¶å¤±è´¥-ä¿ç•™åŸä»¶"
        else:
            shutil.copy2(inv['path'], os.path.join(no_xml_pdf_dir, os.path.basename(inv['path'])))
        
        data['åºå·'] = idx
        excel_rows.append(data)
        idx += 1

    # --- é˜¶æ®µ C: å‰©ä½™è¡Œç¨‹å• ---
    for t in trip_pool:
        if not t['used']:
            processed_source_files.add(os.path.abspath(t['path']))
            try: shutil.copy2(t['path'], os.path.join(no_xml_pdf_dir, os.path.basename(t['path'])))
            except: pass

    # --- é˜¶æ®µ D: è‡ªåŠ¨æ ¸å¯¹ (æ‰¾å‡ºé—æ¼æ–‡ä»¶) ---
    missing_files = []
    # è¿‡æ»¤åªæ£€æŸ¥ pdf å’Œ xml
    check_exts = ('.pdf', '.xml')
    for f in all_files:
        if f.lower().endswith(check_exts):
            # å¦‚æœæ–‡ä»¶çš„ç»å¯¹è·¯å¾„ä¸åœ¨å·²å¤„ç†é›†åˆä¸­
            if os.path.abspath(f) not in processed_source_files:
                missing_files.append(f)

    # ç”Ÿæˆ Excel
    excel_path = None
    if excel_rows:
        df = pd.DataFrame(excel_rows)
        cols = ["åºå·", "å‘ç¥¨å·ç ", "å¼€ç¥¨æ—¥æœŸ", "é”€å”®æ–¹åç§°", "ä»·ç¨åˆè®¡", "æ•°æ®æ¥æº", "å¤‡æ³¨", "æ–‡ä»¶å"]
        for c in cols: 
            if c not in df.columns: df[c] = ""
        df = df[cols]
        # å¼ºåˆ¶æ•°å€¼è½¬æ¢
        df['ä»·ç¨åˆè®¡'] = pd.to_numeric(df['ä»·ç¨åˆè®¡'], errors='coerce').fillna(0.0)
        sum_row = {"åºå·": "æ€»è®¡", "ä»·ç¨åˆè®¡": df['ä»·ç¨åˆè®¡'].sum(), "é”€å”®æ–¹åç§°": f"å…± {len(df)} å¼ "}
        df = pd.concat([df, pd.DataFrame([sum_row])], ignore_index=True)
        excel_path = os.path.join(output_dir, 'Summary_Final.xlsx')
        df.to_excel(excel_path, index=False)

    return excel_path, merged_pdf_dir, no_xml_pdf_dir, missing_files

# ==========================================
# 4. æ‰‹åŠ¨æ ¸å¯¹åŠŸèƒ½ (Tab 2)
# ==========================================
def run_manual_check(raw_dir, proc_zip_path, out_dir):
    """åŸºäºæ–‡ä»¶åçš„æ‰‹åŠ¨æ ¸å¯¹"""
    # 1. è¯»å–å·²å¤„ç†å‘ç¥¨å·
    processed_nums = set()
    with zipfile.ZipFile(proc_zip_path, 'r') as z:
        for n in z.namelist():
            base = os.path.basename(n)
            # æå–æ–‡ä»¶åä¸­çš„é•¿æ•°å­—
            m = re.search(r'(\d{8,})', base)
            if m: processed_nums.add(m.group(1))

    # 2. æ‰«æåŸå§‹æ–‡ä»¶
    missing = []
    matched_count = 0
    
    for root, _, files in os.walk(raw_dir):
        for f in files:
            if not f.lower().endswith(('.pdf', '.xml')): continue
            fp = os.path.join(root, f)
            
            # ç®€æ˜“æå–å‘ç¥¨å·
            num = None
            try:
                if f.endswith('.xml'):
                    info = parse_xml_invoice_data(fp)
                    if info: num = info['num']
                else:
                    data = extract_data_from_pdf_simple(fp)
                    if data: num = data['å‘ç¥¨å·ç ']
            except: pass
            
            if num and num in processed_nums:
                matched_count += 1
            else:
                # åªæœ‰å½“å®ƒæ˜¯å‘ç¥¨ä¸”æ²¡æ‰¾åˆ°æ—¶æ‰ç®—Missing
                # æˆ–æ˜¯è¡Œç¨‹å•ä¸”æ²¡æ‰¾åˆ°
                missing.append(fp)
    
    # æ‰“åŒ…
    zip_p = None
    if missing:
        zip_p = os.path.join(out_dir, "Manual_Missing.zip")
        with zipfile.ZipFile(zip_p, 'w', zipfile.ZIP_DEFLATED) as z:
            for m in missing: z.write(m, os.path.basename(m))
            
    return matched_count, len(missing), zip_p

# ==========================================
# 5. Streamlit ä¸»ç•Œé¢
# ==========================================

def main():
    st.set_page_config(page_title="å‘ç¥¨æ— å¿§ V11 (ç»ˆæç‰ˆ)", layout="wide")
    st.title("ğŸ§¾ å‘ç¥¨æ— å¿§ V11 (å«è‡ªåŠ¨æ ¸å¯¹ä¸é—æ¼æ‰“åŒ…)")

    tab1, tab2 = st.tabs(["ğŸš€ ä¸€é”®å¤„ç† (è‡ªåŠ¨æ ¸å¯¹)", "ğŸ” æ‰‹åŠ¨å¤æ ¸ (æ—§åŒ…å®¡è®¡)"])

    # --- Tab 1: è‡ªåŠ¨å¤„ç† + è‡ªåŠ¨æ ¸å¯¹ ---
    with tab1:
        st.info("ä¸Šä¼  ZIP/æ–‡ä»¶å¤¹ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨ï¼š1.éš”ç¦»ä½œç”¨åŸŸåŒ¹é…è¡Œç¨‹å• 2.ç”Ÿæˆæ±‡æ€» 3.è‡ªåŠ¨æ‰¾å‡ºé—æ¼æ–‡ä»¶å¹¶æ‰“åŒ…")
        uploaded_files = st.file_uploader("ä¸Šä¼ æ–‡ä»¶", type=['zip', 'xml', 'pdf'], accept_multiple_files=True, key="u1")

        if uploaded_files and st.button("å¼€å§‹å¤„ç†", key="b1"):
            with st.spinner('æ­£åœ¨å…¨æµç¨‹å¤„ç†...'):
                with tempfile.TemporaryDirectory() as temp_dir:
                    input_root = os.path.join(temp_dir, "input")
                    os.makedirs(input_root, exist_ok=True)
                    
                    # 1. ç‰©ç†éš”ç¦»ä¿å­˜
                    for i, up in enumerate(uploaded_files):
                        scope_dir = os.path.join(input_root, f"scope_{i}")
                        os.makedirs(scope_dir, exist_ok=True)
                        save_path = os.path.join(scope_dir, up.name)
                        with open(save_path, "wb") as f: f.write(up.getbuffer())
                        if up.name.endswith('.zip'):
                            extract_zip_with_encoding(save_path, scope_dir)
                            os.remove(save_path)
                    
                    # 2. è¿è¡Œç®¡é“
                    out_dir = os.path.join(temp_dir, "output")
                    excel, merged, noxml, missing_list = run_process_pipeline(input_root, out_dir)
                    
                    # 3. ç»“æœå±•ç¤º
                    st.success("âœ… å¤„ç†å®Œæˆï¼")
                    
                    # ç»Ÿè®¡
                    col1, col2 = st.columns(2)
                    if excel:
                        df = pd.read_excel(excel)
                        count = len(df) - 1 # å‡å»æ€»è®¡è¡Œ
                        col1.metric("æˆåŠŸåŒ¹é…å‘ç¥¨", f"{count} å¼ ")
                        st.dataframe(df.tail(3))
                    
                    # é—æ¼å¤„ç†
                    col2.metric("é—æ¼æ–‡ä»¶", f"{len(missing_list)} ä¸ª", delta_color="inverse")
                    if missing_list:
                        st.warning("âš ï¸ æ£€æµ‹åˆ°æœ‰æ–‡ä»¶æœªè¢«å¤„ç†ï¼ˆå¯èƒ½æ˜¯æŸåã€åŠ å¯†æˆ–éå‘ç¥¨æ–‡ä»¶ï¼‰ï¼Œå·²æ‰“åŒ…å¦‚ä¸‹ï¼š")
                        missing_zip = os.path.join(temp_dir, "Missing_Files.zip")
                        with zipfile.ZipFile(missing_zip, 'w', zipfile.ZIP_DEFLATED) as z:
                            for mf in missing_list:
                                z.write(mf, f"é—æ¼æ–‡ä»¶/{os.path.basename(mf)}")
                        with open(missing_zip, "rb") as f:
                            st.download_button("ğŸ“¥ ä¸‹è½½é—æ¼æ–‡ä»¶åŒ… (Missing.zip)", f, "Missing_Files.zip", type="primary")

                    # ä¸»ç»“æœæ‰“åŒ…
                    if excel:
                        res_zip = os.path.join(temp_dir, "Result.zip")
                        with zipfile.ZipFile(res_zip, 'w', zipfile.ZIP_DEFLATED) as z:
                            z.write(excel, "æ±‡æ€»è¡¨.xlsx")
                            for r, _, fs in os.walk(merged):
                                for f in fs: z.write(os.path.join(r, f), f"åˆå¹¶åå‘ç¥¨/{f}")
                            for r, _, fs in os.walk(noxml):
                                for f in fs: z.write(os.path.join(r, f), f"ç‹¬ç«‹å‘ç¥¨/{f}")
                        
                        with open(res_zip, "rb") as f:
                            st.download_button("ğŸ“¥ ä¸‹è½½å¤„ç†ç»“æœ (Result.zip)", f, "Invoices_Result.zip")

    # --- Tab 2: æ‰‹åŠ¨æ ¸å¯¹ ---
    with tab2:
        st.write("ç”¨äºæ ¸å¯¹**ä»¥å‰å¤„ç†è¿‡çš„**ç»“æœåŒ…ã€‚")
        c1, c2 = st.columns(2)
        raw_ups = c1.file_uploader("1. ä¸Šä¼ åŸå§‹å‘ç¥¨ (ZIP/PDF)", type=['zip','pdf'], accept_multiple_files=True, key="u2")
        proc_zip = c2.file_uploader("2. ä¸Šä¼ å·²å¤„ç† Result.zip", type=['zip'], key="u3")
        
        if raw_ups and proc_zip and st.button("å¼€å§‹æ ¸å¯¹", key="b2"):
            with tempfile.TemporaryDirectory() as td:
                raw_d = os.path.join(td, "raw")
                os.makedirs(raw_d, exist_ok=True)
                for up in raw_ups:
                    p = os.path.join(raw_d, up.name)
                    with open(p, "wb") as f: f.write(up.getbuffer())
                    if p.endswith('.zip'): extract_zip_with_encoding(p, raw_d)
                
                pz = os.path.join(td, "proc.zip")
                with open(pz, "wb") as f: f.write(proc_zip.getbuffer())
                
                match, miss, mzip = run_manual_check(raw_d, pz, td)
                st.metric("åŒ¹é…æˆåŠŸ", match)
                st.metric("é—æ¼/æœªåŒ¹é…", miss)
                if mzip:
                    with open(mzip, "rb") as f:
                        st.download_button("ä¸‹è½½æœªåŒ¹é…æ–‡ä»¶", f, "Unmatched.zip")

if __name__ == "__main__":
    main()