import streamlit as st
import os
import zipfile
import shutil
import tempfile
import re
import pandas as pd
import pdfplumber
import xml.etree.ElementTree as ET
from pypdf import PdfWriter

# ==========================================
# 1. åŸºç¡€å·¥å…·å‡½æ•°
# ==========================================

def extract_zip_with_encoding(zip_path, extract_to):
    """è§£å‹ ZIP å¹¶ä¿®å¤ä¸­æ–‡ä¹±ç """
    with zipfile.ZipFile(zip_path, 'r') as z:
        for file_info in z.infolist():
            try:
                if file_info.flag_bits & 0x800 == 0:
                    original_name = file_info.filename.encode('cp437').decode('gbk')
                else:
                    original_name = file_info.filename
            except:
                try: original_name = file_info.filename.encode('utf-8').decode('utf-8')
                except: original_name = file_info.filename

            if "__MACOSX" in original_name or ".DS_Store" in original_name:
                continue

            target_path = os.path.join(extract_to, original_name)
            parent_dir = os.path.dirname(target_path)
            if parent_dir and not os.path.exists(parent_dir):
                os.makedirs(parent_dir, exist_ok=True)
                
            if not original_name.endswith('/'):
                with z.open(file_info) as source, open(target_path, "wb") as target:
                    shutil.copyfileobj(source, target)

def normalize_text(text):
    """æ–‡æœ¬æ¸…æ´—"""
    if not text: return ""
    # æ›¿æ¢å¸¸è§å¹²æ‰°å­—ç¬¦ï¼Œç»Ÿä¸€æ ‡ç‚¹
    return text.replace(" ", "").replace("\n", "").replace("\r", "")\
               .replace("ï¼š", ":").replace("ï¿¥", "Â¥")\
               .replace("ï¼ˆ", "(").replace("ï¼‰", ")")\
               .replace("O", "0").replace("o", "0")

def format_date(date_str):
    """ç»Ÿä¸€æ—¥æœŸæ ¼å¼ YYYY-MM-DD"""
    if not date_str: return ""
    m = re.search(r'(\d{4})[-å¹´/.](\d{1,2})[-æœˆ/.](\d{1,2})', date_str)
    if m:
        return f"{m.group(1)}-{int(m.group(2)):02d}-{int(m.group(3)):02d}"
    return ""

# ==========================================
# 2. é‡‘é¢å¤„ç†æ ¸å¿ƒå¼•æ“ (æ–°å¢å¤§å†™è§£æ)
# ==========================================

def cn_upper_to_float(cn_str):
    """
    å°†ä¸­æ–‡å¤§å†™é‡‘é¢è½¬æ¢ä¸ºæµ®ç‚¹æ•°
    ä¾‹å¦‚ï¼šè´°ä½°æŒæ‹¾ååœ†æŒè§’å£¹åˆ† -> 283.81
    """
    if not cn_str: return 0.0
    
    # æ˜ å°„è¡¨
    CN_NUM = {'é›¶': 0, 'å£¹': 1, 'è´°': 2, 'å': 3, 'è‚†': 4, 'ä¼': 5, 'é™†': 6, 'æŸ’': 7, 'æŒ': 8, 'ç–': 9,
              'ä¸€': 1, 'äºŒ': 2, 'ä¸‰': 3, 'å››': 4, 'äº”': 5, 'å…­': 6, 'ä¸ƒ': 7, 'å…«': 8, 'ä¹': 9, 'ä¸¤': 2}
    CN_UNIT = {'æ‹¾': 10, 'å': 10, 'ä½°': 100, 'ç™¾': 100, 'ä»Ÿ': 1000, 'åƒ': 1000, 'ä¸‡': 10000, 'äº¿': 100000000}
    
    # æ¸…æ´—ï¼šå»æ‰"æ•´"ã€"æ­£"ã€"åœ†"ã€"å…ƒ"ç­‰
    # ä½†è¦æ³¨æ„"åœ†"æ˜¯åˆ†ç•Œçº¿
    
    # ç®€å•è§£æé€»è¾‘ï¼š
    # 1. æŒ‰"åœ†/å…ƒ"åˆ†å‰²æ•´æ•°å’Œå°æ•°
    parts = re.split(r'[åœ†å…ƒ]', cn_str)
    integer_str = parts[0]
    decimal_str = parts[1] if len(parts) > 1 else ""
    
    # --- è§£ææ•´æ•°éƒ¨åˆ† ---
    def parse_section(s):
        val = 0
        curr_digit = 0
        unit_val = 0
        
        for char in s:
            if char in CN_NUM:
                curr_digit = CN_NUM[char]
            elif char in CN_UNIT:
                if char in ['ä¸‡', 'äº¿']:
                    # é‡åˆ°ä¸‡/äº¿ï¼Œç»“ç®—å‰é¢çš„æ‰€æœ‰
                    val = (val + unit_val + curr_digit) * CN_UNIT[char]
                    unit_val = 0
                    curr_digit = 0
                else:
                    unit_val += curr_digit * CN_UNIT[char]
                    curr_digit = 0
            # é›¶å¿½ç•¥
        return val + unit_val + curr_digit

    total = parse_section(integer_str)
    
    # --- è§£æå°æ•°éƒ¨åˆ† (è§’ã€åˆ†) ---
    decimal_val = 0.0
    curr_digit = 0
    for char in decimal_str:
        if char in CN_NUM:
            curr_digit = CN_NUM[char]
        elif char == 'è§’':
            decimal_val += curr_digit * 0.1
            curr_digit = 0
        elif char == 'åˆ†':
            decimal_val += curr_digit * 0.01
            curr_digit = 0
            
    return round(total + decimal_val, 2)

def find_amount_strict(text):
    """
    ä¸¥æ ¼é‡‘é¢æå–ç­–ç•¥ï¼š
    1. ä¼˜å…ˆæå–å¤§å†™é‡‘é¢ (Authoritative)
    2. æå–å°å†™é‡‘é¢ (Verify)
    3. è¿”å› (æœ€ä½³é‡‘é¢, å¤‡æ³¨ä¿¡æ¯)
    """
    if not text: return 0.0, "ç©ºç™½å†…å®¹"
    
    # --- 1. æå–å¤§å†™é‡‘é¢ ---
    # åŒ¹é…æ¨¡å¼ï¼šä»·ç¨åˆè®¡(å¤§å†™) XXXXX
    # å…¼å®¹ï¼šå¤§å†™:ã€å¤§å†™ï¼š
    upper_pattern = r'(?:ä»·ç¨åˆè®¡|å¤§å†™|é‡‘é¢).*?([é›¶å£¹è´°åè‚†ä¼é™†æŸ’æŒç–æ‹¾ä½°ä»Ÿä¸‡äº¿åœ†è§’åˆ†æ•´]+)'
    upper_match = re.search(upper_pattern, text)
    
    amount_upper = 0.0
    has_upper = False
    
    if upper_match:
        cn_str = upper_match.group(1)
        # æ’é™¤çŸ­æ‚éŸ³ï¼ˆä¾‹å¦‚åªåŒ¹é…åˆ°ä¸€ä¸ª"åœ†"å­—ï¼‰
        if len(cn_str) > 1:
            try:
                amount_upper = cn_upper_to_float(cn_str)
                if amount_upper > 0:
                    has_upper = True
            except: pass

    # --- 2. æå–å°å†™é‡‘é¢ ---
    # åŒ¹é…æ¨¡å¼ï¼š(å°å†™)ã€Â¥ã€ï¿¥ ç´§è·Ÿçš„æ•°å­—
    # ä¸¥æ ¼æ¨¡å¼ï¼šä¸å†å…¨å±æœç´¢æœ€å¤§æ•°å­—ï¼Œé˜²æ­¢åŒ¹é…åˆ°å•ä»·
    lower_pattern = r'(?:å°å†™|Â¥|ï¿¥|åˆè®¡)[^0-9\.]*([0-9]{1,3}(?:,[0-9]{3})*\.[0-9]{2})'
    lower_matches = re.findall(lower_pattern, text)
    
    amount_lower = 0.0
    has_lower = False
    
    # å–ç¬¬ä¸€ä¸ªåŒ¹é…åˆ°çš„æœ‰æ•ˆé‡‘é¢ (é€šå¸¸å‘ç¥¨å°å†™å°±åœ¨å¤§å†™åé¢)
    for m in lower_matches:
        try:
            val = float(m.replace(",", ""))
            if 0.01 <= val <= 5000000:
                amount_lower = val
                has_lower = True
                break # æ‰¾åˆ°å³æ­¢
        except: continue

    # --- 3. å†³ç­–ä¸æ ¡éªŒ ---
    
    # æƒ…å†µA: æœ‰å¤§å†™ (ä»¥å¤§å†™ä¸ºå‡†)
    if has_upper:
        if has_lower:
            if abs(amount_upper - amount_lower) > 0.1:
                return amount_upper, f"âš ï¸ å¤§å°å†™ä¸ç¬¦ (å¤§å†™:{amount_upper} å°å†™:{amount_lower})"
            else:
                return amount_upper, "æ­£å¸¸" # æ ¡éªŒé€šè¿‡
        else:
            return amount_upper, "æ­£å¸¸ (æ— å°å†™)"

    # æƒ…å†µB: æ— å¤§å†™ï¼Œæœ‰å°å†™ (é™çº§ä½¿ç”¨å°å†™)
    if has_lower:
        return amount_lower, "ä½¿ç”¨å°å†™ (æœªè¯»åˆ°å¤§å†™)"
        
    # æƒ…å†µC: éƒ½æ²¡æœ‰
    return 0.0, "è­¦å‘Š:æœªè¯»åˆ°é‡‘é¢"

def extract_seller_name_smart(text):
    """æå–é”€å”®æ–¹"""
    suffix = r"[\u4e00-\u9fa5()ï¼ˆï¼‰]{2,30}(?:å…¬å¸|äº‹åŠ¡æ‰€|é…’åº—|æ—…è¡Œç¤¾|ç»è¥éƒ¨|æœåŠ¡éƒ¨|åˆ†è¡Œ|æ”¯è¡Œ|é¦†|åº—|å¤„|ä¸­å¿ƒ)"
    candidates = list(set(re.findall(suffix, text)))
    blacklist = ["ç¨åŠ¡å±€", "è´¢æ”¿éƒ¨", "è´­ä¹°æ–¹", "å¼€æˆ·è¡Œ", "é“¶è¡Œ", "åœ°å€", "ç”µè¯", "ç»Ÿä¸€ç¤¾ä¼šä¿¡ç”¨", "çº³ç¨äºº", "é€‚ç”¨ç¨ç‡", "å¯†ç åŒº", "æœºå™¨ç¼–å·"]
    filtered = [c for c in candidates if not any(b in c for b in blacklist) and len(c) >= 4]
    return max(filtered, key=len) if filtered else ""

def is_trip_file(filename, text=None):
    """åˆ¤æ–­è¡Œç¨‹å•"""
    fn = filename.lower()
    if "è¡Œç¨‹" in fn or "trip" in fn or "æŠ¥é”€" in fn:
        if text:
            clean = normalize_text(text)
            if "å‘ç¥¨ä»£ç " in clean or "å‘ç¥¨å·ç " in clean or "ç”µå­å‘ç¥¨" in clean:
                return False
        return True
    return False

# ==========================================
# 3. è§£æå‡½æ•° (XML & PDF)
# ==========================================

def parse_xml_invoice_data(xml_path):
    try:
        tree = ET.parse(xml_path)
        root = tree.getroot()
        def g(path):
            node = root.find(path)
            return node.text if node is not None else ""

        num = g(".//TaxSupervisionInfo/InvoiceNumber") or g(".//InvoiceNumber") or g(".//Fphm")
        date = g(".//TaxSupervisionInfo/IssueTime") or g(".//IssueTime") or g(".//Kprq")
        seller = g(".//SellerInformation/SellerName") or g(".//Xfmc")
        
        # XML ä¸­çš„é‡‘é¢é€šå¸¸æ˜¯æ•°å­—ï¼Œç›´æ¥è¯»å–
        amt_str = g(".//BasicInformation/TotalTax-includedAmount") or g(".//TotalTax-includedAmount") or g(".//TotalAmount") or g(".//Jshj")
        amount = float(amt_str.replace(',', '')) if amt_str else 0.0

        return {
            "num": num, "date": format_date(date), 
            "seller": seller, "amount": amount
        }
    except: return None

def extract_data_from_pdf_simple(pdf_path):
    try:
        with pdfplumber.open(pdf_path) as p:
            if not p.pages: return None
            raw = p.pages[0].extract_text()
            if not raw or len(raw.strip()) < 10: 
                return {
                    "å‘ç¥¨å·ç ": "", "å¼€ç¥¨æ—¥æœŸ": "", "é”€å”®æ–¹åç§°": "", "ä»·ç¨åˆè®¡": 0.0,
                    "æ–‡ä»¶å": os.path.basename(pdf_path), "å¤‡æ³¨": "âš ï¸ çº¯å›¾/æ‰«æä»¶"
                }
            
            text = normalize_text(raw)
            num = ""
            m20 = re.search(r'(\d{20})', text)
            if m20: num = m20.group(1)
            else:
                m8 = re.search(r'(?:å·ç |No)[:|]?(\d{8,})', text)
                if m8: num = m8.group(1)
            
            date = ""
            md = re.search(r'(\d{4}[-å¹´/.]\d{1,2}[-æœˆ/.]\d{1,2}æ—¥?)', text)
            if md: date = format_date(md.group(1))
            
            # ä½¿ç”¨ä¸¥æ ¼é‡‘é¢æå–ç­–ç•¥
            amt, status_note = find_amount_strict(text)
            seller = extract_seller_name_smart(text)
            
            # å¦‚æœæ²¡è¯»åˆ°å·ä½†è¯»åˆ°äº†é‡‘é¢ï¼Œæ ‡æ³¨ä¸€ä¸‹
            if not num and amt > 0:
                if "è­¦å‘Š" not in status_note:
                    status_note = "æ— å‘ç¥¨å·-" + status_note
            
            return {
                "å‘ç¥¨å·ç ": num, "å¼€ç¥¨æ—¥æœŸ": date, "é”€å”®æ–¹åç§°": seller,
                "ä»·ç¨åˆè®¡": amt, "æ–‡ä»¶å": os.path.basename(pdf_path),
                "å¤‡æ³¨": status_note
            }
    except: return None

# ==========================================
# 4. æ ¡éªŒå¼•æ“ (Verifier)
# ==========================================

class InvoiceVerifier:
    def __init__(self, processed_df):
        self.df = processed_df
        self.processed_nums = {} 
        self.processed_attrs = {}
        
        for _, row in self.df.iterrows():
            p_num = str(row.get('å‘ç¥¨å·ç ', '')).strip()
            p_amt = float(row.get('ä»·ç¨åˆè®¡', 0))
            p_date = str(row.get('å¼€ç¥¨æ—¥æœŸ', '')).strip()
            p_seller = str(row.get('é”€å”®æ–¹åç§°', '')).strip()
            
            if p_num and len(p_num) > 6:
                self.processed_nums[p_num] = {'amount': p_amt, 'date': p_date}
            
            short_seller = p_seller[:4] if len(p_seller) >=4 else p_seller
            attr_key = (f"{p_amt:.2f}", p_date, short_seller)
            self.processed_attrs[attr_key] = True

    def check(self, raw_info):
        raw_num = str(raw_info.get('num') or raw_info.get('å‘ç¥¨å·ç ') or '').strip()
        raw_amt = float(raw_info.get('amount') or raw_info.get('ä»·ç¨åˆè®¡') or 0)
        raw_date = str(raw_info.get('date') or raw_info.get('å¼€ç¥¨æ—¥æœŸ') or '').strip()
        raw_seller = str(raw_info.get('seller') or raw_info.get('é”€å”®æ–¹åç§°') or '').strip()
        
        # 1. å¼ºæ ¡éªŒï¼šå·ç  + é‡‘é¢
        if raw_num and len(raw_num) > 6:
            if raw_num in self.processed_nums:
                rec_amt = self.processed_nums[raw_num]['amount']
                if abs(rec_amt - raw_amt) < 0.1:
                    return True
                else:
                    return True # å·ç å¯¹ä¸Šäº†å°±ç®—æ‰¾åˆ°ï¼Œä½†é‡‘é¢ä¸ä¸€è‡´æ˜¯å¦ä¸€å›äº‹
        
        # 2. å¼±æ ¡éªŒï¼šé‡‘é¢ + æ—¥æœŸ + é”€å”®æ–¹ (é’ˆå¯¹æ— å·æ–‡ä»¶)
        if raw_amt > 0:
            short_seller = raw_seller[:4] if len(raw_seller) >=4 else raw_seller
            attr_key = (f"{raw_amt:.2f}", raw_date, short_seller)
            if attr_key in self.processed_attrs:
                return True
            
            # 3. å…œåº•æ ¡éªŒï¼šé‡‘é¢ + æ—¥æœŸ (åªæœ‰å½“é‡‘é¢æ¯”è¾ƒç‹¬ç‰¹ï¼Œå³æœ‰å°æ•°ä½æ—¶)
            if raw_amt % 1 != 0:
                for k in self.processed_attrs:
                    if k[0] == f"{raw_amt:.2f}" and k[1] == raw_date:
                        return True

        return False

# ==========================================
# 5. ä¸»å¤„ç†æµç¨‹
# ==========================================

def run_process_pipeline(input_root_dir, output_dir):
    merged_dir = os.path.join(output_dir, 'Merged_PDFs')
    noxml_dir = os.path.join(output_dir, 'No_XML_PDFs')
    os.makedirs(merged_dir, exist_ok=True)
    os.makedirs(noxml_dir, exist_ok=True)

    all_files = []
    for root, dirs, files in os.walk(input_root_dir):
        for f in files: all_files.append(os.path.join(root, f))
    
    xml_files = [f for f in all_files if f.lower().endswith('.xml')]
    pdf_files = [f for f in all_files if f.lower().endswith('.pdf')]
    
    trip_pool = []
    invoice_pdf_pool = []
    
    for pdf in pdf_files:
        try:
            with pdfplumber.open(pdf) as p:
                if not p.pages: continue
                text = normalize_text(p.pages[0].extract_text())
                amt, _ = find_amount_strict(text) # ä½¿ç”¨ä¸¥æ ¼æ¨¡å¼
                folder = os.path.dirname(pdf)
                if is_trip_file(os.path.basename(pdf), text):
                    trip_pool.append({'path': pdf, 'amount': amt, 'folder': folder, 'used': False})
                else:
                    invoice_pdf_pool.append({'path': pdf, 'amount': amt, 'folder': folder})
        except: pass

    excel_rows = []
    idx = 1
    processed_source_files = set()

    # A. XMLå¤„ç†
    for xml in xml_files:
        info = parse_xml_invoice_data(xml)
        if not info: continue
        processed_source_files.add(os.path.abspath(xml))
        
        row = {"åºå·": idx, "å‘ç¥¨å·ç ": info['num'], "å¼€ç¥¨æ—¥æœŸ": info['date'],
               "é”€å”®æ–¹åç§°": info['seller'], "ä»·ç¨åˆè®¡": info['amount'], "æ•°æ®æ¥æº": "XML", "æ–‡ä»¶å": os.path.basename(xml), "å¤‡æ³¨": "æ­£å¸¸"}
        
        folder = os.path.dirname(xml)
        target_pdf = None
        cands = [p['path'] for p in invoice_pdf_pool if p['folder'] == folder]
        xml_base = os.path.splitext(os.path.basename(xml))[0]
        
        for p in cands:
            if xml_base in os.path.basename(p) or (info['num'] and info['num'] in os.path.basename(p)):
                target_pdf = p; break
        
        if target_pdf:
            processed_source_files.add(os.path.abspath(target_pdf))
            matched_trip = None
            for t in [x for x in trip_pool if x['folder'] == folder and not x['used']]:
                if abs(t['amount'] - info['amount']) < 0.05:
                    matched_trip = t; t['used'] = True; break
            
            if matched_trip:
                processed_source_files.add(os.path.abspath(matched_trip['path']))
                try:
                    merger = PdfWriter()
                    merger.append(target_pdf); merger.append(matched_trip['path'])
                    safe_name = f"{info['num']}_{info['amount']}.pdf".replace(':','').replace('/','_')
                    merger.write(os.path.join(merged_dir, safe_name)); merger.close()
                    row['å¤‡æ³¨'] = "å·²åˆå¹¶è¡Œç¨‹å•"
                except:
                    shutil.copy2(target_pdf, os.path.join(noxml_dir, os.path.basename(target_pdf)))
                    row['å¤‡æ³¨'] = "åˆå¹¶å¤±è´¥-ä¿ç•™åŸä»¶"
            else:
                shutil.copy2(target_pdf, os.path.join(noxml_dir, os.path.basename(target_pdf)))
        else:
             row['å¤‡æ³¨'] = "ä»…XML(ç¼ºPDF)"
        
        excel_rows.append(row); idx += 1

    # B. PDFå¤„ç†
    for inv in invoice_pdf_pool:
        if os.path.abspath(inv['path']) in processed_source_files: continue
        
        data = extract_data_from_pdf_simple(inv['path'])
        if not data: continue
        processed_source_files.add(os.path.abspath(inv['path']))
        
        matched_trip = None
        folder = inv['folder']
        for t in [x for x in trip_pool if x['folder'] == folder and not x['used']]:
            if inv['amount'] > 0 and abs(t['amount'] - inv['amount']) < 0.05:
                matched_trip = t; t['used'] = True; break
        
        if matched_trip:
            processed_source_files.add(os.path.abspath(matched_trip['path']))
            try:
                merger = PdfWriter()
                merger.append(inv['path']); merger.append(matched_trip['path'])
                num = data.get('å‘ç¥¨å·ç ', 'NoNum')
                safe_name = f"{num}_{inv['amount']}.pdf".replace(':','').replace('/','_')
                merger.write(os.path.join(merged_dir, safe_name)); merger.close()
                data['å¤‡æ³¨'] = "å·²åˆå¹¶è¡Œç¨‹å•"
                if data['ä»·ç¨åˆè®¡'] == 0: data['ä»·ç¨åˆè®¡'] = inv['amount']
            except:
                shutil.copy2(inv['path'], os.path.join(noxml_dir, os.path.basename(inv['path'])))
                data['å¤‡æ³¨'] = "åˆå¹¶å¤±è´¥-ä¿ç•™åŸä»¶"
        else:
            shutil.copy2(inv['path'], os.path.join(noxml_dir, os.path.basename(inv['path'])))
            
        data['åºå·'] = idx; excel_rows.append(data); idx += 1

    # C. è¡Œç¨‹å•å…œåº•
    for t in trip_pool:
        if not t['used']:
            processed_source_files.add(os.path.abspath(t['path']))
            try: shutil.copy2(t['path'], os.path.join(noxml_dir, os.path.basename(t['path'])))
            except: pass

    # D. ç”Ÿæˆç»“æœä¸æ ¸å¯¹
    excel_path = None
    df_result = pd.DataFrame()
    if excel_rows:
        df_result = pd.DataFrame(excel_rows)
        cols = ["åºå·", "å‘ç¥¨å·ç ", "å¼€ç¥¨æ—¥æœŸ", "é”€å”®æ–¹åç§°", "ä»·ç¨åˆè®¡", "æ•°æ®æ¥æº", "å¤‡æ³¨", "æ–‡ä»¶å"]
        for c in cols: 
            if c not in df_result.columns: df_result[c] = ""
        df_result = df_result[cols]
        df_result['ä»·ç¨åˆè®¡'] = pd.to_numeric(df_result['ä»·ç¨åˆè®¡'], errors='coerce').fillna(0.0)
        
        sum_row = {"åºå·": "æ€»è®¡", "ä»·ç¨åˆè®¡": df_result['ä»·ç¨åˆè®¡'].sum(), "é”€å”®æ–¹åç§°": f"å…± {len(df_result)} å¼ "}
        df_display = pd.concat([df_result, pd.DataFrame([sum_row])], ignore_index=True)
        excel_path = os.path.join(output_dir, 'Summary_Final.xlsx')
        df_display.to_excel(excel_path, index=False)

    missing_files = []
    if not df_result.empty:
        verifier = InvoiceVerifier(df_result)
        for f in all_files:
            if not f.lower().endswith(('.pdf', '.xml')): continue
            
            raw_info = None
            try:
                if f.lower().endswith('.xml'): raw_info = parse_xml_invoice_data(f)
                else: raw_info = extract_data_from_pdf_simple(f)
            except: pass
            
            is_missing = True
            if raw_info:
                # ç‰¹æ®Šå¤„ç†ï¼šå¦‚æœPDFè¢«è¯†åˆ«ä¸ºçº¯å›¾(å¤‡æ³¨å«è­¦å‘Š)ï¼Œç›´æ¥ç®—é—æ¼
                if "çº¯å›¾" in raw_info.get('å¤‡æ³¨', ''):
                    is_missing = True
                elif verifier.check(raw_info):
                    is_missing = False
            
            if is_missing:
                missing_files.append(f)

    return excel_path, merged_dir, noxml_dir, missing_files

# ==========================================
# 6. æ‰‹åŠ¨æ ¸å¯¹åŠŸèƒ½
# ==========================================

def run_manual_check(raw_dir, proc_zip_path, out_dir):
    df_proc = pd.DataFrame()
    with zipfile.ZipFile(proc_zip_path, 'r') as z:
        xls = [n for n in z.namelist() if n.endswith('.xlsx')]
        if xls:
            with z.open(xls[0]) as f: df_proc = pd.read_excel(f)
        else:
            # å…¼å®¹æ—§ç‰ˆZIP
            rows = []
            for n in z.namelist():
                if n.endswith('.pdf'):
                    base = os.path.basename(n)
                    m = re.match(r'(\d+)_([\d\.]+)\.pdf', base)
                    if m: rows.append({'å‘ç¥¨å·ç ': m.group(1), 'ä»·ç¨åˆè®¡': float(m.group(2))})
            df_proc = pd.DataFrame(rows)

    verifier = InvoiceVerifier(df_proc)
    missing = []
    matched_count = 0
    
    for root, _, files in os.walk(raw_dir):
        for f in files:
            if not f.lower().endswith(('.pdf', '.xml')): continue
            fp = os.path.join(root, f)
            
            raw_info = None
            try:
                if f.lower().endswith('.xml'): raw_info = parse_xml_invoice_data(fp)
                else: raw_info = extract_data_from_pdf_simple(fp)
            except: pass
            
            if raw_info and verifier.check(raw_info):
                matched_count += 1
            else:
                missing.append(fp)
    
    zip_p = None
    if missing:
        zip_p = os.path.join(out_dir, "Manual_Missing.zip")
        with zipfile.ZipFile(zip_p, 'w', zipfile.ZIP_DEFLATED) as z:
            for m in missing: z.write(m, os.path.basename(m))
            
    return matched_count, len(missing), zip_p

# ==========================================
# 7. Streamlit ä¸»ç•Œé¢
# ==========================================

def main():
    st.set_page_config(page_title="å‘ç¥¨æ— å¿§ V12 (å¤§å†™é‡‘é¢æ ¡éªŒç‰ˆ)", layout="wide")
    st.title("ğŸ§¾ å‘ç¥¨æ— å¿§ V12 (ä¸¥æ ¼é‡‘é¢æ ¡éªŒ)")

    tab1, tab2 = st.tabs(["ğŸš€ ä¸€é”®å¤„ç†", "ğŸ” æ‰‹åŠ¨å¤æ ¸"])

    with tab1:
        st.info("ä¸Šä¼  ZIP/æ–‡ä»¶å¤¹ -> ä¼˜å…ˆæå–å¤§å†™é‡‘é¢ -> è‡ªåŠ¨æ ¸å¯¹")
        uploaded_files = st.file_uploader("ä¸Šä¼ æ–‡ä»¶", type=['zip', 'xml', 'pdf'], accept_multiple_files=True, key="u1")

        if uploaded_files and st.button("å¼€å§‹å¤„ç†", key="b1"):
            with st.spinner('æ­£åœ¨å¤„ç†...'):
                with tempfile.TemporaryDirectory() as temp_dir:
                    input_root = os.path.join(temp_dir, "input")
                    os.makedirs(input_root, exist_ok=True)
                    
                    for i, up in enumerate(uploaded_files):
                        scope_dir = os.path.join(input_root, f"scope_{i}")
                        os.makedirs(scope_dir, exist_ok=True)
                        save_path = os.path.join(scope_dir, up.name)
                        with open(save_path, "wb") as f: f.write(up.getbuffer())
                        if up.name.endswith('.zip'):
                            extract_zip_with_encoding(save_path, scope_dir)
                            os.remove(save_path)
                    
                    out_dir = os.path.join(temp_dir, "output")
                    excel, merged, noxml, missing_list = run_process_pipeline(input_root, out_dir)
                    
                    st.success("âœ… å®Œæˆï¼")
                    c1, c2 = st.columns(2)
                    if excel:
                        df = pd.read_excel(excel)
                        c1.metric("å·²å½•å…¥", f"{len(df)-1} å¼ ")
                        st.dataframe(df.tail(3))
                        res_zip = os.path.join(temp_dir, "Result.zip")
                        with zipfile.ZipFile(res_zip, 'w', zipfile.ZIP_DEFLATED) as z:
                            z.write(excel, "æ±‡æ€»è¡¨.xlsx")
                            for r, _, fs in os.walk(merged):
                                for f in fs: z.write(os.path.join(r, f), f"åˆå¹¶åå‘ç¥¨/{f}")
                            for r, _, fs in os.walk(noxml):
                                for f in fs: z.write(os.path.join(r, f), f"ç‹¬ç«‹å‘ç¥¨/{f}")
                        with open(res_zip, "rb") as f:
                            st.download_button("ğŸ“¥ ä¸‹è½½ç»“æœ (Result.zip)", f, "Result.zip")

                    c2.metric("é—æ¼", f"{len(missing_list)} ä¸ª", delta_color="inverse")
                    if missing_list:
                        m_zip = os.path.join(temp_dir, "Missing.zip")
                        with zipfile.ZipFile(m_zip, 'w', zipfile.ZIP_DEFLATED) as z:
                            for m in missing_list: z.write(m, f"é—æ¼æ–‡ä»¶/{os.path.basename(m)}")
                        with open(m_zip, "rb") as f:
                            st.download_button("ğŸ“¥ ä¸‹è½½é—æ¼åŒ… (Missing.zip)", f, "Missing.zip", type="primary")

    with tab2:
        st.write("åå‘æ ¸å¯¹ï¼šç”¨ Excel ç»“æœæ£€æŸ¥åŸå§‹æ–‡ä»¶æ˜¯å¦é—æ¼ã€‚")
        c1, c2 = st.columns(2)
        raw_ups = c1.file_uploader("1. ä¸Šä¼ åŸå§‹æ–‡ä»¶", type=['zip','pdf'], accept_multiple_files=True, key="u2")
        proc_zip = c2.file_uploader("2. ä¸Šä¼  Result.zip", type=['zip'], key="u3")
        
        if raw_ups and proc_zip and st.button("å¼€å§‹æ ¸å¯¹", key="b2"):
            with st.spinner("æ ¸å¯¹ä¸­..."):
                with tempfile.TemporaryDirectory() as td:
                    raw_d = os.path.join(td, "raw")
                    os.makedirs(raw_d, exist_ok=True)
                    for up in raw_ups:
                        p = os.path.join(raw_d, up.name)
                        with open(p, "wb") as f: f.write(up.getbuffer())
                        if p.endswith('.zip'): extract_zip_with_encoding(p, raw_d)
                    
                    pz = os.path.join(td, "proc.zip")
                    with open(pz, "wb") as f: f.write(proc_zip.getbuffer())
                    
                    match, miss, mzip = run_manual_check(raw_d, pz, td)
                    st.metric("âœ… åŒ¹é…æˆåŠŸ", match)
                    st.metric("âŒ é—æ¼", miss)
                    if mzip:
                        with open(mzip, "rb") as f:
                            st.download_button("ğŸ“¥ ä¸‹è½½é—æ¼æ–‡ä»¶", f, "Manual_Missing.zip")

if __name__ == "__main__":
    main()