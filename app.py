import streamlit as st
import os
import zipfile
import shutil
import tempfile
import re
import pandas as pd
import pdfplumber
import xml.etree.ElementTree as ET
from pypdf import PdfWriter

# ==========================================
# 1. åŸºç¡€å·¥å…·å‡½æ•° (è§£å‹ã€æ¸…æ´—ã€é€šç”¨æå–)
# ==========================================

def extract_zip_with_encoding(zip_path, extract_to):
    """è§£å‹ ZIP å¹¶ä¿®å¤ä¸­æ–‡ä¹±ç  (CP437 -> GBK è‡ªåŠ¨è½¬æ¢)"""
    with zipfile.ZipFile(zip_path, 'r') as z:
        for file_info in z.infolist():
            try:
                # å°è¯•ä¿®å¤æ–‡ä»¶åç¼–ç 
                if file_info.flag_bits & 0x800 == 0:
                    original_name = file_info.filename.encode('cp437').decode('gbk')
                else:
                    original_name = file_info.filename
            except:
                try: original_name = file_info.filename.encode('utf-8').decode('utf-8')
                except: original_name = file_info.filename

            # è¿‡æ»¤æ‰ macOS éšè—æ–‡ä»¶
            if "__MACOSX" in original_name or ".DS_Store" in original_name:
                continue

            target_path = os.path.join(extract_to, original_name)
            
            # é˜²æ­¢è·¯å¾„ç©¿è¶Šï¼Œç¡®ä¿çˆ¶ç›®å½•å­˜åœ¨
            parent_dir = os.path.dirname(target_path)
            if parent_dir and not os.path.exists(parent_dir):
                os.makedirs(parent_dir, exist_ok=True)
                
            # åªè§£å‹æ–‡ä»¶ï¼Œä¸è§£å‹çº¯æ–‡ä»¶å¤¹æ¡ç›®
            if not original_name.endswith('/'):
                with z.open(file_info) as source, open(target_path, "wb") as target:
                    shutil.copyfileobj(source, target)

def normalize_text(text):
    """æ¸…æ´—æ–‡æœ¬ï¼šå»ç©ºæ ¼ã€æ¢è¡Œã€å…¨è§’è½¬åŠè§’"""
    if not text: return ""
    return text.replace(" ", "").replace("\n", "").replace("\r", "")\
               .replace("ï¼š", ":").replace("ï¿¥", "Â¥")\
               .replace("ï¼ˆ", "(").replace("ï¼‰", ")")

def find_max_valid_amount(text):
    """
    ä»æ–‡æœ¬ä¸­æå–æ‰€æœ‰çœ‹èµ·æ¥åƒé‡‘é¢çš„æ•°å­—ï¼Œå–æœ€å¤§å€¼ä½œä¸ºä»·ç¨åˆè®¡ã€‚
    æ’é™¤æ—¥æœŸã€ç¨ç‡ã€æ•°é‡ç­‰å¹²æ‰°ã€‚
    """
    # åŒ¹é… 123.45 æˆ– 1,234.56 æ ¼å¼
    matches = re.findall(r'(\d{1,3}(?:,\d{3})*\.\d{2})', text)
    valid_amounts = []
    for m in matches:
        try:
            val = float(m.replace(",", ""))
            # è¿‡æ»¤é€»è¾‘ï¼šé‡‘é¢é€šå¸¸åœ¨ 0.01 åˆ° 500ä¸‡ä¹‹é—´
            # æ’é™¤å¸¸è§çš„ç¨ç‡ 0.06, 0.03, 0.13, 0.01 å’Œæ•°é‡ 1.00
            if 0.01 <= val <= 5000000 and val not in [0.06, 0.03, 0.13, 0.01, 1.00]:
                valid_amounts.append(val)
        except: continue
    
    return max(valid_amounts) if valid_amounts else 0.0

def extract_seller_name_smart(text):
    """æ™ºèƒ½æå–é”€å”®æ–¹åç§°"""
    # åŒ¹é…ä»¥ç‰¹å®šåç¼€ç»“å°¾çš„ä¸­æ–‡åç§°
    suffix_pattern = r"[\u4e00-\u9fa5()ï¼ˆï¼‰]{2,30}(?:å…¬å¸|äº‹åŠ¡æ‰€|é…’åº—|æ—…è¡Œç¤¾|ç»è¥éƒ¨|æœåŠ¡éƒ¨|åˆ†è¡Œ|æ”¯è¡Œ|é¦†|åº—|å¤„|ä¸­å¿ƒ)"
    candidates = list(set(re.findall(suffix_pattern, text)))
    
    # é»‘åå•è¿‡æ»¤
    blacklist = ["ç¨åŠ¡å±€", "è´¢æ”¿éƒ¨", "è´­ä¹°æ–¹", "å¼€æˆ·è¡Œ", "é“¶è¡Œ", "åœ°å€", "ç”µè¯", "ç»Ÿä¸€ç¤¾ä¼šä¿¡ç”¨", "çº³ç¨äºº", "é€‚ç”¨ç¨ç‡"]
    filtered = [c for c in candidates if not any(b in c for b in blacklist) and len(c) >= 4]
    
    if not filtered: return ""
    # é€šå¸¸å–æœ€é•¿çš„åå­—ä½œä¸ºé”€å”®æ–¹å…¨ç§°
    return max(filtered, key=len)

def is_trip_file(filename, text=None):
    """åˆ¤æ–­æ˜¯å¦ä¸ºè¡Œç¨‹å•/æŠ¥é”€å•"""
    fn = filename.lower()
    # ç‰¹å¾ 1: æ–‡ä»¶ååŒ…å«å…³é”®å­—
    if "è¡Œç¨‹" in fn or "trip" in fn or "æŠ¥é”€" in fn:
        # ç‰¹å¾ 2: å†…å®¹æ’é™¤å‘ç¥¨ç‰¹å¾ (é˜²æ­¢æ–‡ä»¶åå«è¡Œç¨‹å•ä½†å…¶å®æ˜¯å‘ç¥¨)
        if text:
            clean_text = normalize_text(text)
            # å¦‚æœå†…å®¹é‡Œæœ‰æ˜ç¡®çš„"å‘ç¥¨ä»£ç "ã€"å‘ç¥¨å·ç "ã€"ç”µå­å‘ç¥¨"ï¼Œåˆ™å³ä½¿æ–‡ä»¶åæœ‰è¡Œç¨‹ä¹Ÿè§†ä¸ºå‘ç¥¨
            if "å‘ç¥¨ä»£ç " in clean_text or "å‘ç¥¨å·ç " in clean_text or "ç”µå­å‘ç¥¨" in clean_text:
                return False
        return True
    return False

# ==========================================
# 2. æ ¸å¿ƒè§£æå‡½æ•° (XML & PDF) - å·²è¡¥å…¨
# ==========================================

def parse_xml_invoice_data(xml_path):
    """
    å®Œæ•´è§£æ XML æ•°æ®
    é€‚é…ï¼šæ•°ç”µç¥¨ï¼ˆç¨åŠ¡å±€ï¼‰ã€èˆªä¿¡ã€ç™¾æœ›äº‘ç­‰ä¸åŒç»“æ„
    """
    try:
        tree = ET.parse(xml_path)
        root = tree.getroot()
        
        # è¾…åŠ©å‡½æ•°ï¼šå®‰å…¨è·å–èŠ‚ç‚¹æ–‡æœ¬
        def g(path):
            node = root.find(path)
            return node.text if node is not None else ""

        # 1. æå–å‘ç¥¨å·ç  (ä¸åŒè§„èŒƒè·¯å¾„ä¸åŒ)
        num = g(".//TaxSupervisionInfo/InvoiceNumber")
        if not num: num = g(".//InvoiceNumber")
        if not num: num = g(".//Fphm") # éƒ¨åˆ†æ—§æ¥å£
        
        # 2. æå–æ—¥æœŸ
        date = g(".//TaxSupervisionInfo/IssueTime")
        if not date: date = g(".//IssueTime")
        if not date: date = g(".//Kprq")
        
        # 3. æå–é”€å”®æ–¹
        seller = g(".//SellerInformation/SellerName")
        if not seller: seller = g(".//Xfmc")
        
        # 4. æå–é‡‘é¢ (ä»·ç¨åˆè®¡)
        amt_str = g(".//BasicInformation/TotalTax-includedAmount")
        if not amt_str: amt_str = g(".//TotalTax-includedAmount")
        if not amt_str: amt_str = g(".//TotalAmount") # å…¼å®¹
        if not amt_str: amt_str = g(".//Jshj")
        
        amount = float(amt_str) if amt_str else 0.0

        return {
            "num": num,
            "date": date,
            "seller": seller,
            "amount": amount
        }
    except Exception as e:
        # print(f"XML Parse Error {xml_path}: {e}")
        return None

def extract_data_from_pdf_simple(pdf_path):
    """
    ä» PDF ä¸­æå–åŸºç¡€å‘ç¥¨æ•°æ®
    """
    try:
        with pdfplumber.open(pdf_path) as p:
            if not p.pages: return None
            # è·å–ç¬¬ä¸€é¡µæ–‡æœ¬
            raw_text = p.pages[0].extract_text()
            if not raw_text: return None
            
            clean_text = normalize_text(raw_text)
            
            # 1. æå–å‘ç¥¨å·ç  (ä¼˜å…ˆæ‰¾20ä½å…¨ç”µå·ç ï¼Œå…¶æ¬¡æ‰¾æ™®é€šå‘ç¥¨å·)
            num = ""
            m_20 = re.search(r'(\d{20})', clean_text)
            if m_20:
                num = m_20.group(1)
            else:
                m_8 = re.search(r'(?:å·ç |No)[:|]?(\d{8,})', clean_text)
                if m_8: num = m_8.group(1)
            
            # 2. æå–æ—¥æœŸ
            date = ""
            m_date = re.search(r'(\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥)', clean_text)
            if m_date: date = m_date.group(1)
            
            # 3. æå–é‡‘é¢
            amount = find_max_valid_amount(clean_text)
            
            # 4. æå–é”€å”®æ–¹
            seller = extract_seller_name_smart(clean_text)
            
            return {
                "å‘ç¥¨å·ç ": num,
                "å¼€ç¥¨æ—¥æœŸ": date,
                "é”€å”®æ–¹åç§°": seller,
                "ä»·ç¨åˆè®¡": amount,
                "æ•°æ®æ¥æº": "PDFè¯†åˆ«",
                "æ–‡ä»¶å": os.path.basename(pdf_path),
                "å¤‡æ³¨": "æ­£å¸¸" if amount > 0 else "è­¦å‘Š:æœªè¯»åˆ°é‡‘é¢"
            }
    except Exception:
        return None

# ==========================================
# 3. ä¸šåŠ¡æµç¨‹é€»è¾‘ (ä¸¥æ ¼é—­ç¯åŒ¹é…)
# ==========================================

def run_process_pipeline(input_root_dir, output_dir):
    """
    input_root_dir: åŒ…å«å¤šä¸ªç‹¬ç«‹ scope æ–‡ä»¶å¤¹çš„æ ¹ç›®å½•
    output_dir: ç»“æœè¾“å‡ºç›®å½•
    """
    merged_pdf_dir = os.path.join(output_dir, 'Merged_PDFs')
    no_xml_pdf_dir = os.path.join(output_dir, 'No_XML_PDFs')
    os.makedirs(merged_pdf_dir, exist_ok=True)
    os.makedirs(no_xml_pdf_dir, exist_ok=True)

    # 1. éå†æ‰€æœ‰æ–‡ä»¶ï¼Œå»ºç«‹ç´¢å¼•
    # æ³¨æ„ï¼šè¿™é‡Œä¼šéå† input_root_dir ä¸‹çš„æ‰€æœ‰å­æ–‡ä»¶å¤¹ (Scope)
    all_files = []
    for root, dirs, files in os.walk(input_root_dir):
        for f in files:
            all_files.append(os.path.join(root, f))
    
    xml_files = [f for f in all_files if f.lower().endswith('.xml')]
    pdf_files = [f for f in all_files if f.lower().endswith('.pdf')]
    
    # 2. å»ºç«‹ Trip Pool (è¡Œç¨‹å•æ± )
    # å…³é”®ç»“æ„: {'path': abs_path, 'amount': 123.45, 'folder': dir_path, 'used': False}
    trip_pool = []
    invoice_pdf_pool = [] # æ²¡æœ‰XMLçš„å‘ç¥¨PDFå€™é€‰
    
    # é¢„æ‰«æ PDF
    for pdf in pdf_files:
        try:
            with pdfplumber.open(pdf) as p:
                if not p.pages: continue
                text = normalize_text(p.pages[0].extract_text())
                amount = find_max_valid_amount(text)
                folder = os.path.dirname(pdf) # è·å–ç‰©ç†æ–‡ä»¶å¤¹è·¯å¾„ (Scope)
                
                if is_trip_file(os.path.basename(pdf), text):
                    trip_pool.append({'path': pdf, 'amount': amount, 'folder': folder, 'used': False})
                else:
                    # åªè¦ä¸æ˜¯è¡Œç¨‹å•ï¼Œéƒ½è§†ä¸ºå‘ç¥¨å€™é€‰
                    invoice_pdf_pool.append({'path': pdf, 'amount': amount, 'folder': folder})
        except: pass

    excel_rows = []
    idx = 1
    processed_invoice_pdfs = set() # è®°å½•å·²è¢«å¤„ç†çš„PDFè·¯å¾„

    # --- é˜¶æ®µ A: ä¼˜å…ˆå¤„ç† XML (å‡†ç¡®åº¦æœ€é«˜) ---
    for xml in xml_files:
        inv_info = parse_xml_invoice_data(xml)
        if not inv_info: continue
        
        row = {
            "åºå·": idx, "å‘ç¥¨å·ç ": inv_info['num'], "å¼€ç¥¨æ—¥æœŸ": inv_info['date'],
            "é”€å”®æ–¹åç§°": inv_info['seller'], "ä»·ç¨åˆè®¡": inv_info['amount'], 
            "æ•°æ®æ¥æº": "XML", "æ–‡ä»¶å": os.path.basename(xml), "å¤‡æ³¨": "æ­£å¸¸"
        }
        
        # 1. åœ¨åŒç›®å½•ä¸‹æ‰¾å¯¹åº”çš„å‘ç¥¨ PDF
        xml_folder = os.path.dirname(xml) # é”å®š Scope
        target_invoice_pdf = None
        
        # ç­›é€‰ï¼šScope å¿…é¡»ç›¸åŒ
        potential_invs = [p['path'] for p in invoice_pdf_pool if p['folder'] == xml_folder]
        xml_base = os.path.splitext(os.path.basename(xml))[0]
        
        for p_path in potential_invs:
            p_name = os.path.basename(p_path)
            # åŒ¹é…é€»è¾‘ï¼šåŒå OR åŒ…å«å‘ç¥¨å·
            if xml_base in p_name or (inv_info['num'] and inv_info['num'] in p_name):
                target_invoice_pdf = p_path
                break
        
        # å¦‚æœæ‰¾åˆ°äº† PDF
        if target_invoice_pdf:
            processed_invoice_pdfs.add(target_invoice_pdf)
            
            # 2. åœ¨åŒç›®å½•ä¸‹æ‰¾åŒ¹é…çš„è¡Œç¨‹å• (Strict Match)
            matched_trip = None
            candidate_trips = [t for t in trip_pool if t['folder'] == xml_folder and not t['used']]
            
            for trip in candidate_trips:
                # åŒ¹é…é€»è¾‘ï¼šé‡‘é¢ä¸€è‡´ (è¯¯å·® < 0.05)
                if abs(trip['amount'] - inv_info['amount']) < 0.05:
                    matched_trip = trip
                    trip['used'] = True
                    break
            
            if matched_trip:
                try:
                    merger = PdfWriter()
                    merger.append(target_invoice_pdf)
                    merger.append(matched_trip['path'])
                    # å®‰å…¨æ–‡ä»¶å
                    safe_name = f"{inv_info['num']}_{inv_info['amount']}.pdf".replace(':','').replace('/','_')
                    merger.write(os.path.join(merged_pdf_dir, safe_name))
                    merger.close()
                    row['å¤‡æ³¨'] = "å·²åˆå¹¶è¡Œç¨‹å•"
                except: pass
            else:
                # æ²¡æ‰¾åˆ°è¡Œç¨‹å•ï¼Œå¤åˆ¶åŸ PDF åˆ° No_XML (ä½œä¸ºæœªåˆå¹¶å‘ç¥¨)
                try: shutil.copy2(target_invoice_pdf, os.path.join(no_xml_pdf_dir, os.path.basename(target_invoice_pdf)))
                except: pass
        
        excel_rows.append(row)
        idx += 1

    # --- é˜¶æ®µ B: å¤„ç†æ—  XML çš„ PDF å‘ç¥¨ ---
    for inv_pdf in invoice_pdf_pool:
        if inv_pdf['path'] in processed_invoice_pdfs: continue
        
        # æå–å‘ç¥¨æ•°æ®
        pdf_data = extract_data_from_pdf_simple(inv_pdf['path'])
        if not pdf_data: continue
        
        # åœ¨åŒç›®å½•ä¸‹æ‰¾åŒ¹é…è¡Œç¨‹å•
        matched_trip = None
        folder = inv_pdf['folder'] # é”å®š Scope
        candidate_trips = [t for t in trip_pool if t['folder'] == folder and not t['used']]
        
        for trip in candidate_trips:
            # é‡‘é¢å¿…é¡»æœ‰æ•ˆ(>0)ä¸”ä¸€è‡´
            if inv_pdf['amount'] > 0 and abs(trip['amount'] - inv_pdf['amount']) < 0.05:
                matched_trip = trip
                trip['used'] = True
                break
        
        # æœ‰åŒ¹é…åˆ™åˆå¹¶ï¼Œæ— åŒ¹é…åˆ™ä¿ç•™åŸä»¶
        if matched_trip:
            try:
                merger = PdfWriter()
                merger.append(inv_pdf['path'])
                merger.append(matched_trip['path'])
                
                num = pdf_data.get('å‘ç¥¨å·ç ', 'NoNum')
                amt = inv_pdf['amount']
                safe_name = f"{num}_{amt}.pdf".replace(':','').replace('/','_')
                merger.write(os.path.join(merged_pdf_dir, safe_name))
                merger.close()
                
                pdf_data['å¤‡æ³¨'] = "å·²åˆå¹¶è¡Œç¨‹å•(PDFåŒ¹é…)"
                # ç¡®ä¿ Excel é‡Œé‡‘é¢æ˜¯å‡†ç¡®çš„ï¼ˆä¼˜å…ˆä¿¡ PDF æå–çš„ï¼Œæˆ–è€…è¡Œç¨‹å•çš„ï¼‰
                if pdf_data['ä»·ç¨åˆè®¡'] == 0: pdf_data['ä»·ç¨åˆè®¡'] = amt
            except: pass
        else:
            try:
                shutil.copy2(inv_pdf['path'], os.path.join(no_xml_pdf_dir, os.path.basename(inv_pdf['path'])))
            except: pass
        
        # è¡¥å…¨åºå·å¹¶æ·»åŠ 
        pdf_data['åºå·'] = idx
        excel_rows.append(pdf_data)
        idx += 1

    # --- é˜¶æ®µ C: å…œåº• (ä¿ç•™æœªä½¿ç”¨çš„è¡Œç¨‹å•) ---
    for trip in trip_pool:
        if not trip['used']:
            try: shutil.copy2(trip['path'], os.path.join(no_xml_pdf_dir, os.path.basename(trip['path'])))
            except: pass

    # ç”Ÿæˆ Excel
    if excel_rows:
        df = pd.DataFrame(excel_rows)
        # ç¡®ä¿åˆ—é¡ºåº
        cols = ["åºå·", "å‘ç¥¨å·ç ", "å¼€ç¥¨æ—¥æœŸ", "é”€å”®æ–¹åç§°", "ä»·ç¨åˆè®¡", "æ•°æ®æ¥æº", "å¤‡æ³¨", "æ–‡ä»¶å"]
        for c in cols: 
            if c not in df.columns: df[c] = ""
        df = df[cols]
        
        # æ ¼å¼åŒ–é‡‘é¢
        df['ä»·ç¨åˆè®¡'] = pd.to_numeric(df['ä»·ç¨åˆè®¡'], errors='coerce').fillna(0.0)
        
        # æ·»åŠ æ€»è®¡è¡Œ
        sum_row = {"åºå·": "æ€»è®¡", "ä»·ç¨åˆè®¡": df['ä»·ç¨åˆè®¡'].sum(), "é”€å”®æ–¹åç§°": f"å…± {len(df)} å¼ "}
        df = pd.concat([df, pd.DataFrame([sum_row])], ignore_index=True)
        
        excel_path = os.path.join(output_dir, 'Summary_Final.xlsx')
        df.to_excel(excel_path, index=False)
        return excel_path, merged_pdf_dir, no_xml_pdf_dir
    
    return None, None, None

# ==========================================
# 4. Streamlit ç•Œé¢
# ==========================================

def main():
    st.set_page_config(page_title="å‘ç¥¨æ— å¿§ V8.0 (é—­ç¯ç‰ˆ)", layout="wide")
    st.title("ğŸ§¾ å‘ç¥¨æ— å¿§ V8.0 (ä¸¥æ ¼é—­ç¯åŒ¹é…)")
    st.info("åŠŸèƒ½ï¼šä¸Šä¼  ZIP/æ–‡ä»¶å¤¹ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨åœ¨ã€åŒä¸€ä¸ªåŒ…å†…ã€‘ä¸¥æ ¼åŒ¹é…å‘ç¥¨å’Œè¡Œç¨‹å•ã€‚")

    uploaded_files = st.file_uploader(
        "è¯·ä¸Šä¼ å‘ç¥¨ ZIP (æ”¯æŒå¤šåŒ…ä¸Šä¼ )", 
        type=['zip', 'xml', 'pdf'], 
        accept_multiple_files=True
    )

    if uploaded_files and st.button("å¼€å§‹å¤„ç†"):
        with st.spinner('æ­£åœ¨åˆ†æ (ä¿æŒæ–‡ä»¶åŒ…éš”ç¦»)...'):
            with tempfile.TemporaryDirectory() as temp_dir:
                # input_root æ˜¯æ‰€æœ‰ scope æ–‡ä»¶å¤¹çš„çˆ¶çº§
                input_root = os.path.join(temp_dir, "input_root")
                os.makedirs(input_root, exist_ok=True)
                
                # === å…³é”®ï¼šä¸ºæ¯ä¸ªä¸Šä¼ é¡¹å»ºç«‹ç‹¬ç«‹æ–‡ä»¶å¤¹ (Scope) ===
                for i, up_file in enumerate(uploaded_files):
                    # æ–‡ä»¶å¤¹å: index_filename
                    safe_foldername = f"scope_{i}_{re.sub(r'[^a-zA-Z0-9]', '_', up_file.name)}"
                    file_scope_dir = os.path.join(input_root, safe_foldername)
                    os.makedirs(file_scope_dir, exist_ok=True)
                    
                    save_path = os.path.join(file_scope_dir, up_file.name)
                    with open(save_path, "wb") as f:
                        f.write(up_file.getbuffer())
                    
                    # å¦‚æœæ˜¯ ZIPï¼Œè§£å‹åˆ°å½“å‰ Scope
                    if up_file.name.lower().endswith('.zip'):
                        extract_zip_with_encoding(save_path, file_scope_dir)
                        os.remove(save_path) # åˆ é™¤åŸ ZIP
                
                # æ‰§è¡Œå¤„ç†
                output_dir = os.path.join(temp_dir, "output")
                excel, merged, noxml = run_process_pipeline(input_root, output_dir)
                
                if excel:
                    st.success("å¤„ç†å®Œæˆï¼")
                    st.dataframe(pd.read_excel(excel).tail(5))
                    
                    # æ‰“åŒ…ç»“æœ
                    res_zip = os.path.join(temp_dir, "Result.zip")
                    with zipfile.ZipFile(res_zip, 'w', zipfile.ZIP_DEFLATED) as z:
                        z.write(excel, "æ±‡æ€»è¡¨.xlsx")
                        for r, _, fs in os.walk(merged):
                            for f in fs: z.write(os.path.join(r, f), f"åˆå¹¶åå‘ç¥¨/{f}")
                        for r, _, fs in os.walk(noxml):
                            for f in fs: z.write(os.path.join(r, f), f"ç‹¬ç«‹å‘ç¥¨/{f}")
                            
                    with open(res_zip, "rb") as f:
                        st.download_button("ä¸‹è½½ç»“æœåŒ…", f, "Invoices_Scoped.zip")
                else:
                    st.error("æœªæ‰¾åˆ°æœ‰æ•ˆå‘ç¥¨ã€‚")

if __name__ == "__main__":
    main()