import streamlit as st
import os
import zipfile
import shutil
import tempfile
import re
import pandas as pd
import pdfplumber
import xml.etree.ElementTree as ET
from pypdf import PdfWriter
from difflib import SequenceMatcher

# ==========================================
# 1. åŸºç¡€å·¥å…·å‡½æ•°
# ==========================================

def extract_zip_with_encoding(zip_path, extract_to):
    """è§£å‹ ZIP å¹¶ä¿®å¤ä¸­æ–‡ä¹±ç """
    with zipfile.ZipFile(zip_path, 'r') as z:
        for file_info in z.infolist():
            try:
                # å°è¯•ä¿®å¤æ–‡ä»¶åç¼–ç  (CP437 -> GBK)
                if file_info.flag_bits & 0x800 == 0:
                    original_name = file_info.filename.encode('cp437').decode('gbk')
                else:
                    original_name = file_info.filename
            except:
                try: original_name = file_info.filename.encode('utf-8').decode('utf-8')
                except: original_name = file_info.filename

            if "__MACOSX" in original_name or ".DS_Store" in original_name:
                continue

            target_path = os.path.join(extract_to, original_name)
            parent_dir = os.path.dirname(target_path)
            if parent_dir and not os.path.exists(parent_dir):
                os.makedirs(parent_dir, exist_ok=True)
                
            if not original_name.endswith('/'):
                with z.open(file_info) as source, open(target_path, "wb") as target:
                    shutil.copyfileobj(source, target)

def normalize_text(text):
    """æ–‡æœ¬æ¸…æ´—"""
    if not text: return ""
    return text.replace(" ", "").replace("\n", "").replace("\r", "")\
               .replace("ï¼š", ":").replace("ï¿¥", "Â¥")\
               .replace("ï¼ˆ", "(").replace("ï¼‰", ")")\
               .replace("O", "0")

def format_date(date_str):
    """ç»Ÿä¸€æ—¥æœŸæ ¼å¼ YYYY-MM-DD"""
    if not date_str: return ""
    m = re.search(r'(\d{4})[-å¹´/.](\d{1,2})[-æœˆ/.](\d{1,2})', date_str)
    if m:
        return f"{m.group(1)}-{int(m.group(2)):02d}-{int(m.group(3)):02d}"
    return ""

# ==========================================
# 2. æ ¸å¿ƒé€»è¾‘ï¼šæ–‡ä»¶ç±»å‹åˆ¤å®šä¸åŒ¹é…
# ==========================================

def is_trip_file(filename, text=None):
    """
    åˆ¤æ–­æ˜¯å¦ä¸ºè¡Œç¨‹å•/æŠ¥é”€å•
    """
    fn = filename.lower()
    
    # 1. æ–‡ä»¶åç‰¹å¾ (å¢åŠ  'æŠ¥é”€å•')
    if "è¡Œç¨‹" in fn or "trip" in fn or "æŠ¥é”€" in fn:
        if text:
            clean = normalize_text(text)
            # é˜²è¯¯åˆ¤é€»è¾‘ï¼šåªæœ‰å½“å‡ºç°æ˜ç¡®çš„"å‘ç¥¨å·ç +æ•°å­—"æ—¶ï¼Œæ‰è®¤ä¸ºå®ƒæ˜¯å‘ç¥¨
            # ä»…æœ‰"ç”µå­å‘ç¥¨"å››ä¸ªå­—ï¼ˆå¦‚å…è´£å£°æ˜ï¼‰ä¸ä½œä¸ºæ’é™¤ä¾æ®
            if re.search(r'å‘ç¥¨å·ç [:|]?\d{8}', clean):
                return False
            # æŸäº›è¡Œç¨‹å•è™½ç„¶å«"å‘ç¥¨"å­—æ ·ï¼Œä½†å¦‚æœæœ‰"è¡Œç¨‹å•"æˆ–"Trip"å­—æ ·ä¸”æ— å‘ç¥¨å·ï¼Œä»è§†ä¸ºè¡Œç¨‹å•
        return True
        
    # 2. å†…å®¹ç‰¹å¾å…œåº•
    if text:
        clean = normalize_text(text)
        if ("è¡Œç¨‹å•" in clean or "triptable" in clean) and not re.search(r'å‘ç¥¨å·ç [:|]?\d{8}', clean):
             return True

    return False

def clean_filename_for_matching(filename):
    """æ¸…æ´—æ–‡ä»¶åï¼Œæå–æ ¸å¿ƒç‰¹å¾"""
    name = os.path.splitext(filename)[0]
    # å»é™¤é€šç”¨æ— æ„ä¹‰è¯æ±‡ï¼Œä¿ç•™æ ¸å¿ƒæ ‡è¯†(å¦‚è®¢å•å·ã€äººå)
    keywords = [
        "ç”µå­å‘ç¥¨", "æ™®é€šå‘ç¥¨", "å‘ç¥¨", "invoice", 
        "è¡Œç¨‹æŠ¥é”€å•", "æŠ¥é”€å•", "è¡Œç¨‹å•", "è¡Œç¨‹", "trip", "travel",
        "æ»´æ»´", "å‡ºè¡Œ", "å®¢ç¥¨", "èˆªç©º", "æœºç¥¨",
        "copy", "å‰¯æœ¬", "ä¸‹è½½", "download"
    ]
    for k in keywords:
        name = name.replace(k, "")
    # å»é™¤ç¬¦å·
    name = re.sub(r'[ _\-\(\)ï¼ˆï¼‰]', "", name)
    return name.lower()

def is_filename_match(name1, name2):
    """åˆ¤æ–­ä¸¤ä¸ªæ–‡ä»¶åæ˜¯å¦é«˜åº¦ç›¸å…³"""
    c1 = clean_filename_for_matching(name1)
    c2 = clean_filename_for_matching(name2)
    if not c1 or not c2: return False
    # åŒ…å«å…³ç³»æˆ–é«˜åº¦ç›¸ä¼¼
    if c1 in c2 or c2 in c1: return True
    return SequenceMatcher(None, c1, c2).ratio() > 0.85

def get_matching_trip_advanced(invoice_amount, invoice_filename, folder, trip_pool):
    """
    å¢å¼ºåŒ¹é…å¼•æ“ï¼šæ–‡ä»¶ååŒ¹é…ä¼˜å…ˆ -> é‡‘é¢æ ¡éªŒ
    """
    # ç­›é€‰åŒ Scope (åŒæ–‡ä»¶å¤¹) ä¸‹æœªä½¿ç”¨çš„è¡Œç¨‹å•
    candidates = [t for t in trip_pool if t['folder'] == folder and not t['used']]
    if not candidates: return None, None

    # --- ç­–ç•¥ A: ä¼˜å…ˆæ–‡ä»¶ååŒ¹é… (ç¬¦åˆç”¨æˆ·"ä¸€ä¸€åŒ¹é…"çš„æè¿°) ---
    for t in candidates:
        if is_filename_match(invoice_filename, os.path.basename(t['path'])):
            # æ‰¾åˆ°æ–‡ä»¶ååŒ¹é…çš„ï¼Œç«‹å³æ ¡éªŒé‡‘é¢
            trip_amt = t['amount']
            inv_amt = invoice_amount if invoice_amount > 0 else 0
            
            # é‡‘é¢æ ¡éªŒ (å…è®¸ 0.1 å…ƒè¯¯å·®)
            if inv_amt > 0 and trip_amt > 0:
                if abs(trip_amt - inv_amt) < 0.1:
                    return t, "æ­£å¸¸(æ–‡ä»¶å+é‡‘é¢åŒ¹é…)"
                else:
                    # é‡‘é¢ä¸ç¬¦ï¼Œä½†æ–‡ä»¶ååŒ¹é…ï¼Œä¾ç„¶åˆå¹¶ï¼Œä½†æ ‡è®°éœ€å¤æ ¸
                    return t, f"âŒ é‡‘é¢ä¸ç¬¦(å‘ç¥¨:{inv_amt} vs è¡Œç¨‹:{trip_amt}) éœ€äººå·¥å¤æ ¸"
            else:
                # å…¶ä¸­ä¸€æ–¹æ²¡è¯»åˆ°é‡‘é¢ï¼Œä½†æ–‡ä»¶åå¯¹äº†ï¼Œä¹Ÿåˆå¹¶
                return t, "æ–‡ä»¶ååŒ¹é…-é‡‘é¢ç¼ºå¤±(éœ€æ ¸å¯¹)"

    # --- ç­–ç•¥ B: é‡‘é¢ç²¾å‡†åŒ¹é… (ä½œä¸ºè¡¥å……) ---
    # å¦‚æœæ–‡ä»¶åæ²¡å¯¹ä¸Šï¼ˆå¯èƒ½é‡å‘½åäº†ï¼‰ï¼Œä½†é‡‘é¢å®Œå…¨ä¸€è‡´ï¼Œä¹Ÿè®¤
    if invoice_amount > 0:
        for t in candidates:
            if abs(t['amount'] - invoice_amount) < 0.05:
                return t, "é‡‘é¢åŒ¹é…(æ–‡ä»¶åä¸ç¬¦)"
    
    # --- ç­–ç•¥ C: åŒåŒ…å”¯ä¸€æ€§å…œåº• ---
    # ä¸€ä¸ªåŒ…é‡Œå‰©æœ€åä¸€å¼ å‘ç¥¨å’Œä¸€å¼ è¡Œç¨‹å•
    if len(candidates) == 1:
        return candidates[0], "å”¯ä¸€åŒ¹é…(æ…ç”¨-éœ€æ ¸å¯¹)"

    return None, None

# ==========================================
# 3. æ•°æ®æå– (å«å¤§å†™è§£æ)
# ==========================================

def cn_upper_to_float(cn_str):
    """ä¸­æ–‡å¤§å†™é‡‘é¢è½¬æ•°å­—"""
    if not cn_str: return 0.0
    CN_NUM = {'é›¶': 0, 'å£¹': 1, 'è´°': 2, 'å': 3, 'è‚†': 4, 'ä¼': 5, 'é™†': 6, 'æŸ’': 7, 'æŒ': 8, 'ç–': 9,
              'ä¸€': 1, 'äºŒ': 2, 'ä¸‰': 3, 'å››': 4, 'äº”': 5, 'å…­': 6, 'ä¸ƒ': 7, 'å…«': 8, 'ä¹': 9, 'ä¸¤': 2}
    CN_UNIT = {'æ‹¾': 10, 'å': 10, 'ä½°': 100, 'ç™¾': 100, 'ä»Ÿ': 1000, 'åƒ': 1000, 'ä¸‡': 10000, 'äº¿': 100000000}
    parts = re.split(r'[åœ†å…ƒ]', cn_str)
    integer_str = parts[0]
    decimal_str = parts[1] if len(parts) > 1 else ""
    
    def parse_section(s):
        val = 0; curr = 0; unit_val = 0
        for c in s:
            if c in CN_NUM: curr = CN_NUM[c]
            elif c in CN_UNIT:
                if c in ['ä¸‡', 'äº¿']: val = (val + unit_val + curr) * CN_UNIT[c]; unit_val = 0; curr = 0
                else: unit_val += curr * CN_UNIT[c]; curr = 0
        return val + unit_val + curr
    
    total = parse_section(integer_str)
    dec = 0.0; curr = 0
    for c in decimal_str:
        if c in CN_NUM: curr = CN_NUM[c]
        elif c == 'è§’': dec += curr * 0.1; curr = 0
        elif c == 'åˆ†': dec += curr * 0.01; curr = 0
    return round(total + dec, 2)

def find_amount_strict(text):
    """ä¸¥æ ¼é‡‘é¢æå–"""
    if not text: return 0.0, "ç©ºç™½"
    
    # 1. å¤§å†™ä¼˜å…ˆ
    up_m = re.search(r'(?:ä»·ç¨åˆè®¡|å¤§å†™|é‡‘é¢).*?([é›¶å£¹è´°åè‚†ä¼é™†æŸ’æŒç–æ‹¾ä½°ä»Ÿä¸‡äº¿åœ†è§’åˆ†æ•´]+)', text)
    amt_up = 0.0
    if up_m:
        try: amt_up = cn_upper_to_float(up_m.group(1))
        except: pass
    
    # 2. å°å†™æ ¡éªŒ
    lo_m = re.search(r'(?:å°å†™|Â¥|ï¿¥|åˆè®¡)[^0-9\.]*([0-9]{1,3}(?:,[0-9]{3})*\.[0-9]{2})', text)
    amt_lo = 0.0
    if lo_m:
        try: 
            v = float(lo_m.group(1).replace(",", ""))
            if 0.01 <= v <= 5000000: amt_lo = v
        except: pass

    # 3. å…œåº• (å…¨æ–‡æœ€å¤§å€¼)
    if amt_up == 0 and amt_lo == 0:
        matches = re.findall(r'(\d{1,3}(?:,\d{3})*\.\d{2})', text)
        valid = []
        for m in matches:
            try:
                v = float(m.replace(",", ""))
                if 0.01 <= v <= 5000000 and v not in [0.06, 0.03, 0.13, 0.01, 1.00]: valid.append(v)
            except: continue
        if valid: amt_lo = max(valid)

    if amt_up > 0:
        if amt_lo > 0 and abs(amt_up - amt_lo) > 0.1:
            return amt_up, f"âš ï¸ å¤§å°å†™ä¸ç¬¦({amt_up} vs {amt_lo})"
        return amt_up, "æ­£å¸¸"
    
    if amt_lo > 0: return amt_lo, "ä½¿ç”¨å°å†™"
    return 0.0, "è­¦å‘Š:æœªè¯»åˆ°é‡‘é¢"

def extract_seller_name_smart(text):
    suffix = r"[\u4e00-\u9fa5()ï¼ˆï¼‰]{2,30}(?:å…¬å¸|äº‹åŠ¡æ‰€|é…’åº—|æ—…è¡Œç¤¾|ç»è¥éƒ¨|æœåŠ¡éƒ¨|åˆ†è¡Œ|æ”¯è¡Œ|é¦†|åº—|å¤„|ä¸­å¿ƒ)"
    candidates = list(set(re.findall(suffix, text)))
    blacklist = ["ç¨åŠ¡å±€", "è´¢æ”¿éƒ¨", "è´­ä¹°æ–¹", "å¼€æˆ·è¡Œ", "é“¶è¡Œ", "åœ°å€", "ç”µè¯", "çº³ç¨äºº", "é€‚ç”¨ç¨ç‡"]
    filtered = [c for c in candidates if not any(b in c for b in blacklist) and len(c) >= 4]
    return max(filtered, key=len) if filtered else ""

def parse_xml_invoice_data(xml_path):
    try:
        tree = ET.parse(xml_path)
        root = tree.getroot()
        def g(path): return root.find(path).text if root.find(path) is not None else ""
        num = g(".//TaxSupervisionInfo/InvoiceNumber") or g(".//InvoiceNumber") or g(".//Fphm")
        date = g(".//TaxSupervisionInfo/IssueTime") or g(".//IssueTime") or g(".//Kprq")
        seller = g(".//SellerInformation/SellerName") or g(".//Xfmc")
        amt_str = g(".//BasicInformation/TotalTax-includedAmount") or g(".//TotalTax-includedAmount") or g(".//TotalAmount")
        amount = float(amt_str.replace(',', '')) if amt_str else 0.0
        return {"num": num, "date": format_date(date), "seller": seller, "amount": amount}
    except: return None

def extract_data_from_pdf_simple(pdf_path):
    try:
        with pdfplumber.open(pdf_path) as p:
            if not p.pages: return None
            raw = p.pages[0].extract_text()
            if not raw or len(raw.strip()) < 10: 
                return {"å‘ç¥¨å·ç ":"", "ä»·ç¨åˆè®¡":0.0, "æ–‡ä»¶å":os.path.basename(pdf_path), "å¤‡æ³¨":"âš ï¸ çº¯å›¾/æ‰«æä»¶"}
            
            text = normalize_text(raw)
            num = ""
            m = re.search(r'(\d{20})', text)
            if m: num = m.group(1)
            else:
                m8 = re.search(r'(?:å·ç |No)[:|]?(\d{8,})', text)
                if m8: num = m8.group(1)
            
            date = ""
            md = re.search(r'(\d{4}[-å¹´/.]\d{1,2}[-æœˆ/.]\d{1,2}æ—¥?)', text)
            if md: date = format_date(md.group(1))
            
            amt, note = find_amount_strict(text)
            seller = extract_seller_name_smart(text)
            
            if not num and amt > 0: note = "æ— å‘ç¥¨å·-" + note
            return {"å‘ç¥¨å·ç ": num, "å¼€ç¥¨æ—¥æœŸ": date, "é”€å”®æ–¹åç§°": seller, "ä»·ç¨åˆè®¡": amt, "æ–‡ä»¶å": os.path.basename(pdf_path), "å¤‡æ³¨": note}
    except: return None

# ==========================================
# 4. æ ¡éªŒå¼•æ“ (Verifier)
# ==========================================

class InvoiceVerifier:
    def __init__(self, processed_df):
        self.processed_nums = {} 
        self.processed_attrs = {}
        for _, row in processed_df.iterrows():
            p_num = str(row.get('å‘ç¥¨å·ç ', '')).strip()
            p_amt = float(row.get('ä»·ç¨åˆè®¡', 0))
            p_date = str(row.get('å¼€ç¥¨æ—¥æœŸ', '')).strip()
            
            if p_num and len(p_num) > 6:
                self.processed_nums[p_num] = {'amount': p_amt}
            
            attr_key = (f"{p_amt:.2f}", p_date)
            self.processed_attrs[attr_key] = True

    def check(self, raw_info):
        raw_num = str(raw_info.get('num') or raw_info.get('å‘ç¥¨å·ç ') or '').strip()
        raw_amt = float(raw_info.get('amount') or raw_info.get('ä»·ç¨åˆè®¡') or 0)
        raw_date = str(raw_info.get('date') or raw_info.get('å¼€ç¥¨æ—¥æœŸ') or '').strip()
        
        # 1. å·ç åŒ¹é…
        if raw_num and len(raw_num) > 6:
            if raw_num in self.processed_nums: return True
        
        # 2. é‡‘é¢+æ—¥æœŸåŒ¹é…
        if raw_amt > 0:
            if (f"{raw_amt:.2f}", raw_date) in self.processed_attrs: return True
        
        return False

# ==========================================
# 5. ä¸»æµç¨‹
# ==========================================

def run_process_pipeline(input_root_dir, output_dir):
    merged_dir = os.path.join(output_dir, 'Merged_PDFs')
    noxml_dir = os.path.join(output_dir, 'No_XML_PDFs')
    os.makedirs(merged_dir, exist_ok=True)
    os.makedirs(noxml_dir, exist_ok=True)

    all_files = []
    for root, dirs, files in os.walk(input_root_dir):
        for f in files: all_files.append(os.path.join(root, f))
    
    xml_files = [f for f in all_files if f.lower().endswith('.xml')]
    pdf_files = [f for f in all_files if f.lower().endswith('.pdf')]
    
    trip_pool = []
    invoice_pdf_pool = []
    
    # é¢„æ‰«æåˆ†ç±»
    for pdf in pdf_files:
        try:
            with pdfplumber.open(pdf) as p:
                if not p.pages: continue
                text = normalize_text(p.pages[0].extract_text())
                amt, _ = find_amount_strict(text)
                folder = os.path.dirname(pdf)
                if is_trip_file(os.path.basename(pdf), text):
                    trip_pool.append({'path': pdf, 'amount': amt, 'folder': folder, 'used': False})
                else:
                    invoice_pdf_pool.append({'path': pdf, 'amount': amt, 'folder': folder})
        except: pass

    excel_rows = []
    idx = 1
    processed_source_files = set()

    # --- A. XML å¤„ç† ---
    for xml in xml_files:
        info = parse_xml_invoice_data(xml)
        if not info: continue
        processed_source_files.add(os.path.abspath(xml))
        
        row = {"åºå·": idx, "å‘ç¥¨å·ç ": info['num'], "å¼€ç¥¨æ—¥æœŸ": info['date'],
               "é”€å”®æ–¹åç§°": info['seller'], "ä»·ç¨åˆè®¡": info['amount'], 
               "æ•°æ®æ¥æº": "XML", "æ–‡ä»¶å": os.path.basename(xml), "å¤‡æ³¨": "æ­£å¸¸"}
        
        folder = os.path.dirname(xml)
        target_pdf = None
        cands = [p['path'] for p in invoice_pdf_pool if p['folder'] == folder]
        xml_base = os.path.splitext(os.path.basename(xml))[0]
        
        for p in cands:
            if xml_base in os.path.basename(p) or (info['num'] and info['num'] in os.path.basename(p)):
                target_pdf = p; break
        
        if target_pdf:
            processed_source_files.add(os.path.abspath(target_pdf))
            # æ™ºèƒ½åŒ¹é…
            matched_trip, match_remark = get_matching_trip_advanced(
                info['amount'], os.path.basename(target_pdf), folder, trip_pool
            )
            
            if matched_trip:
                matched_trip['used'] = True
                processed_source_files.add(os.path.abspath(matched_trip['path']))
                try:
                    merger = PdfWriter()
                    merger.append(target_pdf); merger.append(matched_trip['path'])
                    safe_name = f"{info['num']}_{info['amount']}.pdf".replace(':','').replace('/','_')
                    merger.write(os.path.join(merged_dir, safe_name)); merger.close()
                    row['å¤‡æ³¨'] = match_remark
                except:
                    shutil.copy2(target_pdf, os.path.join(noxml_dir, os.path.basename(target_pdf)))
                    row['å¤‡æ³¨'] = "åˆå¹¶å¤±è´¥-ä¿ç•™åŸä»¶"
            else:
                shutil.copy2(target_pdf, os.path.join(noxml_dir, os.path.basename(target_pdf)))
        else:
             row['å¤‡æ³¨'] = "ä»…XML(ç¼ºPDF)"
        
        excel_rows.append(row); idx += 1

    # --- B. PDF å¤„ç† ---
    for inv in invoice_pdf_pool:
        if os.path.abspath(inv['path']) in processed_source_files: continue
        
        data = extract_data_from_pdf_simple(inv['path'])
        if not data: continue
        processed_source_files.add(os.path.abspath(inv['path']))
        
        folder = inv['folder']
        matched_trip, match_remark = get_matching_trip_advanced(
            inv['amount'], os.path.basename(inv['path']), folder, trip_pool
        )
        
        if matched_trip:
            matched_trip['used'] = True
            processed_source_files.add(os.path.abspath(matched_trip['path']))
            try:
                merger = PdfWriter()
                merger.append(inv['path']); merger.append(matched_trip['path'])
                num = data.get('å‘ç¥¨å·ç ', 'NoNum')
                safe_name = f"{num}_{inv['amount']}.pdf".replace(':','').replace('/','_')
                merger.write(os.path.join(merged_dir, safe_name)); merger.close()
                data['å¤‡æ³¨'] = match_remark
            except:
                shutil.copy2(inv['path'], os.path.join(noxml_dir, os.path.basename(inv['path'])))
                data['å¤‡æ³¨'] = "åˆå¹¶å¤±è´¥-ä¿ç•™åŸä»¶"
        else:
            shutil.copy2(inv['path'], os.path.join(noxml_dir, os.path.basename(inv['path'])))
            
        data['åºå·'] = idx; excel_rows.append(data); idx += 1

    # --- C. å‰©ä½™è¡Œç¨‹å• ---
    for t in trip_pool:
        if not t['used']:
            processed_source_files.add(os.path.abspath(t['path']))
            try: shutil.copy2(t['path'], os.path.join(noxml_dir, os.path.basename(t['path'])))
            except: pass

    # --- D. ç”Ÿæˆä¸æ ¸å¯¹ ---
    excel_path = None
    df_result = pd.DataFrame()
    if excel_rows:
        df_result = pd.DataFrame(excel_rows)
        cols = ["åºå·", "å‘ç¥¨å·ç ", "å¼€ç¥¨æ—¥æœŸ", "é”€å”®æ–¹åç§°", "ä»·ç¨åˆè®¡", "æ•°æ®æ¥æº", "å¤‡æ³¨", "æ–‡ä»¶å"]
        for c in cols: 
            if c not in df_result.columns: df_result[c] = ""
        df_result = df_result[cols]
        df_result['ä»·ç¨åˆè®¡'] = pd.to_numeric(df_result['ä»·ç¨åˆè®¡'], errors='coerce').fillna(0.0)
        
        sum_row = {"åºå·": "æ€»è®¡", "ä»·ç¨åˆè®¡": df_result['ä»·ç¨åˆè®¡'].sum(), "é”€å”®æ–¹åç§°": f"å…± {len(df_result)} å¼ "}
        df_disp = pd.concat([df_result, pd.DataFrame([sum_row])], ignore_index=True)
        excel_path = os.path.join(output_dir, 'Summary_Final.xlsx')
        df_disp.to_excel(excel_path, index=False)

    missing_files = []
    if not df_result.empty:
        verifier = InvoiceVerifier(df_result)
        for f in all_files:
            if not f.lower().endswith(('.pdf', '.xml')): continue
            raw_info = None
            try:
                if f.lower().endswith('.xml'): raw_info = parse_xml_invoice_data(f)
                else: raw_info = extract_data_from_pdf_simple(f)
            except: pass
            
            is_missing = True
            if raw_info:
                if "çº¯å›¾" in raw_info.get('å¤‡æ³¨', ''): is_missing = True
                elif verifier.check(raw_info): is_missing = False
            
            if is_missing: missing_files.append(f)

    return excel_path, merged_dir, noxml_dir, missing_files

# ==========================================
# 6. æ‰‹åŠ¨æ ¸å¯¹åŠŸèƒ½
# ==========================================

def run_manual_check(raw_dir, proc_zip_path, out_dir):
    df_proc = pd.DataFrame()
    with zipfile.ZipFile(proc_zip_path, 'r') as z:
        xls = [n for n in z.namelist() if n.endswith('.xlsx')]
        if xls:
            with z.open(xls[0]) as f: df_proc = pd.read_excel(f)
        else:
            rows = []
            for n in z.namelist():
                if n.endswith('.pdf'):
                    m = re.match(r'(\d+)_([\d\.]+)\.pdf', os.path.basename(n))
                    if m: rows.append({'å‘ç¥¨å·ç ': m.group(1), 'ä»·ç¨åˆè®¡': float(m.group(2))})
            df_proc = pd.DataFrame(rows)

    verifier = InvoiceVerifier(df_proc)
    missing = []
    matched_count = 0
    
    for root, _, files in os.walk(raw_dir):
        for f in files:
            if not f.lower().endswith(('.pdf', '.xml')): continue
            fp = os.path.join(root, f)
            raw_info = None
            try:
                if f.lower().endswith('.xml'): raw_info = parse_xml_invoice_data(fp)
                else: raw_info = extract_data_from_pdf_simple(fp)
            except: pass
            
            if raw_info and verifier.check(raw_info): matched_count += 1
            else: missing.append(fp)
    
    zip_p = None
    if missing:
        zip_p = os.path.join(out_dir, "Manual_Missing.zip")
        with zipfile.ZipFile(zip_p, 'w', zipfile.ZIP_DEFLATED) as z:
            for m in missing: z.write(m, os.path.basename(m))
            
    return matched_count, len(missing), zip_p

# ==========================================
# 7. Streamlit UI
# ==========================================

def main():
    st.set_page_config(page_title="å‘ç¥¨æ— å¿§ V14 (å®Œç¾åŒ¹é…ç‰ˆ)", layout="wide")
    st.title("ğŸ§¾ å‘ç¥¨æ— å¿§ V14 (æ–‡ä»¶åä¼˜å…ˆ + äººå·¥å¤æ ¸)")

    tab1, tab2 = st.tabs(["ğŸš€ ä¸€é”®å¤„ç†", "ğŸ” æ‰‹åŠ¨å¤æ ¸"])

    with tab1:
        st.info("ç­–ç•¥ï¼š1.æ–‡ä»¶åæ ¸å¿ƒåŒ¹é…(ä¼˜å…ˆ) 2.é‡‘é¢åŒ¹é… 3.è‡ªåŠ¨é«˜äº®é‡‘é¢ä¸ç¬¦é¡¹")
        uploaded_files = st.file_uploader("ä¸Šä¼ æ–‡ä»¶", type=['zip', 'xml', 'pdf'], accept_multiple_files=True, key="u1")

        if uploaded_files and st.button("å¼€å§‹å¤„ç†", key="b1"):
            with st.spinner('æ­£åœ¨å¤„ç†...'):
                with tempfile.TemporaryDirectory() as temp_dir:
                    input_root = os.path.join(temp_dir, "input")
                    os.makedirs(input_root, exist_ok=True)
                    for i, up in enumerate(uploaded_files):
                        scope_dir = os.path.join(input_root, f"scope_{i}")
                        os.makedirs(scope_dir, exist_ok=True)
                        save_path = os.path.join(scope_dir, up.name)
                        with open(save_path, "wb") as f: f.write(up.getbuffer())
                        if up.name.endswith('.zip'):
                            extract_zip_with_encoding(save_path, scope_dir)
                            os.remove(save_path)
                    
                    out_dir = os.path.join(temp_dir, "output")
                    excel, merged, noxml, missing_list = run_process_pipeline(input_root, out_dir)
                    
                    st.success("âœ… å®Œæˆï¼")
                    c1, c2 = st.columns(2)
                    if excel:
                        df = pd.read_excel(excel)
                        c1.metric("å·²å½•å…¥", f"{len(df)-1} å¼ ")
                        st.dataframe(df.tail(3))
                        res_zip = os.path.join(temp_dir, "Result.zip")
                        with zipfile.ZipFile(res_zip, 'w', zipfile.ZIP_DEFLATED) as z:
                            z.write(excel, "æ±‡æ€»è¡¨.xlsx")
                            for r, _, fs in os.walk(merged):
                                for f in fs: z.write(os.path.join(r, f), f"åˆå¹¶åå‘ç¥¨/{f}")
                            for r, _, fs in os.walk(noxml):
                                for f in fs: z.write(os.path.join(r, f), f"ç‹¬ç«‹å‘ç¥¨/{f}")
                        with open(res_zip, "rb") as f:
                            st.download_button("ğŸ“¥ ä¸‹è½½ç»“æœ (Result.zip)", f, "Result.zip")

                    c2.metric("é—æ¼", f"{len(missing_list)} ä¸ª", delta_color="inverse")
                    if missing_list:
                        m_zip = os.path.join(temp_dir, "Missing.zip")
                        with zipfile.ZipFile(m_zip, 'w', zipfile.ZIP_DEFLATED) as z:
                            for m in missing_list: z.write(m, f"é—æ¼æ–‡ä»¶/{os.path.basename(m)}")
                        with open(m_zip, "rb") as f:
                            st.download_button("ğŸ“¥ ä¸‹è½½é—æ¼åŒ… (Missing.zip)", f, "Missing.zip", type="primary")

    with tab2:
        st.write("åå‘æ ¸å¯¹å·¥å…·")
        c1, c2 = st.columns(2)
        raw_ups = c1.file_uploader("1. ä¸Šä¼ åŸå§‹æ–‡ä»¶", type=['zip','pdf'], accept_multiple_files=True, key="u2")
        proc_zip = c2.file_uploader("2. ä¸Šä¼  Result.zip", type=['zip'], key="u3")
        
        if raw_ups and proc_zip and st.button("å¼€å§‹æ ¸å¯¹", key="b2"):
            with st.spinner("æ ¸å¯¹ä¸­..."):
                with tempfile.TemporaryDirectory() as td:
                    raw_d = os.path.join(td, "raw")
                    os.makedirs(raw_d, exist_ok=True)
                    for up in raw_ups:
                        p = os.path.join(raw_d, up.name)
                        with open(p, "wb") as f: f.write(up.getbuffer())
                        if p.endswith('.zip'): extract_zip_with_encoding(p, raw_d)
                    
                    pz = os.path.join(td, "proc.zip")
                    with open(pz, "wb") as f: f.write(proc_zip.getbuffer())
                    
                    match, miss, mzip = run_manual_check(raw_d, pz, td)
                    st.metric("âœ… åŒ¹é…æˆåŠŸ", match)
                    st.metric("âŒ é—æ¼", miss)
                    if mzip:
                        with open(mzip, "rb") as f:
                            st.download_button("ğŸ“¥ ä¸‹è½½é—æ¼æ–‡ä»¶", f, "Manual_Missing.zip")

if __name__ == "__main__":
    main()