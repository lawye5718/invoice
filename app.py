import streamlit as st
import os
import zipfile
import shutil
import tempfile
import re
import pandas as pd
import pdfplumber
import xml.etree.ElementTree as ET
from pypdf import PdfWriter

# ==========================================
# 1. åŸºç¡€å·¥å…·å‡½æ•°
# ==========================================

def extract_zip_with_encoding(zip_path, extract_to):
    """è§£å‹ ZIP å¹¶ä¿®å¤ä¸­æ–‡ä¹±ç """
    with zipfile.ZipFile(zip_path, 'r') as z:
        for file_info in z.infolist():
            try:
                if file_info.flag_bits & 0x800 == 0:
                    original_name = file_info.filename.encode('cp437').decode('gbk')
                else:
                    original_name = file_info.filename
            except:
                try: original_name = file_info.filename.encode('utf-8').decode('utf-8')
                except: original_name = file_info.filename

            if "__MACOSX" in original_name or ".DS_Store" in original_name:
                continue

            target_path = os.path.join(extract_to, original_name)
            parent_dir = os.path.dirname(target_path)
            if parent_dir and not os.path.exists(parent_dir):
                os.makedirs(parent_dir, exist_ok=True)
                
            if not original_name.endswith('/'):
                with z.open(file_info) as source, open(target_path, "wb") as target:
                    shutil.copyfileobj(source, target)

def normalize_text(text):
    if not text: return ""
    return text.replace(" ", "").replace("\n", "").replace("\r", "")\
               .replace("ï¼š", ":").replace("ï¿¥", "Â¥")\
               .replace("ï¼ˆ", "(").replace("ï¼‰", ")")

def find_max_valid_amount(text):
    """æå–é‡‘é¢"""
    matches = re.findall(r'(\d{1,3}(?:,\d{3})*\.\d{2})', text)
    valid_amounts = []
    for m in matches:
        try:
            val = float(m.replace(",", ""))
            # æ’é™¤å¸¸è§å¹²æ‰°ï¼šç¨ç‡(0.06/0.13)ã€æ•°é‡(1.00)ã€è¿‡å°çš„é‡‘é¢
            if 0.01 <= val <= 5000000 and val not in [0.06, 0.03, 0.13, 0.01, 1.00]:
                valid_amounts.append(val)
        except: continue
    return max(valid_amounts) if valid_amounts else 0.0

def extract_seller_name_smart(text):
    """æå–é”€å”®æ–¹"""
    suffix_pattern = r"[\u4e00-\u9fa5()ï¼ˆï¼‰]{2,30}(?:å…¬å¸|äº‹åŠ¡æ‰€|é…’åº—|æ—…è¡Œç¤¾|ç»è¥éƒ¨|æœåŠ¡éƒ¨|åˆ†è¡Œ|æ”¯è¡Œ|é¦†|åº—|å¤„|ä¸­å¿ƒ)"
    candidates = list(set(re.findall(suffix_pattern, text)))
    blacklist = ["ç¨åŠ¡å±€", "è´¢æ”¿éƒ¨", "è´­ä¹°æ–¹", "å¼€æˆ·è¡Œ", "é“¶è¡Œ", "åœ°å€", "ç”µè¯", "ç»Ÿä¸€ç¤¾ä¼šä¿¡ç”¨", "çº³ç¨äºº", "é€‚ç”¨ç¨ç‡", "å¯†ç åŒº"]
    filtered = [c for c in candidates if not any(b in c for b in blacklist) and len(c) >= 4]
    return max(filtered, key=len) if filtered else ""

def is_trip_file(filename, text=None):
    """åˆ¤æ–­æ˜¯å¦ä¸ºè¡Œç¨‹å•"""
    fn = filename.lower()
    if "è¡Œç¨‹" in fn or "trip" in fn or "æŠ¥é”€" in fn:
        if text:
            clean = normalize_text(text)
            if "å‘ç¥¨ä»£ç " in clean or "å‘ç¥¨å·ç " in clean or "ç”µå­å‘ç¥¨" in clean:
                return False
        return True
    return False

# ==========================================
# 2. è§£æå‡½æ•°
# ==========================================

def parse_xml_invoice_data(xml_path):
    try:
        tree = ET.parse(xml_path)
        root = tree.getroot()
        def g(path):
            node = root.find(path)
            return node.text if node is not None else ""

        num = g(".//TaxSupervisionInfo/InvoiceNumber") or g(".//InvoiceNumber") or g(".//Fphm")
        date = g(".//TaxSupervisionInfo/IssueTime") or g(".//IssueTime") or g(".//Kprq")
        seller = g(".//SellerInformation/SellerName") or g(".//Xfmc")
        
        amt_str = g(".//BasicInformation/TotalTax-includedAmount") or g(".//TotalTax-includedAmount") or g(".//TotalAmount") or g(".//Jshj")
        # ä¿®å¤é‡‘é¢é€—å·é—®é¢˜
        amount = float(amt_str.replace(',', '')) if amt_str else 0.0

        return {"num": num, "date": date, "seller": seller, "amount": amount}
    except: return None

def extract_data_from_pdf_simple(pdf_path):
    try:
        with pdfplumber.open(pdf_path) as p:
            if not p.pages: return None
            raw = p.pages[0].extract_text()
            if not raw: return None
            text = normalize_text(raw)
            
            num = ""
            m20 = re.search(r'(\d{20})', text)
            if m20: num = m20.group(1)
            else:
                m8 = re.search(r'(?:å·ç |No)[:|]?(\d{8,})', text)
                if m8: num = m8.group(1)
            
            date = ""
            md = re.search(r'(\d{4}[-å¹´/.]\d{1,2}[-æœˆ/.]\d{1,2}æ—¥?)', text)
            if md: date = md.group(1)
            
            amt = find_max_valid_amount(text)
            seller = extract_seller_name_smart(text)
            
            return {
                "å‘ç¥¨å·ç ": num, "å¼€ç¥¨æ—¥æœŸ": date, "é”€å”®æ–¹åç§°": seller,
                "ä»·ç¨åˆè®¡": amt, "æ•°æ®æ¥æº": "PDFè¯†åˆ«", "æ–‡ä»¶å": os.path.basename(pdf_path),
                "å¤‡æ³¨": "æ­£å¸¸" if amt > 0 else "è­¦å‘Š:æœªè¯»åˆ°é‡‘é¢"
            }
    except: return None

# ==========================================
# 3. æ ¸å¿ƒå¤„ç†æµç¨‹ (å«è‡ªåŠ¨æ ¸å¯¹)
# ==========================================

def run_process_pipeline(input_root_dir, output_dir):
    """
    æ‰§è¡Œå¤„ç†å¹¶åœ¨æœ€åè¿›è¡Œè‡ªåŠ¨æ ¸å¯¹
    è¿”å›: excelè·¯å¾„, åˆå¹¶æ–‡ä»¶å¤¹, ç‹¬ç«‹å‘ç¥¨æ–‡ä»¶å¤¹, é—æ¼æ–‡ä»¶åˆ—è¡¨
    """
    merged_pdf_dir = os.path.join(output_dir, 'Merged_PDFs')
    no_xml_pdf_dir = os.path.join(output_dir, 'No_XML_PDFs')
    os.makedirs(merged_pdf_dir, exist_ok=True)
    os.makedirs(no_xml_pdf_dir, exist_ok=True)

    # 1. æ‰«ææ‰€æœ‰æ–‡ä»¶
    all_files = []
    for root, dirs, files in os.walk(input_root_dir):
        for f in files: all_files.append(os.path.join(root, f))
    
    xml_files = [f for f in all_files if f.lower().endswith('.xml')]
    pdf_files = [f for f in all_files if f.lower().endswith('.pdf')]
    
    # 2. å»ºç«‹è¡Œç¨‹å•æ±  & å‘ç¥¨å€™é€‰æ±  (åŒºåˆ† Scope)
    trip_pool = []
    invoice_pdf_pool = []
    
    for pdf in pdf_files:
        try:
            with pdfplumber.open(pdf) as p:
                if not p.pages: continue
                text = normalize_text(p.pages[0].extract_text())
                amt = find_max_valid_amount(text)
                folder = os.path.dirname(pdf)
                
                if is_trip_file(os.path.basename(pdf), text):
                    trip_pool.append({'path': pdf, 'amount': amt, 'folder': folder, 'used': False})
                else:
                    invoice_pdf_pool.append({'path': pdf, 'amount': amt, 'folder': folder})
        except: pass

    excel_rows = []
    idx = 1
    
    # ã€æ ¸å¯¹å…³é”®ã€‘è®°å½•å“ªäº›åŸå§‹æ–‡ä»¶è¢«æˆåŠŸä½¿ç”¨äº†
    processed_source_files = set()

    # --- é˜¶æ®µ A: XML å‘ç¥¨ ---
    for xml in xml_files:
        info = parse_xml_invoice_data(xml)
        if not info: continue
        
        # æ ‡è®° XML ä¸ºå·²å¤„ç†
        processed_source_files.add(os.path.abspath(xml))
        
        row = {
            "åºå·": idx, "å‘ç¥¨å·ç ": info['num'], "å¼€ç¥¨æ—¥æœŸ": info['date'],
            "é”€å”®æ–¹åç§°": info['seller'], "ä»·ç¨åˆè®¡": info['amount'], 
            "æ•°æ®æ¥æº": "XML", "æ–‡ä»¶å": os.path.basename(xml), "å¤‡æ³¨": "æ­£å¸¸"
        }
        
        # æ‰¾ PDF
        folder = os.path.dirname(xml)
        target_pdf = None
        
        # Scope åŒ¹é…
        cands = [p['path'] for p in invoice_pdf_pool if p['folder'] == folder]
        xml_base = os.path.splitext(os.path.basename(xml))[0]
        
        for p in cands:
            if xml_base in os.path.basename(p) or (info['num'] and info['num'] in os.path.basename(p)):
                target_pdf = p
                break
        
        if target_pdf:
            processed_source_files.add(os.path.abspath(target_pdf))
            
            # æ‰¾è¡Œç¨‹å•
            matched_trip = None
            trips = [t for t in trip_pool if t['folder'] == folder and not t['used']]
            for t in trips:
                if abs(t['amount'] - info['amount']) < 0.05:
                    matched_trip = t
                    t['used'] = True
                    break
            
            if matched_trip:
                processed_source_files.add(os.path.abspath(matched_trip['path']))
                try:
                    merger = PdfWriter()
                    merger.append(target_pdf)
                    merger.append(matched_trip['path'])
                    safe_name = f"{info['num']}_{info['amount']}.pdf".replace(':','').replace('/','_')
                    merger.write(os.path.join(merged_pdf_dir, safe_name))
                    merger.close()
                    row['å¤‡æ³¨'] = "å·²åˆå¹¶è¡Œç¨‹å•"
                except:
                    # åˆå¹¶å¤±è´¥ï¼Œå¤åˆ¶åŸä»¶ä½œä¸ºå…œåº•
                    shutil.copy2(target_pdf, os.path.join(no_xml_pdf_dir, os.path.basename(target_pdf)))
                    row['å¤‡æ³¨'] = "åˆå¹¶å¤±è´¥-ä¿ç•™åŸä»¶"
            else:
                shutil.copy2(target_pdf, os.path.join(no_xml_pdf_dir, os.path.basename(target_pdf)))
        
        excel_rows.append(row)
        idx += 1

    # --- é˜¶æ®µ B: æ—  XML çš„ PDF ---
    for inv in invoice_pdf_pool:
        if os.path.abspath(inv['path']) in processed_source_files: continue
        
        data = extract_data_from_pdf_simple(inv['path'])
        if not data: continue
        
        processed_source_files.add(os.path.abspath(inv['path']))
        
        matched_trip = None
        folder = inv['folder']
        trips = [t for t in trip_pool if t['folder'] == folder and not t['used']]
        for t in trips:
            if inv['amount'] > 0 and abs(t['amount'] - inv['amount']) < 0.05:
                matched_trip = t
                t['used'] = True
                break
        
        if matched_trip:
            processed_source_files.add(os.path.abspath(matched_trip['path']))
            try:
                merger = PdfWriter()
                merger.append(inv['path'])
                merger.append(matched_trip['path'])
                num = data.get('å‘ç¥¨å·ç ', 'NoNum')
                safe_name = f"{num}_{inv['amount']}.pdf".replace(':','').replace('/','_')
                merger.write(os.path.join(merged_pdf_dir, safe_name))
                merger.close()
                data['å¤‡æ³¨'] = "å·²åˆå¹¶è¡Œç¨‹å•"
                if data['ä»·ç¨åˆè®¡'] == 0: data['ä»·ç¨åˆè®¡'] = inv['amount']
            except:
                shutil.copy2(inv['path'], os.path.join(no_xml_pdf_dir, os.path.basename(inv['path'])))
                data['å¤‡æ³¨'] = "åˆå¹¶å¤±è´¥-ä¿ç•™åŸä»¶"
        else:
            shutil.copy2(inv['path'], os.path.join(no_xml_pdf_dir, os.path.basename(inv['path'])))
        
        data['åºå·'] = idx
        excel_rows.append(data)
        idx += 1

    # --- é˜¶æ®µ C: å‰©ä½™è¡Œç¨‹å• ---
    for t in trip_pool:
        if not t['used']:
            processed_source_files.add(os.path.abspath(t['path']))
            try: shutil.copy2(t['path'], os.path.join(no_xml_pdf_dir, os.path.basename(t['path'])))
            except: pass

    # --- é˜¶æ®µ D: è‡ªåŠ¨æ ¸å¯¹ (æ‰¾å‡ºé—æ¼æ–‡ä»¶) ---
    missing_files = []
    # è¿‡æ»¤åªæ£€æŸ¥ pdf å’Œ xml
    check_exts = ('.pdf', '.xml')
    for f in all_files:
        if f.lower().endswith(check_exts):
            if os.path.abspath(f) not in processed_source_files:
                missing_files.append(f)

    # ç”Ÿæˆ Excel
    excel_path = None
    if excel_rows:
        df = pd.DataFrame(excel_rows)
        cols = ["åºå·", "å‘ç¥¨å·ç ", "å¼€ç¥¨æ—¥æœŸ", "é”€å”®æ–¹åç§°", "ä»·ç¨åˆè®¡", "æ•°æ®æ¥æº", "å¤‡æ³¨", "æ–‡ä»¶å"]
        for c in cols: 
            if c not in df.columns: df[c] = ""
        df = df[cols]
        df['ä»·ç¨åˆè®¡'] = pd.to_numeric(df['ä»·ç¨åˆè®¡'], errors='coerce').fillna(0.0)
        sum_row = {"åºå·": "æ€»è®¡", "ä»·ç¨åˆè®¡": df['ä»·ç¨åˆè®¡'].sum(), "é”€å”®æ–¹åç§°": f"å…± {len(df)} å¼ "}
        df = pd.concat([df, pd.DataFrame([sum_row])], ignore_index=True)
        excel_path = os.path.join(output_dir, 'Summary_Final.xlsx')
        df.to_excel(excel_path, index=False)

    return excel_path, merged_pdf_dir, no_xml_pdf_dir, missing_files

# ==========================================
# 4. æ‰‹åŠ¨æ ¸å¯¹åŠŸèƒ½ (Tab 2)
# ==========================================
def run_manual_check(raw_dir, proc_zip_path, out_dir):
    """åŸºäºæ–‡ä»¶åçš„æ‰‹åŠ¨æ ¸å¯¹"""
    # 1. è¯»å–å·²å¤„ç†å‘ç¥¨å·
    processed_nums = set()
    with zipfile.ZipFile(proc_zip_path, 'r') as z:
        for n in z.namelist():
            base = os.path.basename(n)
            m = re.search(r'^(\d{8,})', base)
            if m: processed_nums.add(m.group(1))

    # 2. æ‰«æåŸå§‹æ–‡ä»¶
    missing = []
    matched_count = 0
    
    for root, _, files in os.walk(raw_dir):
        for f in files:
            if not f.lower().endswith(('.pdf', '.xml')): continue
            fp = os.path.join(root, f)
            
            # ç®€æ˜“æå–å‘ç¥¨å·
            num = None
            try:
                if f.endswith('.xml'):
                    info = parse_xml_invoice_data(fp)
                    if info: num = info['num']
                else:
                    data = extract_data_from_pdf_simple(fp)
                    if data: num = data['å‘ç¥¨å·ç ']
            except: pass
            
            # åˆ¤æ–­
            # å¦‚æœæ˜¯è¡Œç¨‹å•(Trip)ï¼Œä¸”æ²¡æœ‰è¢«åˆå¹¶(ä¸åœ¨zipé‡Œä½“ç°)ï¼Œå¯èƒ½æ— æ³•ç›´æ¥é€šè¿‡æ–‡ä»¶ååˆ¤æ–­
            # è¿™é‡Œä¸»è¦æ ¸å¯¹ä¸»å‘ç¥¨
            if num and num in processed_nums:
                matched_count += 1
            else:
                # åªæœ‰å½“å®ƒæ˜¯å‘ç¥¨ä¸”æ²¡æ‰¾åˆ°æ—¶æ‰ç®—Missing
                # æˆ–æ˜¯è¡Œç¨‹å•ä¸”æ²¡æ‰¾åˆ°
                missing.append(fp)
    
    # æ‰“åŒ…
    zip_p = None
    if missing:
        zip_p = os.path.join(out_dir, "Manual_Missing.zip")
        with zipfile.ZipFile(zip_p, 'w', zipfile.ZIP_DEFLATED) as z:
            for m in missing: z.write(m, os.path.basename(m))
            
    return matched_count, len(missing), zip_p

# ==========================================
# 5. Streamlit ä¸»ç•Œé¢
# ==========================================

def main():
    st.set_page_config(page_title="å‘ç¥¨æ— å¿§ V10 (ç»ˆæç‰ˆ)", layout="wide")
    st.title("ğŸ§¾ å‘ç¥¨æ— å¿§ V10 (å«è‡ªåŠ¨æ ¸å¯¹ä¸é—æ¼æ‰“åŒ…)")

    tab1, tab2 = st.tabs(["ğŸš€ ä¸€é”®å¤„ç† (è‡ªåŠ¨æ ¸å¯¹)", "ğŸ” æ‰‹åŠ¨å¤æ ¸ (æ—§åŒ…å®¡è®¡)"])

    # --- Tab 1: è‡ªåŠ¨å¤„ç† + è‡ªåŠ¨æ ¸å¯¹ ---
    with tab1:
        st.info("ä¸Šä¼  ZIP/æ–‡ä»¶å¤¹ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨ï¼š1.éš”ç¦»ä½œç”¨åŸŸåŒ¹é…è¡Œç¨‹å• 2.ç”Ÿæˆæ±‡æ€» 3.è‡ªåŠ¨æ‰¾å‡ºé—æ¼æ–‡ä»¶å¹¶æ‰“åŒ…")
        uploaded_files = st.file_uploader("ä¸Šä¼ æ–‡ä»¶", type=['zip', 'xml', 'pdf'], accept_multiple_files=True, key="u1")

        if uploaded_files and st.button("å¼€å§‹å¤„ç†", key="b1"):
            with st.spinner('æ­£åœ¨å…¨æµç¨‹å¤„ç†...'):
                with tempfile.TemporaryDirectory() as temp_dir:
                    input_root = os.path.join(temp_dir, "input")
                    os.makedirs(input_root, exist_ok=True)
                    
                    # 1. ç‰©ç†éš”ç¦»ä¿å­˜
                    for i, up in enumerate(uploaded_files):
                        scope_dir = os.path.join(input_root, f"scope_{i}")
                        os.makedirs(scope_dir, exist_ok=True)
                        save_path = os.path.join(scope_dir, up.name)
                        with open(save_path, "wb") as f: f.write(up.getbuffer())
                        if up.name.endswith('.zip'):
                            extract_zip_with_encoding(save_path, scope_dir)
                            os.remove(save_path)
                    
                    # 2. è¿è¡Œç®¡é“
                    out_dir = os.path.join(temp_dir, "output")
                    excel, merged, noxml, missing_list = run_process_pipeline(input_root, out_dir)
                    
                    # 3. ç»“æœå±•ç¤º
                    st.success("âœ… å¤„ç†å®Œæˆï¼")
                    
                    # ç»Ÿè®¡
                    col1, col2 = st.columns(2)
                    if excel:
                        df = pd.read_excel(excel)
                        count = len(df) - 1 # å‡å»æ€»è®¡è¡Œ
                        col1.metric("æˆåŠŸåŒ¹é…å‘ç¥¨", f"{count} å¼ ")
                        st.dataframe(df.tail(3))
                    
                    # é—æ¼å¤„ç†
                    col2.metric("é—æ¼æ–‡ä»¶", f"{len(missing_list)} ä¸ª", delta_color="inverse")
                    if missing_list:
                        st.warning("âš ï¸ æ£€æµ‹åˆ°æœ‰æ–‡ä»¶æœªè¢«å¤„ç†ï¼ˆå¯èƒ½æ˜¯æŸåã€åŠ å¯†æˆ–éå‘ç¥¨æ–‡ä»¶ï¼‰ï¼Œå·²æ‰“åŒ…å¦‚ä¸‹ï¼š")
                        missing_zip = os.path.join(temp_dir, "Missing_Files.zip")
                        with zipfile.ZipFile(missing_zip, 'w', zipfile.ZIP_DEFLATED) as z:
                            for mf in missing_list:
                                z.write(mf, f"é—æ¼æ–‡ä»¶/{os.path.basename(mf)}")
                        with open(missing_zip, "rb") as f:
                            st.download_button("ğŸ“¥ ä¸‹è½½é—æ¼æ–‡ä»¶åŒ… (Missing.zip)", f, "Missing_Files.zip", type="primary")

                    # ä¸»ç»“æœæ‰“åŒ…
                    if excel:
                        res_zip = os.path.join(temp_dir, "Result.zip")
                        with zipfile.ZipFile(res_zip, 'w', zipfile.ZIP_DEFLATED) as z:
                            z.write(excel, "æ±‡æ€»è¡¨.xlsx")
                            for r, _, fs in os.walk(merged):
                                for f in fs: z.write(os.path.join(r, f), f"åˆå¹¶åå‘ç¥¨/{f}")
                            for r, _, fs in os.walk(noxml):
                                for f in fs: z.write(os.path.join(r, f), f"ç‹¬ç«‹å‘ç¥¨/{f}")
                        
                        with open(res_zip, "rb") as f:
                            st.download_button("ğŸ“¥ ä¸‹è½½å¤„ç†ç»“æœ (Result.zip)", f, "Invoices_Result.zip")

    # --- Tab 2: æ‰‹åŠ¨æ ¸å¯¹ ---
    with tab2:
        st.write("ç”¨äºæ ¸å¯¹**ä»¥å‰å¤„ç†è¿‡çš„**ç»“æœåŒ…ã€‚")
        c1, c2 = st.columns(2)
        raw_ups = c1.file_uploader("1. ä¸Šä¼ åŸå§‹å‘ç¥¨ (ZIP/PDF)", type=['zip','pdf'], accept_multiple_files=True, key="u2")
        proc_zip = c2.file_uploader("2. ä¸Šä¼ å·²å¤„ç† Result.zip", type=['zip'], key="u3")
        
        if raw_ups and proc_zip and st.button("å¼€å§‹æ ¸å¯¹", key="b2"):
            with tempfile.TemporaryDirectory() as td:
                raw_d = os.path.join(td, "raw")
                os.makedirs(raw_d, exist_ok=True)
                for up in raw_ups:
                    p = os.path.join(raw_d, up.name)
                    with open(p, "wb") as f: f.write(up.getbuffer())
                    if p.endswith('.zip'): extract_zip_with_encoding(p, raw_d)
                
                pz = os.path.join(td, "proc.zip")
                with open(pz, "wb") as f: f.write(proc_zip.getbuffer())
                
                match, miss, mzip = run_manual_check(raw_d, pz, td)
                st.metric("åŒ¹é…æˆåŠŸ", match)
                st.metric("é—æ¼/æœªåŒ¹é…", miss)
                if mzip:
                    with open(mzip, "rb") as f:
                        st.download_button("ä¸‹è½½æœªåŒ¹é…æ–‡ä»¶", f, "Unmatched.zip")

if __name__ == "__main__":
    main()